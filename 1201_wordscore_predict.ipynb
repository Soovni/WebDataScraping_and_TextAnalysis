{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d22e090f326c46a2addabd25938c3bf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_301658b9f13b4e4ab9698afa9e84078e","IPY_MODEL_a1c2e03e6f804e56be2acc771e18b76b","IPY_MODEL_3d834bd7e10d4727b218360cbba3adba"],"layout":"IPY_MODEL_df7e15759c464347a3b8bd9ddd36c96a"}},"301658b9f13b4e4ab9698afa9e84078e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b98ada64f7ad4012aa2a8a028670c2b1","placeholder":"​","style":"IPY_MODEL_9851a7bd5841420bba2b46225137567d","value":"tokenizer_config.json: 100%"}},"a1c2e03e6f804e56be2acc771e18b76b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f8c8611b04147aebeae027f01541da3","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9b0fbffc15a421c9b6aa43cc7af664b","value":48}},"3d834bd7e10d4727b218360cbba3adba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9f1608aa1664d24962b68f91c5c0ccd","placeholder":"​","style":"IPY_MODEL_54a8d483397c43b99d0f529c07aa8548","value":" 48.0/48.0 [00:00&lt;00:00, 3.46kB/s]"}},"df7e15759c464347a3b8bd9ddd36c96a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b98ada64f7ad4012aa2a8a028670c2b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9851a7bd5841420bba2b46225137567d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f8c8611b04147aebeae027f01541da3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9b0fbffc15a421c9b6aa43cc7af664b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9f1608aa1664d24962b68f91c5c0ccd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54a8d483397c43b99d0f529c07aa8548":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d1d17f759704aa3a04367fd1573a052":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6406610b2ef04b08a4dbfa2576e18aa0","IPY_MODEL_be690b24fb03468ea17a6b5d4a757116","IPY_MODEL_4c73868dba9845eaaf1601a7d0cad9e2"],"layout":"IPY_MODEL_81e1894e17714bfcab8ab9b3055aa7be"}},"6406610b2ef04b08a4dbfa2576e18aa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66931a5dcbbd4f7cb515761e9a1b707f","placeholder":"​","style":"IPY_MODEL_b9bc92c5061b44208352229c7f53161b","value":"vocab.txt: 100%"}},"be690b24fb03468ea17a6b5d4a757116":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a48c9eb04f34460bbae613502fc7870e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f0ed73e63c145eeb955322057fa475f","value":231508}},"4c73868dba9845eaaf1601a7d0cad9e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19972b4ddb346dc8fb3705380d84351","placeholder":"​","style":"IPY_MODEL_5b30f352bf1f4af09a6a492a24f99b5a","value":" 232k/232k [00:00&lt;00:00, 1.03MB/s]"}},"81e1894e17714bfcab8ab9b3055aa7be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66931a5dcbbd4f7cb515761e9a1b707f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9bc92c5061b44208352229c7f53161b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a48c9eb04f34460bbae613502fc7870e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f0ed73e63c145eeb955322057fa475f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d19972b4ddb346dc8fb3705380d84351":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b30f352bf1f4af09a6a492a24f99b5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09fe0e8a998c437394460a48321e67d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f737bfa537b74cb8874e3177e0e72763","IPY_MODEL_2772ef6f06234ec2a2968fd23458081f","IPY_MODEL_19fff7e212174ffe912901973b248653"],"layout":"IPY_MODEL_40fe215f0a0148a699783f2c9174500d"}},"f737bfa537b74cb8874e3177e0e72763":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bdc202cd7964022a7af773b492b1dcd","placeholder":"​","style":"IPY_MODEL_465501d42c65416083a794c527c568dc","value":"tokenizer.json: 100%"}},"2772ef6f06234ec2a2968fd23458081f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_171eb1fa692e4ff69a9dfeac8832a6ce","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_894eb3f8149e4584bd5368536c67c028","value":466062}},"19fff7e212174ffe912901973b248653":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca86e92dbd174731af92f8cc730351bf","placeholder":"​","style":"IPY_MODEL_a7b11473e72e402ab71b737f8627bd57","value":" 466k/466k [00:00&lt;00:00, 28.1MB/s]"}},"40fe215f0a0148a699783f2c9174500d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bdc202cd7964022a7af773b492b1dcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"465501d42c65416083a794c527c568dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"171eb1fa692e4ff69a9dfeac8832a6ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894eb3f8149e4584bd5368536c67c028":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca86e92dbd174731af92f8cc730351bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7b11473e72e402ab71b737f8627bd57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e6e5e176dc241a2bdb7f4ab145038b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04d1e8ea3b2d4cdbb34bc4392d9e4095","IPY_MODEL_74cf4c840c2141698c722210d26c77ce","IPY_MODEL_38c4ee4f6a0448b39a1ce40121a46cfd"],"layout":"IPY_MODEL_cdeda28e27e84e339898f46355923423"}},"04d1e8ea3b2d4cdbb34bc4392d9e4095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94e8002bf21a423aa011d7134083294b","placeholder":"​","style":"IPY_MODEL_fdd2a883fda04752ac3326117939737d","value":"config.json: 100%"}},"74cf4c840c2141698c722210d26c77ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d669affab0a54dce8b91e3e7c5a4f1aa","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7249436c7daa450c8c280511928b2187","value":570}},"38c4ee4f6a0448b39a1ce40121a46cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ac1c728bfd344faae7dbdbc5543e180","placeholder":"​","style":"IPY_MODEL_a70f9f19123d4e37b4a47c06417f7d3b","value":" 570/570 [00:00&lt;00:00, 45.5kB/s]"}},"cdeda28e27e84e339898f46355923423":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94e8002bf21a423aa011d7134083294b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdd2a883fda04752ac3326117939737d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d669affab0a54dce8b91e3e7c5a4f1aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7249436c7daa450c8c280511928b2187":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ac1c728bfd344faae7dbdbc5543e180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a70f9f19123d4e37b4a47c06417f7d3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e3a76fe8c7142be844e1f64b7f58536":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6754f952cfb948e0b218ed6f5f40921a","IPY_MODEL_bf2acf19e44b46e4ae8a0895c24f98f4","IPY_MODEL_6f8d8e4cd9314621890f14d34114baf4"],"layout":"IPY_MODEL_67fba1c363184b87a1df269665a3361a"}},"6754f952cfb948e0b218ed6f5f40921a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69f0a7373af94dc1abf806fd5004a0c5","placeholder":"​","style":"IPY_MODEL_aaa7942a5bce4672b4ee7cc48243d63c","value":"model.safetensors: 100%"}},"bf2acf19e44b46e4ae8a0895c24f98f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20debfa94e7e4285a6e62ffca4dc6753","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56d5b9e473ec478eb58a90dfbd6164c6","value":440449768}},"6f8d8e4cd9314621890f14d34114baf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a703331d0c346469f966cb60cdb2623","placeholder":"​","style":"IPY_MODEL_793d52ac2e8c422db680d7a776ec5e64","value":" 440M/440M [00:01&lt;00:00, 241MB/s]"}},"67fba1c363184b87a1df269665a3361a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f0a7373af94dc1abf806fd5004a0c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaa7942a5bce4672b4ee7cc48243d63c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20debfa94e7e4285a6e62ffca4dc6753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56d5b9e473ec478eb58a90dfbd6164c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a703331d0c346469f966cb60cdb2623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"793d52ac2e8c422db680d7a776ec5e64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"GmtOs44dns5Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","다방 결과 해석:\n","\n","- 가장 중요한 단어는 **\"허위\"**로, 중요도가 약 0.397으로 매우 높다.\n","- 이는 리뷰 데이터에서 \"허위\"라는 단어가 등장하면 별점 예측에 큰 영향을 준다는 것을 의미함.\n","  - 예: \"허위 매물\", \"허위 광고\" 같은 부정적 맥락에서 별점이 낮게 평가되었을 가능성이 높습니다.\n","- 앱 버전(예: \"2.1\", \"2.4.1\")도 일부 중요 피처로 포함되었습니다.\n","- 특정 앱 버전에서 사용자 경험이 좋지 않아 별점에 영향을 미쳤을 수 있습니다.\n","- 단어 \"네트워크\", \"업데이트\", \"오류\" 등은 리뷰에서 문제가 언급될 때 부정적 평가로 이어졌을 가능성이 있습니다.\n","- \"삭제\"는 리뷰에서 앱을 삭제하려는 사용자 경험과 관련된 부정적 별점으로 이어질 가능성이 있습니다."],"metadata":{"id":"zRGaWddrqjx1"}},{"cell_type":"markdown","source":["--------------------------------------\n"," 밑에는 다른 방법\n","  -------------------------------------------------"],"metadata":{"id":"RUWHZ_NMvZx2"}},{"cell_type":"markdown","source":["## 주요단계 설명\n","\n","* (1)  버전 그룹화\n","major.minor 형태로 버전을 묶음 (2.1.0, 2.1.1 → 2.1).\n","* (2) 버전별 단어 빈도 분석\n","각 버전에서 등장한 단어를 집계하여 명사 빈도를 계산.\n","버전별로 많이 등장한 단어를 비교.\n","* (3) 별점과 단어 관계 분석\n","특정 단어가 별점에 미치는 영향을 분석.\n","예: \"허위\", \"오류\" 등의 단어가 부정적 별점에 기여.\n","* (4) 버전별 데이터로 모델링\n","버전별 데이터를 입력으로 별점 예측 모델을 학습.\n","텍스트 데이터를 버전별로 그룹화하여 모델의 입력 변수로 사용."],"metadata":{"id":"-7XsB778vZ_m"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import ast\n","from collections import Counter\n","from google.colab import drive\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')\n","\n","# 데이터 경로 설정\n","base_path = '/content/drive/MyDrive/2024/TextMining'\n","data_path = os.path.join(base_path, 'reviews_data')\n","output_path = os.path.join(base_path, 'reviewmodel')  # 결과 저장 폴더\n","os.makedirs(output_path, exist_ok=True)  # 폴더가 없으면 생성\n","\n","app_names = ['다방', '직방', '네이버부동산', '피터팬', '호갱노노']\n","files = [os.path.join(data_path, f\"preprocessed2_reviews_data_{app}_별점.csv\") for app in app_names]\n","\n","# 버전별 단어 빈도 저장용 딕셔너리\n","version_word_results = {}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Zahb0BEq-t7","executionInfo":{"status":"ok","timestamp":1733809567569,"user_tz":-540,"elapsed":41173,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"806f3897-5d00-4b4f-da55-d0a292ca4ea9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["1. 버전 그룹화\n","major.minor 형태로 버전을 묶음 (2.1.0, 2.1.1 → 2.1).\n","2. 버전별 단어 빈도 분석\n","각 버전에서 등장한 단어를 집계하여 명사 빈도를 계산."],"metadata":{"id":"BB3oKbREwG0H"}},{"cell_type":"code","source":["\n","\n","# 파일별 데이터 처리\n","for app, file in zip(app_names, files):\n","    if os.path.exists(file):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 데이터 로드\n","        data = pd.read_csv(file)\n","\n","        # 결측치 처리\n","        data_cleaned = data.dropna(subset=['reviewCreatedVersion'])\n","        data_cleaned['reviewCreatedVersion'] = data_cleaned['reviewCreatedVersion'].astype(str)\n","\n","        # 버전을 'major.minor' 형태로 그룹화\n","        data_cleaned['grouped_version'] = data_cleaned['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n","\n","        # 버전별 단어 빈도 계산\n","        version_word_counts = {}\n","        for version, group in data_cleaned.groupby('grouped_version'):\n","            # 명사 추출 및 빈도 계산\n","            words = group['nouns_without_stopwords'].apply(lambda x: eval(x)).explode()\n","            word_counts = Counter(words)\n","            version_word_counts[version] = word_counts.most_common(10)\n","\n","        print(f\"{app}: 버전별 주요 단어:\")\n","        for version, words in version_word_counts.items():\n","            print(f\"Version {version}: {words}\")\n","\n","        # 저장\n","        version_word_results[app] = version_word_counts\n","\n","    else:\n","        print(f\"{app}: 파일을 찾을 수 없음\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WblTAe8MvBML","executionInfo":{"status":"ok","timestamp":1733810370473,"user_tz":-540,"elapsed":8107,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"5713f5af-8d78-4256-f3b1-c7ae81873fb8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 다방...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-cca63738fd21>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['reviewCreatedVersion'] = data_cleaned['reviewCreatedVersion'].astype(str)\n","<ipython-input-2-cca63738fd21>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['grouped_version'] = data_cleaned['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n"]},{"output_type":"stream","name":"stdout","text":["다방: 버전별 주요 단어:\n","Version 1.0: [('매물', 9), ('직거래', 5), ('어플', 5), ('부동산', 4), ('정보', 4), ('볼', 4), ('사진', 3), ('사용', 3), ('최고', 2), ('번창', 2)]\n","Version 1.1: [('방', 5), ('설정', 5), ('어플', 5), ('알림', 4), ('위치', 4), ('최고', 4), ('보기', 4), ('매물', 4), ('디자인', 4), ('앱', 3)]\n","Version 1.2: [('앱', 2), ('방이', 1), ('안', 1), ('보급', 1), ('사무실', 1), ('정보', 1), (nan, 1), ('매우', 1), ('얼른', 1), ('유저', 1)]\n","Version 1.3: [('지역', 3), ('설정', 2), ('별로', 2), ('원룸', 2), ('지도', 2), ('살', 1), ('모든', 1), ('구분', 1), ('은', 1), ('초반', 1)]\n","Version 1.4: [('원룸', 4), ('검색', 3), ('방', 3), ('지도', 2), ('안', 2), ('제주도', 2), ('별', 2), ('식', 2), ('개선', 1), ('노트', 1)]\n","Version 1.5: [('어플', 62), ('방', 35), ('집', 28), ('앱', 22), ('정보', 17), ('대박', 16), ('볼', 15), ('원룸', 12), ('완전', 11), ('아주', 9)]\n","Version 1.6: [('피터', 1), ('팬', 1), ('글', 1), ('앱', 1), ('설치', 1), ('스팸', 1), ('뭐', 1), (nan, 1), ('굿', 1)]\n","Version 1.7: [('방', 9), ('검색', 8), ('어플', 8), ('확인', 5), ('찾기', 4), ('안', 4), ('사진', 4), ('비번', 3), ('추천', 3), ('방도', 3)]\n","Version 1.8: [('매물', 4), ('수가', 3), ('방', 3), ('어플', 3), ('물건', 3), ('소비자', 3), ('구글', 2), ('지도', 2), ('안', 2), ('처리', 2)]\n","Version 1.9: [('방', 3), ('직방', 2), ('확인', 2), ('하라', 2), ('진주시', 2), ('안', 2), ('주변', 2), ('햇', 2), ('애완견', 2), ('앱', 1)]\n","Version 2.0: [('방', 1), ('사진', 1), ('안', 1), ('어캄', 1), ('원주시', 1), ('검색', 1), ('번', 1), ('햇', 1), ('데', 1), ('버렷', 1)]\n","Version 2.1: [('대박', 202), ('어플', 182), ('앱', 146), ('방', 125), ('정보', 114), ('집', 89), ('추천', 48), ('최고', 41), ('사용', 36), ('안', 35)]\n","Version 2.10: [('매물', 7), ('허위', 6), ('어플', 5), ('방', 5), ('부동산', 4), ('다방', 3), ('안', 3), ('보고', 3), ('답', 2), ('거짓말', 2)]\n","Version 2.11: [('방', 28), ('매물', 20), ('다방', 16), ('허위', 13), ('앱', 11), ('어플', 10), ('두', 8), ('부동산', 7), ('안', 6), ('이용', 6)]\n","Version 2.12: [('방', 27), ('매물', 18), ('다방', 17), ('허위', 16), ('안', 12), ('부동산', 11), ('직방', 9), ('어플', 8), ('보고', 7), ('신고', 5)]\n","Version 2.13: [('방', 24), ('매물', 20), ('허위', 19), ('안', 13), ('다방', 11), ('앱', 10), ('필터', 9), ('가격', 8), ('계약', 8), ('부동산', 7)]\n","Version 2.14: [('매물', 61), ('방', 54), ('허위', 48), ('다방', 28), ('안', 21), ('가격', 18), ('집', 18), ('방이', 17), ('관리', 16), ('사람', 15)]\n","Version 2.15: [('방', 39), ('매물', 38), ('다방', 35), ('허위', 34), ('부동산', 16), ('어플', 11), ('신고', 10), ('말', 10), ('방이', 9), ('연락', 9)]\n","Version 2.16: [('매물', 33), ('방', 29), ('허위', 27), ('어플', 15), ('보고', 14), ('사진', 10), ('광고', 9), ('부동산', 9), ('다방', 8), ('말', 7)]\n","Version 2.17: [('매물', 47), ('방', 32), ('허위', 20), ('안', 20), ('사진', 15), ('다방', 15), ('부동산', 11), ('집', 11), ('보고', 10), ('방이', 9)]\n","Version 2.18: [('매물', 304), ('방', 291), ('다방', 267), ('허위', 177), ('어플', 172), ('부동산', 103), ('안', 98), ('원룸', 92), ('정보', 65), ('집', 63)]\n","Version 2.2: [('방', 7), ('안', 6), ('매물', 5), ('방이', 3), ('부동산', 3), ('연락', 3), ('에러', 3), ('어플', 3), ('소비자', 2), ('허위', 2)]\n","Version 2.3: [('어플', 160), ('방', 152), ('앱', 107), ('집', 93), ('다방', 82), ('안', 44), ('원룸', 42), ('매물', 34), ('볼', 34), ('사진', 33)]\n","Version 2.4: [('방', 914), ('어플', 617), ('앱', 586), ('집', 435), ('다방', 373), ('정보', 226), ('최고', 211), ('추천', 202), ('부동산', 174), ('볼', 159)]\n","Version 2.5: [('방', 40), ('매물', 29), ('안', 20), ('허위', 18), ('방이', 15), ('집', 14), ('앱', 12), ('검색', 12), ('다방', 11), ('부동산', 8)]\n","Version 2.6: [('매물', 21), ('방', 17), ('허위', 14), ('안', 7), ('연락', 7), ('말', 7), ('검색', 7), ('부동산', 7), ('집', 7), ('앱', 7)]\n","Version 2.7: [('방', 9), ('안', 3), ('연락', 3), ('모델', 3), ('문자', 2), ('해리', 2), ('계약', 2), ('검색', 2), ('정보', 2), ('데', 2)]\n","Version 2.8: [('매물', 61), ('허위', 41), ('방', 37), ('다방', 28), ('안', 25), ('부동산', 21), ('어플', 14), ('집', 14), ('사진', 14), ('신고', 13)]\n","Version 2.9: [('방', 35), ('매물', 24), ('허위', 15), ('어플', 13), ('다방', 11), ('사진', 8), ('부동산', 7), ('안', 6), ('중개사', 6), ('광고', 5)]\n","Version 3.0: [('매물', 198), ('방', 140), ('다방', 140), ('허위', 110), ('어플', 103), ('부동산', 99), ('집', 84), ('안', 68), ('곳', 47), ('정보', 44)]\n","Version 3.1: [('매물', 172), ('허위', 125), ('방', 93), ('다방', 84), ('어플', 62), ('부동산', 61), ('안', 45), ('사진', 37), ('집', 34), ('앱', 30)]\n","Version 3.10: [('매물', 722), ('집', 544), ('다방', 407), ('허위', 207), ('부동산', 187), ('정보', 151), ('원룸', 129), ('보고', 114), ('안', 111), ('어플', 110)]\n","Version 3.2: [('매물', 277), ('허위', 181), ('방', 131), ('다방', 91), ('부동산', 87), ('집', 79), ('안', 76), ('어플', 76), ('앱', 52), ('사진', 37)]\n","Version 3.3: [('매물', 345), ('허위', 229), ('다방', 170), ('방', 115), ('집', 107), ('부동산', 105), ('어플', 100), ('안', 88), ('앱', 67), ('보고', 54)]\n","Version 3.4: [('매물', 233), ('허위', 151), ('다방', 145), ('집', 92), ('부동산', 80), ('방', 61), ('안', 59), ('어플', 53), ('기능', 41), ('점', 39)]\n","Version 3.5: [('매물', 360), ('다방', 220), ('집', 161), ('허위', 139), ('방', 116), ('어플', 82), ('부동산', 73), ('안', 67), ('앱', 52), ('월세', 51)]\n","Version 3.6: [('매물', 451), ('다방', 240), ('허위', 225), ('집', 211), ('방', 138), ('앱', 117), ('안', 97), ('부동산', 93), ('검증', 86), ('어플', 82)]\n","Version 3.7: [('매물', 284), ('집', 144), ('허위', 135), ('다방', 116), ('부동산', 71), ('방', 59), ('앱', 56), ('안', 55), ('정보', 54), ('어플', 46)]\n","Version 3.8: [('집', 29), ('매물', 27), ('다방', 16), ('허위', 13), ('앱', 12), ('정보', 10), ('이용', 9), ('시설', 9), ('학군', 8), ('방', 7)]\n","Version 3.9: [('매물', 696), ('집', 561), ('다방', 435), ('허위', 247), ('부동산', 195), ('정보', 133), ('방', 118), ('안', 117), ('이용', 112), ('보고', 104)]\n","Version 4.0: [('매물', 40), ('허위', 27), ('앱', 18), ('방', 15), ('안', 13), ('부동산', 11), ('연락', 7), ('곳', 6), ('그냥', 6), ('집', 6)]\n","Version 4.1: [('매물', 33), ('허위', 22), ('다방', 12), ('방', 12), ('안', 9), ('부동산', 8), ('직방', 8), ('관리', 6), ('개', 5), ('집', 5)]\n","Version 4.10: [('매물', 70), ('허위', 46), ('방', 28), ('부동산', 20), ('안', 18), ('다방', 17), ('신고', 14), ('어플', 10), ('문의', 10), ('연락', 10)]\n","Version 4.11: [('방', 12), ('다방', 10), ('매물', 9), ('그냥', 4), ('관리', 4), ('번', 4), ('주변', 4), ('내', 4), ('지도', 3), ('집', 3)]\n","Version 4.12: [('다방', 28), ('매물', 24), ('부동산', 13), ('허위', 10), ('집', 10), ('방', 9), ('연락', 8), ('앱', 8), ('보고', 7), ('안', 7)]\n","Version 4.13: [('매물', 75), ('허위', 48), ('안', 28), ('방', 18), ('어플', 18), ('앱', 16), ('부동산', 12), ('사진', 10), ('다시', 9), ('사기', 9)]\n","Version 4.14: [('안', 24), ('매물', 23), ('어플', 17), ('허위', 17), ('부동산', 11), ('앱', 10), ('다방', 10), ('방', 8), ('다시', 6), ('사기', 6)]\n","Version 4.15: [('매물', 33), ('허위', 19), ('부동산', 14), ('어플', 10), ('방', 8), ('안', 6), ('다방', 6), ('필터', 5), ('전', 4), ('곳', 4)]\n","Version 4.16: [('매물', 8), ('다방', 4), ('거래', 4), ('부동산', 3), ('안', 3), ('함', 3), ('집', 2), ('사기', 2), ('자체', 2), ('번', 2)]\n","Version 4.17: [('매물', 3), ('사용', 2), ('방이', 2), ('개', 2), ('어플', 2), ('원룸', 2), ('민폐', 1), ('주차', 1), ('직원', 1), ('해고', 1)]\n","Version 4.18: [('매물', 27), ('허위', 24), ('방', 16), ('다방', 14), ('부동산', 11), ('어플', 10), ('집', 7), ('안', 7), ('사진', 7), ('앱', 5)]\n","Version 4.19: [('매물', 5), ('허위', 4), ('반려동물', 2), ('가능', 2), ('신고', 2), ('빌라', 2), ('지도', 2), ('축소', 2), ('위치', 2), ('파악', 2)]\n","Version 4.2: [('매물', 38), ('허위', 28), ('반려동물', 25), ('필터', 24), ('대출', 20), ('다방', 19), ('어플', 14), ('가능', 13), ('전세', 12), ('업데이트', 12)]\n","Version 4.20: [('허위', 5), ('매물', 5), ('방', 3), ('글', 3), ('볼', 2), ('필터', 2), ('해결', 1), ('대부분', 1), ('사진', 1), ('보고', 1)]\n","Version 4.3: [('매물', 55), ('허위', 37), ('안', 18), ('집', 18), ('다방', 16), ('방', 16), ('어플', 15), ('신고', 15), ('앱', 12), ('부동산', 12)]\n","Version 4.4: [('매물', 50), ('허위', 42), ('앱', 19), ('안', 19), ('방', 14), ('다방', 13), ('관리', 11), ('개', 8), ('어플', 8), ('신고', 8)]\n","Version 4.5: [('매물', 36), ('허위', 25), ('방', 16), ('앱', 13), ('다방', 8), ('보고', 8), ('부동산', 8), ('안', 8), ('연락', 6), ('신고', 6)]\n","Version 4.6: [('매물', 67), ('허위', 44), ('다방', 21), ('안', 19), ('방', 19), ('부동산', 15), ('어플', 12), ('관리', 9), ('앱', 9), ('신고', 7)]\n","Version 4.7: [('업데이트', 39), ('하라', 15), ('매물', 15), ('허위', 14), ('안', 12), ('최신', 10), ('다방', 8), ('버전', 7), ('계속', 7), ('방', 7)]\n","Version 4.8: [('매물', 23), ('허위', 17), ('방', 14), ('부동산', 12), ('계약', 6), ('다방', 6), ('해', 5), ('중고차', 4), ('어플', 4), ('안', 4)]\n","Version 4.9: [('매물', 21), ('허위', 14), ('방', 9), ('안', 9), ('다방', 8), ('신고', 7), ('어플', 6), ('직', 5), ('앱', 5), ('집', 5)]\n","Version 5.0: [('매물', 31), ('방', 30), ('업데이트', 28), ('허위', 18), ('필터', 18), ('다방', 14), ('안', 12), ('검색', 11), ('선택', 10), ('부동산', 9)]\n","Processing 직방...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-cca63738fd21>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['reviewCreatedVersion'] = data_cleaned['reviewCreatedVersion'].astype(str)\n","<ipython-input-2-cca63738fd21>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['grouped_version'] = data_cleaned['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n"]},{"output_type":"stream","name":"stdout","text":["직방: 버전별 주요 단어:\n","Version 1.0: [('사진', 1), ('확인', 1)]\n","Version 1.1: [('허위', 2), ('방', 2), ('검색', 2), ('물건', 1), ('명', 1), ('등록', 1), ('사기', 1), ('운영', 1), ('어플', 1), ('위치', 1)]\n","Version 3.0: [('방', 68), ('어플', 65), ('지역', 35), ('관악구', 21), ('앱', 21), ('직방', 20), ('안', 18), ('볼', 14), ('정보', 13), ('보고', 13)]\n","Version 4.0: [('사진', 9), ('방', 5), ('서울', 4), ('집', 4), ('볼', 4), ('번', 3), ('방이', 3), ('안', 2), ('정보', 2), ('지도', 2)]\n","Version 4.1: [('안', 25), ('방', 23), ('어플', 21), ('사진', 20), ('집', 19), ('매물', 14), ('원룸', 10), ('볼', 9), ('개', 8), ('정보', 8)]\n","Version 4.10: [('방', 816), ('매물', 613), ('직방', 443), ('안', 433), ('허위', 411), ('집', 301), ('부동산', 283), ('앱', 260), ('어플', 249), ('사진', 233)]\n","Version 4.11: [('방', 20), ('매물', 19), ('안', 12), ('직방', 10), ('허위', 9), ('집', 9), ('부동산', 9), ('광고', 8), ('앱', 7), ('검색', 7)]\n","Version 4.12: [('매물', 165), ('방', 136), ('허위', 114), ('직방', 109), ('안', 81), ('부동산', 61), ('앱', 56), ('집', 49), ('사진', 36), ('직거래', 35)]\n","Version 4.13: [('매물', 504), ('허위', 377), ('방', 333), ('안', 225), ('부동산', 170), ('직방', 170), ('앱', 135), ('사진', 116), ('집', 113), ('어플', 105)]\n","Version 4.14: [('매물', 94), ('허위', 62), ('방', 51), ('직방', 43), ('안', 35), ('중개사', 24), ('사진', 24), ('집', 22), ('앱', 22), ('부동산', 20)]\n","Version 4.15: [('매물', 412), ('허위', 269), ('안', 238), ('방', 215), ('직방', 144), ('앱', 138), ('부동산', 137), ('업데이트', 125), ('집', 104), ('어플', 75)]\n","Version 4.2: [('방', 250), ('어플', 164), ('집', 133), ('앱', 110), ('사진', 92), ('안', 86), ('정보', 73), ('볼', 68), ('직방', 60), ('원룸', 56)]\n","Version 4.5: [('방', 8), ('볼', 5), ('어플', 4), ('안', 4), ('매물', 4), ('업데이트', 3), ('후', 3), ('보기', 3), ('검색', 3), ('확인', 3)]\n","Version 4.6: [('방', 26), ('안', 17), ('어플', 16), ('사진', 9), ('검색', 9), ('직방', 8), ('자꾸', 8), ('앱', 8), ('집', 7), ('실행', 7)]\n","Version 4.7: [('앱', 6), ('인터넷', 5), ('안', 5), ('오류', 4), ('연결', 4), ('뭐', 4), ('사진', 4), ('자꾸', 3), ('데', 3), ('종료', 3)]\n","Version 4.8: [('방', 45), ('안', 38), ('어플', 30), ('앱', 22), ('정보', 20), ('직방', 19), ('사진', 13), ('방이', 13), ('자꾸', 13), ('볼', 13)]\n","Version 4.9: [('직방', 2701), ('방', 2642), ('앱', 1259), ('매물', 940), ('집', 920), ('어플', 850), ('안', 759), ('부동산', 644), ('사진', 632), ('방이', 625)]\n","Version 5.0: [('매물', 159), ('허위', 93), ('직방', 84), ('안', 78), ('집', 56), ('방', 55), ('부동산', 51), ('앱', 48), ('어플', 47), ('다방', 39)]\n","Version 5.1: [('매물', 224), ('안', 221), ('허위', 116), ('로그인', 93), ('방', 90), ('집', 88), ('앱', 85), ('직방', 76), ('부동산', 75), ('정보', 65)]\n","Version 5.10: [('매물', 48), ('허위', 34), ('직방', 24), ('앱', 22), ('안', 21), ('신고', 20), ('집', 20), ('방', 17), ('어플', 15), ('부동산', 13)]\n","Version 5.11: [('매물', 51), ('안', 41), ('직방', 29), ('앱', 27), ('방', 25), ('허위', 22), ('집', 21), ('모빌', 19), ('기능', 17), ('어플', 15)]\n","Version 5.12: [('안', 33), ('매물', 31), ('허위', 17), ('방', 15), ('앱', 15), ('직방', 11), ('보고', 9), ('김', 9), ('연락', 8), ('사람', 8)]\n","Version 5.13: [('매물', 20), ('안', 11), ('허위', 9), ('집', 7), ('등록', 6), ('확인', 5), ('검색', 5), ('직방', 5), ('중개사', 4), ('번', 4)]\n","Version 5.14: [('업데이트', 1), ('후', 1), ('접속', 1)]\n","Version 5.2: [('매물', 165), ('안', 99), ('허위', 84), ('방', 52), ('집', 51), ('부동산', 40), ('직방', 40), ('아파트', 36), ('필터', 32), ('어플', 32)]\n","Version 5.3: [('매물', 273), ('안', 139), ('허위', 112), ('직방', 78), ('방', 77), ('집', 72), ('아파트', 65), ('앱', 65), ('보기', 60), ('어플', 58)]\n","Version 5.4: [('매물', 72), ('안', 40), ('앱', 38), ('허위', 37), ('직방', 29), ('아파트', 27), ('부동산', 23), ('방', 20), ('필터', 19), ('검색', 18)]\n","Version 5.5: [('매물', 10), ('앱', 10), ('연락', 6), ('안', 6), ('집', 5), ('허위', 4), ('문의', 4), ('검색', 4), ('개', 3), ('방', 3)]\n","Version 5.6: [('매물', 106), ('안', 58), ('허위', 58), ('방', 51), ('어플', 42), ('앱', 40), ('부동산', 33), ('집', 30), ('직방', 29), ('검색', 24)]\n","Version 5.7: [('매물', 149), ('허위', 90), ('안', 67), ('직방', 50), ('집', 50), ('방', 50), ('어플', 40), ('연락', 36), ('앱', 35), ('부동산', 32)]\n","Version 5.8: [('매물', 84), ('허위', 60), ('안', 45), ('직방', 37), ('방', 37), ('앱', 35), ('부동산', 35), ('어플', 26), ('집', 21), ('다방', 21)]\n","Version 5.9: [('매물', 61), ('안', 56), ('허위', 36), ('방', 26), ('앱', 25), ('집', 21), ('직방', 18), ('관리', 18), ('어플', 17), ('부동산', 17)]\n","Processing 네이버부동산...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-cca63738fd21>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['reviewCreatedVersion'] = data_cleaned['reviewCreatedVersion'].astype(str)\n","<ipython-input-2-cca63738fd21>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['grouped_version'] = data_cleaned['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n"]},{"output_type":"stream","name":"stdout","text":["네이버부동산: 버전별 주요 단어:\n","Version  '등록': [(nan, 1)]\n","Version 1.0: [('앱', 4), ('안드로이드', 2), ('부동산', 2), ('어플', 2), ('찾기', 2), ('일조', 2), ('기분', 2), ('집', 2), ('드뎌', 1), ('아이폰', 1)]\n","Version 1.1: [('세상', 1), ('자주', 1), ('업', 1), ('부탁', 1)]\n","Version 1.11: [('다킬', 1), ('업데이트', 1)]\n","Version 1.12: [('네이버', 2), ('사이트', 1), ('기능', 1), ('메인', 1), ('어플', 1), ('메뉴', 1), ('추가', 1)]\n","Version 1.13: [('화면', 2), ('터치', 1), ('이동', 1), ('주황색', 1), ('정', 1), ('지금', 1), ('상태', 1), ('론', 1), ('앱', 1), ('전혀', 1)]\n","Version 1.16: [(nan, 1)]\n","Version 1.17: [('부동산', 3), ('어플', 1), ('참고자료', 1), ('사용', 1), ('정보', 1), ('가장', 1), ('적', 1), ('확함', 1), ('매물', 1), ('아주', 1)]\n","Version 1.2: [('최고', 2), ('별루', 1), (nan, 1), ('안드로이드', 1), ('버젼', 1), ('최강', 1), ('부동산', 1), ('앱', 1), (nan, 1), (nan, 1)]\n","Version 1.22: [('폰', 2), ('매물', 2), ('안', 2), ('머', 1), ('보', 1), ('말', 1), ('먹통', 1), ('업', 1), ('뎃', 1), ('네이버', 1)]\n","Version 1.24: [('넥서스', 1), ('지원', 1), ('바람', 1), ('매물', 1), ('강종', 1), ('평면도', 1), ('보고', 1), ('뒤', 1), ('튕기네', 1)]\n","Version 1.25: [('집', 1), ('수도권', 1), ('위주', 1), (nan, 1), (nan, 1), (nan, 1)]\n","Version 1.26: [('앱', 2), ('버전', 1), ('훨', 1), (nan, 1), (nan, 1), ('뒤', 1), ('검색어', 1), ('화면', 1), ('초기', 1), ('둥', 1)]\n","Version 1.27: [(nan, 1), (nan, 1), (nan, 1), (nan, 1), (nan, 1), (nan, 1), (nan, 1), (nan, 1), ('태블릿', 1), ('사용자', 1)]\n","Version 1.28: [(nan, 1), (nan, 1), (nan, 1), ('개발자', 1), ('수고', 1)]\n","Version 1.29: [(nan, 1), (nan, 1)]\n","Version 1.3: [('내', 1), ('위치', 1), ('버튼', 1), ('곳', 1), ('정확도', 1), (nan, 1), ('무지', 1), ('다운로드', 1), ('중', 1), ('아이폰', 1)]\n","Version 1.30: [(nan, 1), (nan, 1), (nan, 1), (nan, 1), (nan, 1)]\n","Version 1.32: [('부동산', 2), (nan, 1), ('지도', 1), ('수원시', 1), ('주택', 1), ('매물', 1), ('설정', 1), ('개', 1), ('중', 1), ('애매', 1)]\n","Version 1.33: [('보기', 1), (nan, 1), (nan, 1)]\n","Version 1.34: [('보기', 2), ('군구', 2), ('매물', 1), ('선택', 1), ('전체', 1), ('기능', 1), ('시', 1), ('살', 1), ('보지', 1)]\n","Version 1.36: [('업데이트', 2), ('전', 1), ('동인지', 1), ('포시', 1), ('별', 1), ('매물', 1), ('클릭', 1), ('관', 1), ('내용', 1), ('최신', 1)]\n","Version 1.37: [('촤', 1)]\n","Version 1.38: [('매물', 3), ('네이버', 3), ('부동산', 3), ('허위', 2), ('구입', 2), ('대부분', 2), ('고', 2), ('앱', 2), ('아파트', 1), ('참조', 1)]\n","Version 1.39: [('옵', 1), ('케이', 1), ('최신', 1), ('버전', 1), ('위치', 1), ('검색', 1), ('폰', 1), ('건가', 1)]\n","Version 1.4: [('지도', 1), ('기반', 1), ('부동산', 1), ('뭔가', 1), ('갈수록', 1), ('안정화', 1), ('느낌', 1), ('드네', 1), (nan, 1), ('짱', 1)]\n","Version 1.40: [('정보', 1), ('실시간', 1), ('부동산', 1), ('어플', 1), ('중', 1), ('쵝오', 1)]\n","Version 1.42: [('검색', 6), ('전', 2), ('알', 2), ('다운', 2), ('베리', 2), ('앱', 1), ('실행', 1), ('선택', 1), ('단계', 1), ('버튼', 1)]\n","Version 1.43: [('신뢰', 2), ('부동산', 2), ('시장', 2), ('실제', 1), ('가격', 1), ('천만원', 1), ('아예', 1), ('매물', 1), ('고', 1), ('나름', 1)]\n","Version 1.44: [('매물', 3), ('그냥', 2), ('볼', 2), ('검색', 2), ('현장', 1), ('직접', 1), ('부동산', 1), ('문의', 1), ('집', 1), ('조보', 1)]\n","Version 1.45: [('최근', 1), ('지도', 1)]\n","Version 1.46: [('정도', 1), ('앱', 1), ('삭제', 1), ('전', 1), ('버전', 1), ('다시', 1), ('거임', 1), (nan, 1), ('집', 1), ('젤', 1)]\n","Version 1.47: [('안', 4), ('부동산', 2), ('뭡', 1), ('누가', 1), ('리', 1), ('보기', 1), ('찾기', 1), ('검색', 1), ('창', 1), ('원룸', 1)]\n","Version 1.48: [('업데이트', 2), ('오류', 1), ('투성이', 1), ('후', 1), ('이미지', 1), ('선택', 1), ('시', 1), ('어플', 1), ('종료', 1), ('네이버', 1)]\n","Version 1.49: [('선택', 3), ('정보', 2), ('아파트', 1), ('주태', 1), ('빌라', 1), ('가지', 1), ('여러', 1), ('형태', 1), ('동시', 1), (nan, 1)]\n","Version 1.5: [('확인', 1), ('매물', 1), ('전화', 1), ('이건', 1), ('뭐', 1), ('뻘', 1), (nan, 1), ('별로', 1), (nan, 1), ('좋넿', 1)]\n","Version 1.50: [(nan, 1)]\n","Version 1.52: [('원룸', 1), (nan, 1), ('앞', 1), ('쭉', 1), ('사용', 1)]\n","Version 1.53: [(nan, 1), ('갑자기', 1), ('다시', 1), ('고', 1), ('매물', 1), ('등록', 1), ('도대체', 1), ('버전', 1), ('조작', 1), ('단', 1)]\n","Version 1.54: [('안', 4), ('지도', 3), ('물건', 2), ('평수', 2), ('네이버', 1), ('부동산', 1), ('보고', 1), ('막상', 1), ('방금', 1), ('전', 1)]\n","Version 1.55: [('정보', 3), ('버전', 2), ('다시', 2), ('중구', 2), ('최고', 2), ('어플', 2), ('아파트', 2), ('시', 2), ('세', 2), ('앱', 2)]\n","Version 1.56: [('계약', 4), ('매물', 2), ('물건', 2), ('완료', 2), ('후', 2), ('삭제', 2), ('달', 1), ('전', 1), ('집', 1), ('쓰기', 1)]\n","Version 1.57: [('부동산', 6), ('집', 6), ('매물', 4), ('직접', 4), ('어플', 3), ('네이버', 3), ('지도', 3), ('가격', 3), ('전', 3), ('돈', 2)]\n","Version 1.58: [('앱', 5), ('매물', 4), ('지도', 3), ('사용', 3), ('부동산', 3), ('물건', 3), ('정보', 3), ('버전', 2), ('얼굴', 2), ('사진', 2)]\n","Version 1.59: [('앱', 2), ('어플', 2), ('항상', 2), ('치', 1), ('계속', 1), ('종료', 1), ('다시', 1), ('마찬가지', 1), ('처음', 1), ('리뷰', 1)]\n","Version 1.6: [('지도', 1), ('업데이트', 1), ('해', 1)]\n","Version 1.60: [('부동산', 12), ('지도', 5), ('정보', 5), ('네이버', 4), ('확인', 3), ('허위', 2), ('매물', 2), ('갤럭시', 2), ('내', 2), ('집', 2)]\n","Version 1.61: [('뷰', 8), ('글자', 7), ('로드', 6), ('노트', 5), ('보고', 5), ('수정', 4), ('글씨', 3), ('지도', 2), ('번', 2), ('다시', 2)]\n","Version 1.62: [('지도', 3), ('안', 3), ('실행', 2), ('매물', 2), ('뷰', 2), ('시세', 2), ('어플', 1), ('중지', 1), ('메세지', 1), ('해결', 1)]\n","Version 1.63: [('버전', 32), ('업데이트', 24), ('부동산', 21), ('앱', 21), ('안', 18), ('네이버', 15), ('매물', 14), ('지도', 12), ('어플', 9), ('사람', 9)]\n","Version 1.7: [('아주', 1), ('성능', 1), ('우수', 1), ('무료', 1), ('욕', 1), ('네이버', 1)]\n","Version 1.8: [('매물', 2), ('줄', 1), ('루', 1), ('사용', 1), ('중', 1), ('튕김', 1), ('위치', 1), ('선택', 1), ('데', 1), ('가요', 1)]\n","Version 1.9: [('주소', 1), ('설정', 1), ('계속', 1), ('다시', 1), ('설치', 1), ('두', 1), ('현상', 1), ('동의', 1), ('창', 1), ('요즘', 1)]\n","Version 2.0: [('버전', 250), ('업데이트', 203), ('안', 189), ('앱', 163), ('전', 151), ('최악', 135), ('매물', 119), ('보기', 90), ('어플', 88), ('네이버', 86)]\n","Version 2.1: [('안', 23), ('매물', 21), ('앱', 15), ('사진', 10), ('검색', 9), ('어플', 7), ('일시', 7), ('위치', 6), ('다시', 5), ('네이버', 5)]\n","Version 2.2: [('안', 60), ('매물', 55), ('앱', 45), ('화면', 43), ('부동산', 36), ('네이버', 35), ('업데이트', 26), ('관심', 24), ('허위', 23), ('오류', 22)]\n","Version 2.3: [('매물', 12), ('안', 11), ('네이버', 11), ('부동산', 11), ('앱', 10), ('어플', 9), ('허위', 7), ('업데이트', 6), ('보기', 6), ('사용', 5)]\n","Version 2.4: [('매물', 146), ('앱', 141), ('안', 137), ('뒤', 92), ('업데이트', 84), ('부동산', 78), ('어플', 66), ('네이버', 57), ('지도', 50), ('화면', 49)]\n","Version [('520', 'Number'), ('가구', 'Noun'), ('인데', 'Josa'), ('5200', 'Number'), ('가구', 'Noun'), ('로', 'Josa'), ('뜨고', 'Verb'), ('다', 'Adverb'), ('0', 'Number'), ('이', 'Noun'), ('하나', 'Noun'), ('씩', 'Suffix'), ('붙어서', 'Verb'), ('나와', 'Verb'), ('요', 'Noun'), ('빨리', 'Adverb'), ('오류', 'Noun'), ('수정', 'Noun'), ('해주세요', 'Verb')]: [(nan, 1)]\n","Processing 피터팬...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-cca63738fd21>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['reviewCreatedVersion'] = data_cleaned['reviewCreatedVersion'].astype(str)\n","<ipython-input-2-cca63738fd21>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['grouped_version'] = data_cleaned['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n"]},{"output_type":"stream","name":"stdout","text":["피터팬: 버전별 주요 단어:\n","Version 1.0: [('앱', 326), ('대박', 300), ('집', 298), ('어플', 262), ('방', 196), ('정보', 169), ('최고', 116), ('보기', 100), ('볼', 95), ('추천', 83)]\n","Version 1.1: [('매물', 21), ('어플', 12), ('안', 9), ('집', 8), ('등록', 8), ('방', 6), ('전', 6), ('계속', 6), ('연락', 5), ('앱', 5)]\n","Version 1.2: [('매물', 21), ('안', 18), ('삭제', 9), ('집', 8), ('주소', 6), ('허위', 6), ('방', 6), ('전화', 5), ('처리', 5), ('등록', 5)]\n","Version 2.0: [('매물', 5), ('앱', 3), ('때문', 2), ('비', 2), ('세상', 2), ('만', 2), ('연락', 2), ('삭제', 2), ('구미', 1), ('정투', 1)]\n","Version 2.1: [('직거래', 18), ('피터팬', 11), ('안심', 11), ('앱', 11), ('사용', 8), ('방', 8), ('어플', 7), ('정보', 7), ('안', 5), ('매물', 5)]\n","Version 2.10: [('매물', 20), ('허위', 10), ('방', 7), ('사용', 5), ('직거래', 5), ('부동산', 5), ('앱', 5), ('안', 4), ('안심', 4), ('보고', 4)]\n","Version 2.11: [('매물', 76), ('허위', 38), ('방', 36), ('앱', 34), ('안', 23), ('부동산', 17), ('어플', 16), ('피터팬', 14), ('연락', 13), ('직거래', 13)]\n","Version 2.12: [('매물', 82), ('허위', 50), ('안', 49), ('어플', 24), ('방', 24), ('부동산', 22), ('앱', 19), ('연락', 18), ('집', 13), ('신고', 12)]\n","Version 2.13: [('매물', 79), ('허위', 63), ('안', 26), ('방', 20), ('앱', 18), ('피터팬', 17), ('부동산', 15), ('어플', 15), ('삭제', 14), ('신고', 11)]\n","Version 2.14: [('매물', 277), ('허위', 155), ('안', 129), ('부동산', 70), ('앱', 68), ('어플', 59), ('방', 56), ('피터팬', 50), ('집', 38), ('신고', 37)]\n","Version 2.15: [('매물', 94), ('허위', 49), ('안', 39), ('앱', 26), ('집', 22), ('필터', 21), ('방', 19), ('어플', 18), ('검색', 17), ('부동산', 14)]\n","Version 2.16: [('안', 10), ('매물', 7), ('문의', 5), ('허위', 3), ('글', 3), ('방', 3), ('어플', 3), ('다시', 3), ('연락', 3), ('계속', 2)]\n","Version 2.17: [('매물', 29), ('허위', 12), ('방', 8), ('안', 6), ('부동산', 6), ('다방', 4), ('그냥', 4), ('직접', 4), ('집', 4), ('인증', 3)]\n","Version 2.18: [('필터', 11), ('안', 11), ('매물', 9), ('적용', 7), ('방', 5), ('전세', 5), ('앱', 4), ('허위', 4), ('채팅', 4), ('개편', 4)]\n","Version 2.19: [('매물', 8), ('앱', 4), ('해', 3), ('찜', 3), ('등록', 2), ('수정', 2), ('추가', 2), ('실행', 2), ('점', 2), ('보고', 2)]\n","Version 2.2: [('정보', 5), ('매물', 3), ('허위', 2), ('거래', 2), ('방', 2), ('사람', 2), ('수가', 2), ('지도', 2), ('공유', 2), ('믿음', 1)]\n","Version 2.20: [('매물', 13), ('안', 12), ('어플', 11), ('앱', 9), ('허위', 8), ('사용', 5), ('등록', 4), ('정보', 4), ('방', 4), ('집', 4)]\n","Version 2.3: [('매물', 5), ('앱', 3), ('카페', 3), ('사진', 3), ('연락', 2), ('관리', 2), ('허위', 2), ('부동산', 2), ('홍보', 2), ('용', 2)]\n","Version 2.4: [('매물', 118), ('허위', 72), ('안', 55), ('방', 53), ('부동산', 44), ('직거래', 38), ('어플', 35), ('앱', 33), ('집', 27), ('피터팬', 27)]\n","Version 2.9: [('매물', 8), ('허위', 5), ('방', 5), ('계약', 4), ('안', 4), ('전화', 3), ('집', 3), ('부동산', 3), ('가격', 2), ('사진', 2)]\n","Processing 호갱노노...\n","호갱노노: 버전별 주요 단어:\n","Version 1.0: [('어플', 22), ('최고', 15), ('정보', 12), ('부동산', 11), ('앱', 10), ('가격', 9), ('거래', 5), ('시세', 5), ('집', 5), ('웹', 5)]\n","Version 1.1: [('가격', 2), ('파악', 2), ('어린이집', 1), ('표시', 1), ('기본', 1), ('제외', 1), ('버벅거려', 1), ('년도', 1), ('동시', 1), ('볼', 1)]\n","Version 1.2: [('정보', 6), ('앱', 4), ('부동산', 3), ('최고', 3), ('실', 2), ('거래', 2), ('파악', 2), ('특목고', 2), ('진학', 2), ('정원', 2)]\n","Version 1.3: [('일시', 1), ('오류', 1), ('하루', 1), ('종일', 1), ('가요', 1), ('지도', 1), ('확인', 1), ('가장', 1), ('장점', 1), ('사람', 1)]\n","Version 1.4: [('앱', 4), ('최고', 4), ('주택', 3), ('지역', 3), ('어플', 3), ('빌라', 2), ('안', 2), ('부동산', 2), ('추가', 2), ('현', 2)]\n","Version 1.5: [('정보', 11), ('부동산', 11), ('어플', 8), ('아파트', 6), ('실', 6), ('거래', 6), ('지도', 5), ('안', 5), ('앱', 5), ('오류', 4)]\n","Version 1.6: [('어플', 6), ('표시', 6), ('정보', 5), ('아파트', 4), ('번', 3), ('부분', 3), ('사용', 3), ('안', 2), ('거리', 2), ('초', 2)]\n","Version 1.7: [('앱', 45), ('최고', 42), ('정보', 39), ('안', 37), ('아파트', 33), ('부동산', 30), ('거래', 24), ('실', 19), ('매물', 18), ('분양', 15)]\n","Version 1.8: [('아파트', 202), ('안', 174), ('앱', 157), ('정보', 144), ('거래', 136), ('실', 115), ('호갱', 88), ('부동산', 78), ('어플', 75), ('글', 70)]\n","Version 1.9: [('안', 96), ('아파트', 91), ('글', 69), ('어플', 67), ('호갱', 65), ('앱', 56), ('정보', 49), ('노노', 46), ('사람', 45), ('거래', 34)]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-cca63738fd21>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['reviewCreatedVersion'] = data_cleaned['reviewCreatedVersion'].astype(str)\n","<ipython-input-2-cca63738fd21>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_cleaned['grouped_version'] = data_cleaned['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n"]}]},{"cell_type":"markdown","source":["## 코드 설명\n","\n","데이터 그룹화:\n","\n","- 데이터를 grouped_version 기준으로 그룹화하여 각 버전별로 독립적으로 모델링.\n","\n","버전별 모델 학습:\n","\n","각 버전에 대해:\n","- 텍스트 데이터를 TF-IDF로 벡터화.\n","- 별점(score)을 종속 변수로 사용하여 RandomForestRegressor 학습.\n","- MSE와 R2 Score로 성능 평가.\n","\n","중요 피처 분석:\n","\n","- 각 버전에서 예측에 기여한 상위 중요한 단어를 분석.\n","데이터가 부족한 버전 스킵:\n","\n","- 10개 미만의 리뷰를 가진 버전은 분석에서 제외하여 안정적인 결과를 보장.\n","\n","결과 저장 및 출력:\n","\n","- model_results에 앱별로 버전별 결과를 저장.\n","- 모든 버전에 대해 MSE, R2 Score, 상위 중요한 단어를 출력.\n"],"metadata":{"id":"UAnrW8qV2jYH"}},{"cell_type":"code","source":[],"metadata":{"id":"sYBup5Z71lgP","executionInfo":{"status":"ok","timestamp":1733810371522,"user_tz":-540,"elapsed":2,"user":{"displayName":"Soobin","userId":"01300891231025069619"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["네이버 파일에 문제가 있는거같음\n","- column 확인결과 column에 텍스트토큰화한게 포함된게 2 행 있어서 제거함."],"metadata":{"id":"lZLH611t3Pj8"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# 파일 경로 설정\n","file_path = os.path.join(data_path, \"preprocessed2_reviews_data_네이버부동산_별점.csv\")\n","\n","# 파일 읽기\n","if os.path.exists(file_path):\n","    print(\"Reading the file...\")\n","    data = pd.read_csv(file_path)\n","\n","    # reviewCreatedVersion 열의 고유 값 확인\n","    if 'reviewCreatedVersion' in data.columns:\n","        unique_versions = data['reviewCreatedVersion'].dropna().unique()\n","        print(f\"총 {len(unique_versions)}개의 고유 버전이 있습니다:\")\n","        for version in sorted(unique_versions):\n","            print(version)\n","    else:\n","        print(\"'reviewCreatedVersion' 열이 데이터에 없습니다.\")\n","else:\n","    print(f\"파일을 찾을 수 없습니다: {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-nBg3Zk3RMT","executionInfo":{"status":"ok","timestamp":1733810371968,"user_tz":-540,"elapsed":12,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"4bc74f37-4dd4-48f7-f444-27931dc7cad0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading the file...\n","총 80개의 고유 버전이 있습니다:\n"," '등록'\n","1.0.0\n","1.0.1\n","1.1.0\n","1.11.0\n","1.12.0\n","1.13.0\n","1.16.0\n","1.17.0\n","1.2.0\n","1.22.0\n","1.24.0\n","1.25.0\n","1.26.0\n","1.27.0\n","1.28.0\n","1.29.0\n","1.3.0\n","1.30.0\n","1.32.0\n","1.33.0\n","1.34.0\n","1.36.0\n","1.37.0\n","1.38.0\n","1.39.0\n","1.4.0\n","1.40.0\n","1.42.0\n","1.43.0\n","1.44.0\n","1.45.0\n","1.46.0\n","1.47.0\n","1.48.0\n","1.49.0\n","1.5.0\n","1.50.0\n","1.52.0\n","1.53.0\n","1.54.0\n","1.55.0\n","1.56.0\n","1.57.0\n","1.58.0\n","1.59.0\n","1.6.0\n","1.60.0\n","1.61.0\n","1.62.0\n","1.63.0\n","1.7.0\n","1.8.0\n","1.9.0\n","2.0.1\n","2.0.2\n","2.0.3\n","2.0.4\n","2.0.5\n","2.0.6\n","2.0.7\n","2.0.8\n","2.0.9\n","2.1.0\n","2.1.1\n","2.2.0\n","2.2.1\n","2.3.1\n","2.4.0\n","2.4.1\n","2.4.11\n","2.4.12\n","2.4.13\n","2.4.2\n","2.4.3\n","2.4.4\n","2.4.7\n","2.4.8\n","2.4.9\n","[('520', 'Number'), ('가구', 'Noun'), ('인데', 'Josa'), ('5200', 'Number'), ('가구', 'Noun'), ('로', 'Josa'), ('뜨고', 'Verb'), ('다', 'Adverb'), ('0', 'Number'), ('이', 'Noun'), ('하나', 'Noun'), ('씩', 'Suffix'), ('붙어서', 'Verb'), ('나와', 'Verb'), ('요', 'Noun'), ('빨리', 'Adverb'), ('오류', 'Noun'), ('수정', 'Noun'), ('해주세요', 'Verb')]\n"]}]},{"cell_type":"code","source":["if 'reviewCreatedVersion' in data.columns:\n","    # reviewCreatedVersion 열에 문자열이 아닌 데이터가 있는지 확인\n","    print(f\"'reviewCreatedVersion' 열의 데이터 타입: {data['reviewCreatedVersion'].dtype}\")\n","    print(\"열 내용 샘플:\")\n","    print(data['reviewCreatedVersion'].head())\n","\n","    # 결측치와 고유 값 확인\n","    unique_versions = data['reviewCreatedVersion'].dropna().unique()\n","    print(f\"총 {len(unique_versions)}개의 고유 버전이 있습니다:\")\n","    for version in sorted(unique_versions):\n","        print(version)\n","else:\n","    print(\"'reviewCreatedVersion' 열이 데이터에 없습니다.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dS7iXq-h4Sad","executionInfo":{"status":"ok","timestamp":1733810371969,"user_tz":-540,"elapsed":11,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"86037e13-ac9e-4832-b0cf-bfbb9389067c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["'reviewCreatedVersion' 열의 데이터 타입: object\n","열 내용 샘플:\n","0    2.4.13\n","1     2.4.8\n","2    2.4.11\n","3     2.4.9\n","4     2.2.0\n","Name: reviewCreatedVersion, dtype: object\n","총 80개의 고유 버전이 있습니다:\n"," '등록'\n","1.0.0\n","1.0.1\n","1.1.0\n","1.11.0\n","1.12.0\n","1.13.0\n","1.16.0\n","1.17.0\n","1.2.0\n","1.22.0\n","1.24.0\n","1.25.0\n","1.26.0\n","1.27.0\n","1.28.0\n","1.29.0\n","1.3.0\n","1.30.0\n","1.32.0\n","1.33.0\n","1.34.0\n","1.36.0\n","1.37.0\n","1.38.0\n","1.39.0\n","1.4.0\n","1.40.0\n","1.42.0\n","1.43.0\n","1.44.0\n","1.45.0\n","1.46.0\n","1.47.0\n","1.48.0\n","1.49.0\n","1.5.0\n","1.50.0\n","1.52.0\n","1.53.0\n","1.54.0\n","1.55.0\n","1.56.0\n","1.57.0\n","1.58.0\n","1.59.0\n","1.6.0\n","1.60.0\n","1.61.0\n","1.62.0\n","1.63.0\n","1.7.0\n","1.8.0\n","1.9.0\n","2.0.1\n","2.0.2\n","2.0.3\n","2.0.4\n","2.0.5\n","2.0.6\n","2.0.7\n","2.0.8\n","2.0.9\n","2.1.0\n","2.1.1\n","2.2.0\n","2.2.1\n","2.3.1\n","2.4.0\n","2.4.1\n","2.4.11\n","2.4.12\n","2.4.13\n","2.4.2\n","2.4.3\n","2.4.4\n","2.4.7\n","2.4.8\n","2.4.9\n","[('520', 'Number'), ('가구', 'Noun'), ('인데', 'Josa'), ('5200', 'Number'), ('가구', 'Noun'), ('로', 'Josa'), ('뜨고', 'Verb'), ('다', 'Adverb'), ('0', 'Number'), ('이', 'Noun'), ('하나', 'Noun'), ('씩', 'Suffix'), ('붙어서', 'Verb'), ('나와', 'Verb'), ('요', 'Noun'), ('빨리', 'Adverb'), ('오류', 'Noun'), ('수정', 'Noun'), ('해주세요', 'Verb')]\n"]}]},{"cell_type":"markdown","source":["## processed2 네이버 파일에 이상한 값들이 있어요,,,, 이게 대체 어디서 나온걸지 확인을 해봐야할듯 합니다."],"metadata":{"id":"KZrqwxsm5CIb"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# 파일 경로 설정\n","file_path = os.path.join(data_path, \"preprocessed2_reviews_data_네이버부동산_별점.csv\")\n","\n","# 검색할 데이터 (리스트 형태로 입력된 데이터)\n","target_data = \"[('520', 'Number'), ('가구', 'Noun'), ('인데', 'Josa'), ('5200', 'Number'), ('가구', 'Noun'), ('로', 'Josa'), ('뜨고', 'Verb'), ('다', 'Adverb'), ('0', 'Number'), ('이', 'Noun'), ('하나', 'Noun'), ('씩', 'Suffix'), ('붙어서', 'Verb'), ('나와', 'Verb'), ('요', 'Noun'), ('빨리', 'Adverb'), ('오류', 'Noun'), ('수정', 'Noun'), ('해주세요', 'Verb')]\"\n","\n","# 파일 읽기\n","if os.path.exists(file_path):\n","    print(\"Reading the file...\")\n","    data = pd.read_csv(file_path)\n","\n","    # 열 이름 확인\n","    print(\"Columns:\", data.columns)\n","\n","    # 검색 대상 열 설정 (가장 가능성 높은 열 지정)\n","    search_column = 'reviewCreatedVersion'  # or 다른 열 이름 (예: 'nouns_without_stopwords')\n","\n","    if search_column in data.columns:\n","        # 해당 데이터가 포함된 행 필터링\n","        matching_rows = data[data[search_column].astype(str) == target_data]\n","\n","        if not matching_rows.empty:\n","            print(f\"총 {len(matching_rows)}개의 행에서 일치하는 데이터가 발견되었습니다.\")\n","            print(\"행 인덱스:\")\n","            print(matching_rows.index.tolist())\n","            print(\"\\n일치하는 행 데이터:\")\n","            print(matching_rows)\n","        else:\n","            print(\"일치하는 데이터가 없습니다.\")\n","    else:\n","        print(f\"'{search_column}' 열이 데이터에 없습니다.\")\n","else:\n","    print(f\"파일을 찾을 수 없습니다: {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95Zh_5mK5IRs","executionInfo":{"status":"ok","timestamp":1733810371969,"user_tz":-540,"elapsed":8,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"91162579-81b9-458c-a029-26631a50711a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading the file...\n","Columns: Index(['reviewId', 'userName', 'userImage', 'content', 'score',\n","       'thumbsUpCount', 'reviewCreatedVersion', 'at', 'replyContent',\n","       'repliedAt', 'appVersion', 'content_preprocessed', 'content_token',\n","       'content_pos', 'nouns_only', 'nouns_without_stopwords'],\n","      dtype='object')\n","총 1개의 행에서 일치하는 데이터가 발견되었습니다.\n","행 인덱스:\n","[1895]\n","\n","일치하는 행 데이터:\n","       reviewId                  userName            userImage content  score  \\\n","1895  문제점을 수정하여   현재는 정상적으로 이용하실 수 있습니다.\"  2014-05-08 11:18:10  1.52.0    NaN   \n","\n","      thumbsUpCount                               reviewCreatedVersion   at  \\\n","1895            NaN  [('520', 'Number'), ('가구', 'Noun'), ('인데', 'Jo...  NaN   \n","\n","     replyContent repliedAt appVersion content_preprocessed content_token  \\\n","1895          NaN       NaN        NaN                  NaN           NaN   \n","\n","     content_pos nouns_only nouns_without_stopwords  \n","1895          []         []                      []  \n"]}]},{"cell_type":"markdown","source":["아,, 실제로 데이터 확인해보니 진짜 이상한게 포함되어있기는 합니다.\n","전처리하는과정에서 그 부분만 잠시 오류가 있었던것 가타요. 결측치 제거해야겟다.\n","\n"],"metadata":{"id":"ZD4PKPQB5m-n"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# 파일 경로 설정\n","file_path = os.path.join(data_path, \"preprocessed2_reviews_data_네이버부동산_별점.csv\")\n","output_file_path = os.path.join(output_path, \"cleaned_네이버부동산_별점.csv\")\n","\n","# 제거할 값 정의\n","values_to_remove = [\n","    \"[('520', 'Number'), ('가구', 'Noun'), ('인데', 'Josa'), ('5200', 'Number'), ('가구', 'Noun'), ('로', 'Josa'), ('뜨고', 'Verb'), ('다', 'Adverb'), ('0', 'Number'), ('이', 'Noun'), ('하나', 'Noun'), ('씩', 'Suffix'), ('붙어서', 'Verb'), ('나와', 'Verb'), ('요', 'Noun'), ('빨리', 'Adverb'), ('오류', 'Noun'), ('수정', 'Noun'), ('해주세요', 'Verb')]\",\n","    \" '등록'\"\n","]\n","\n","# 파일 읽기\n","if os.path.exists(file_path):\n","    print(\"Reading the file...\")\n","    data = pd.read_csv(file_path)\n","\n","    # 열 확인\n","    if 'reviewCreatedVersion' in data.columns:\n","        print(\"Cleaning reviewCreatedVersion...\")\n","\n","        # Null 값과 특정 값을 제거\n","        cleaned_data = data[~data['reviewCreatedVersion'].isnull()]  # Null 값 제거\n","        cleaned_data = cleaned_data[~cleaned_data['reviewCreatedVersion'].astype(str).isin(values_to_remove)]  # 특정 값 제거\n","\n","        # 결과 저장\n","        cleaned_data.to_csv(output_file_path, index=False)\n","        print(f\"Cleaned data saved to: {output_file_path}\")\n","    else:\n","        print(\"'reviewCreatedVersion' 열이 데이터에 없습니다.\")\n","else:\n","    print(f\"파일을 찾을 수 없습니다: {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3IhWocT5vlY","executionInfo":{"status":"ok","timestamp":1733810374490,"user_tz":-540,"elapsed":1480,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"bdd9cb63-bc3f-417f-ad2a-aa7fcca67c00"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading the file...\n","Cleaning reviewCreatedVersion...\n","Cleaned data saved to: /content/drive/MyDrive/2024/TextMining/reviewmodel/cleaned_네이버부동산_별점.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# 데이터 경로 설정\n","data_path = '/content/drive/MyDrive/2024/TextMining/reviews_data'\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","os.makedirs(output_path, exist_ok=True)  # 결과 저장 폴더 생성\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['피터팬', '호갱노노']\n","files = {app: os.path.join(data_path, f\"preprocessed2_reviews_data_{app}_별점.csv\") for app in selected_apps}\n","\n","# 파일 처리\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 파일 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # Null 값 제거\n","        if 'reviewCreatedVersion' in data.columns:\n","            cleaned_data = data.dropna(subset=['reviewCreatedVersion'])  # NaN 값 제거\n","\n","            # 결과 저장\n","            output_file_path = os.path.join(output_path, f\"cleaned_{app}_별점.csv\")\n","            cleaned_data.to_csv(output_file_path, index=False)\n","            print(f\"Cleaned data for {app} saved to: {output_file_path}\")\n","        else:\n","            print(f\"'reviewCreatedVersion' 열이 {app} 데이터에 없습니다.\")\n","    else:\n","        print(f\"File for {app} not found: {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGCiBgea7AHZ","executionInfo":{"status":"ok","timestamp":1733810377167,"user_tz":-540,"elapsed":2685,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"0a82f164-0493-473a-d0dd-42a5e22bac65"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 피터팬...\n","Cleaned data for 피터팬 saved to: /content/drive/MyDrive/2024/TextMining/reviewmodel/cleaned_피터팬_별점.csv\n","Processing 호갱노노...\n","Cleaned data for 호갱노노 saved to: /content/drive/MyDrive/2024/TextMining/reviewmodel/cleaned_호갱노노_별점.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['다방', '직방', '네이버부동산', '피터팬', '호갱노노']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 파일별 고유 값 확인\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Checking 'reviewCreatedVersion' for {app}...\")\n","\n","        # 파일 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # reviewCreatedVersion 열의 고유 값 확인\n","        if 'reviewCreatedVersion' in data.columns:\n","            unique_versions = data['reviewCreatedVersion'].dropna().unique()\n","            print(f\"{app} - reviewCreatedVersion에 포함된 고유 값:\")\n","            for version in sorted(unique_versions):\n","                print(version)\n","            print(f\"총 {len(unique_versions)}개의 고유 값이 있습니다.\\n\")\n","        else:\n","            print(f\"'reviewCreatedVersion' 열이 {app} 데이터에 없습니다.\\n\")\n","    else:\n","        print(f\"File for {app} not found: {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13LctKxq8X-C","executionInfo":{"status":"ok","timestamp":1733810398583,"user_tz":-540,"elapsed":4436,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"8f8aff29-ac24-49cd-fbda-9bb75104329c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Checking 'reviewCreatedVersion' for 다방...\n","다방 - reviewCreatedVersion에 포함된 고유 값:\n","1.0\n","1.0.1\n","1.0.2\n","1.1.1\n","1.2.0\n","1.3.0\n","1.4.1\n","1.5\n","1.6\n","1.7\n","1.8\n","1.9\n","2.0\n","2.1\n","2.10.0\n","2.11.3\n","2.11.4\n","2.12.2\n","2.12.3\n","2.13.4\n","2.13.5\n","2.13.6\n","2.14.4\n","2.14.5\n","2.15.5\n","2.16.2\n","2.17.2\n","2.17.3\n","2.18.1\n","2.18.2\n","2.18.3\n","2.2\n","2.2.1\n","2.2.2\n","2.3\n","2.3.1\n","2.3.2\n","2.3.3\n","2.3.4\n","2.4\n","2.4.1\n","2.4.10\n","2.4.10.1\n","2.4.11\n","2.4.2\n","2.4.3\n","2.4.4\n","2.4.5\n","2.4.6\n","2.4.7\n","2.4.7.1\n","2.4.8\n","2.4.9\n","2.5\n","2.5.1\n","2.5.2\n","2.6\n","2.6.1\n","2.6.3\n","2.6.4\n","2.6.6\n","2.7.1\n","2.8.0\n","2.8.4\n","2.9.6\n","3.0.0\n","3.0.1\n","3.0.2\n","3.0.3\n","3.0.4\n","3.1.0\n","3.1.1\n","3.1.2\n","3.1.3\n","3.10.0\n","3.10.1\n","3.10.2\n","3.10.3\n","3.10.4\n","3.10.5\n","3.10.6\n","3.10.7\n","3.10.8\n","3.2.0\n","3.2.1\n","3.2.2\n","3.2.3\n","3.2.4\n","3.2.5\n","3.2.6\n","3.2.7\n","3.3.0\n","3.3.1\n","3.3.2\n","3.3.3\n","3.3.4\n","3.3.5\n","3.3.6\n","3.3.7\n","3.3.8\n","3.4.0\n","3.4.1\n","3.5.0\n","3.5.2\n","3.6.0\n","3.6.1\n","3.7.0\n","3.8.0\n","3.9.0\n","3.9.1\n","3.9.2\n","3.9.3\n","3.9.4\n","4.0.0\n","4.0.1\n","4.0.2\n","4.1.0\n","4.10.0\n","4.10.1\n","4.10.2\n","4.11.0\n","4.11.1\n","4.12.0\n","4.12.1\n","4.12.2\n","4.13.2\n","4.13.4\n","4.13.5\n","4.13.6\n","4.14.2\n","4.14.3\n","4.14.4\n","4.14.5\n","4.14.6\n","4.15.0\n","4.15.1\n","4.15.2\n","4.15.3\n","4.15.5\n","4.16.0\n","4.16.1\n","4.16.2\n","4.17.1\n","4.17.2\n","4.18.0\n","4.18.1\n","4.18.2\n","4.18.3\n","4.19.0\n","4.2.0\n","4.2.1\n","4.2.2\n","4.20.0\n","4.3.0\n","4.3.1\n","4.3.2\n","4.3.3\n","4.4.0\n","4.4.1\n","4.4.2\n","4.5.0\n","4.6.0\n","4.6.1\n","4.6.2\n","4.7.0\n","4.8.0\n","4.9.0\n","4.9.1\n","5.0.0\n","5.0.1\n","5.0.10\n","5.0.11\n","5.0.12\n","5.0.3\n","5.0.4\n","5.0.5\n","5.0.6\n","5.0.8\n","5.0.9\n","총 179개의 고유 값이 있습니다.\n","\n","Checking 'reviewCreatedVersion' for 직방...\n","직방 - reviewCreatedVersion에 포함된 고유 값:\n","1.0.1\n","1.1\n","1.1.4\n","3.0.1\n","3.0.2\n","3.0.5\n","3.0.6\n","3.0.8\n","4.0.0\n","4.0.1\n","4.0.2\n","4.0.3\n","4.0.5\n","4.0.6\n","4.1.0\n","4.1.1\n","4.1.2\n","4.1.4\n","4.1.5\n","4.1.6\n","4.1.7\n","4.1.8\n","4.1.9\n","4.10.0\n","4.10.1\n","4.10.10\n","4.10.11\n","4.10.12\n","4.10.13\n","4.10.14\n","4.10.15\n","4.10.16\n","4.10.17\n","4.10.19\n","4.10.2\n","4.10.20\n","4.10.21\n","4.10.22\n","4.10.23\n","4.10.24\n","4.10.25\n","4.10.26\n","4.10.27\n","4.10.28\n","4.10.29\n","4.10.3\n","4.10.30\n","4.10.31\n","4.10.32\n","4.10.33\n","4.10.35\n","4.10.36\n","4.10.37\n","4.10.38\n","4.10.39\n","4.10.4\n","4.10.40\n","4.10.41\n","4.10.43\n","4.10.5\n","4.10.6\n","4.10.7\n","4.10.8\n","4.10.9\n","4.11.0\n","4.11.1\n","4.11.2\n","4.12.0\n","4.12.1\n","4.12.10\n","4.12.2\n","4.12.3\n","4.12.4\n","4.12.5\n","4.12.6\n","4.12.7\n","4.12.8\n","4.12.9\n","4.13.0\n","4.13.1\n","4.13.10\n","4.13.11\n","4.13.12\n","4.13.13\n","4.13.14\n","4.13.15\n","4.13.16\n","4.13.17\n","4.13.18\n","4.13.19\n","4.13.21\n","4.13.22\n","4.13.23\n","4.13.24\n","4.13.25\n","4.13.26\n","4.13.27\n","4.13.28\n","4.13.29\n","4.13.3\n","4.13.30\n","4.13.31\n","4.13.32\n","4.13.33\n","4.13.34\n","4.13.35\n","4.13.5\n","4.13.6\n","4.13.7\n","4.13.9\n","4.14.1\n","4.14.2\n","4.14.3\n","4.14.4\n","4.15.0\n","4.15.1\n","4.15.10\n","4.15.11\n","4.15.12\n","4.15.13\n","4.15.14\n","4.15.2\n","4.15.3\n","4.15.4\n","4.15.5\n","4.15.6\n","4.15.7\n","4.15.8\n","4.15.9\n","4.2.0\n","4.2.1\n","4.2.10\n","4.2.11\n","4.2.12\n","4.2.2\n","4.2.20140728\n","4.2.20140729\n","4.2.3\n","4.2.4\n","4.2.5\n","4.2.6\n","4.2.7\n","4.2.8\n","4.2.9\n","4.5.20140801\n","4.6.20140811\n","4.6.20140812\n","4.6.20140813\n","4.6.20140819\n","4.7.20140904\n","4.8.20140911\n","4.8.20140926\n","4.8.20140927\n","4.8.20140929\n","4.8.20141015\n","4.8.20141023\n","4.9.0\n","4.9.10\n","4.9.11\n","4.9.12\n","4.9.13\n","4.9.14\n","4.9.15\n","4.9.16\n","4.9.17\n","4.9.18\n","4.9.19\n","4.9.2\n","4.9.20\n","4.9.21\n","4.9.22\n","4.9.24\n","4.9.25\n","4.9.26\n","4.9.27\n","4.9.28\n","4.9.29\n","4.9.3\n","4.9.30\n","4.9.31\n","4.9.33\n","4.9.34\n","4.9.35\n","4.9.36\n","4.9.37\n","4.9.39\n","4.9.4\n","4.9.40\n","4.9.41\n","4.9.42\n","4.9.43\n","4.9.44\n","4.9.46\n","4.9.47\n","4.9.49\n","4.9.50\n","4.9.51\n","4.9.52\n","4.9.53\n","4.9.54\n","4.9.55\n","4.9.56\n","4.9.57\n","4.9.58\n","4.9.59\n","4.9.6\n","4.9.61\n","4.9.62\n","4.9.63\n","4.9.64\n","4.9.65\n","4.9.66\n","4.9.67\n","4.9.68\n","4.9.69\n","4.9.7\n","4.9.70\n","4.9.8\n","4.9.9\n","5.0.0\n","5.0.1\n","5.0.10\n","5.0.11\n","5.0.12\n","5.0.13\n","5.0.14\n","5.0.15\n","5.0.16\n","5.0.2\n","5.0.3\n","5.0.4\n","5.0.5\n","5.0.6\n","5.0.7\n","5.0.8\n","5.0.9\n","5.1.0\n","5.1.1\n","5.1.10\n","5.1.11\n","5.1.12\n","5.1.13\n","5.1.14\n","5.1.16\n","5.1.17\n","5.1.3\n","5.1.4\n","5.1.5\n","5.1.6\n","5.1.7\n","5.1.9\n","5.10.1\n","5.10.10\n","5.10.11\n","5.10.12\n","5.10.13\n","5.10.2\n","5.10.3\n","5.10.4\n","5.10.6\n","5.10.8\n","5.10.9\n","5.11.0\n","5.11.1\n","5.11.10\n","5.11.11\n","5.11.12\n","5.11.13\n","5.11.14\n","5.11.15\n","5.11.17\n","5.11.19\n","5.11.2\n","5.11.20\n","5.11.3\n","5.11.4\n","5.11.6\n","5.11.7\n","5.11.8\n","5.11.9\n","5.12.0\n","5.12.1\n","5.12.2\n","5.12.3\n","5.12.4\n","5.12.5\n","5.12.6\n","5.12.7\n","5.12.8\n","5.12.9\n","5.13.0\n","5.13.1\n","5.13.2\n","5.13.3\n","5.13.4\n","5.13.5\n","5.13.6\n","5.14.0\n","5.2.0\n","5.2.1\n","5.2.10\n","5.2.11\n","5.2.12\n","5.2.2\n","5.2.3\n","5.2.4\n","5.2.5\n","5.2.6\n","5.2.7\n","5.2.8\n","5.3.1\n","5.3.10\n","5.3.11\n","5.3.12\n","5.3.13\n","5.3.14\n","5.3.15\n","5.3.16\n","5.3.17\n","5.3.18\n","5.3.19\n","5.3.2\n","5.3.20\n","5.3.21\n","5.3.22\n","5.3.23\n","5.3.24\n","5.3.25\n","5.3.26\n","5.3.3\n","5.3.4\n","5.3.5\n","5.3.6\n","5.3.7\n","5.3.8\n","5.3.9\n","5.4.1\n","5.4.3\n","5.4.4\n","5.4.5\n","5.4.6\n","5.4.7\n","5.4.8\n","5.5.0\n","5.6.0\n","5.6.1\n","5.6.2\n","5.6.3\n","5.6.4\n","5.6.5\n","5.6.6\n","5.6.7\n","5.6.8\n","5.6.9\n","5.7.0\n","5.7.1\n","5.7.10\n","5.7.11\n","5.7.12\n","5.7.13\n","5.7.14\n","5.7.15\n","5.7.16\n","5.7.17\n","5.7.18\n","5.7.19\n","5.7.2\n","5.7.3\n","5.7.4\n","5.7.6\n","5.7.7\n","5.7.8\n","5.7.9\n","5.8.0\n","5.8.1\n","5.8.10\n","5.8.11\n","5.8.2\n","5.8.3\n","5.8.4\n","5.8.5\n","5.8.7\n","5.8.8\n","5.8.9\n","5.9.0\n","5.9.10\n","5.9.11\n","5.9.12\n","5.9.13\n","5.9.15\n","5.9.16\n","5.9.17\n","5.9.19\n","5.9.2\n","5.9.3\n","5.9.4\n","5.9.5\n","5.9.8\n","5.9.9\n","총 399개의 고유 값이 있습니다.\n","\n","Checking 'reviewCreatedVersion' for 네이버부동산...\n","네이버부동산 - reviewCreatedVersion에 포함된 고유 값:\n","1.0.0\n","1.0.1\n","1.1.0\n","1.11.0\n","1.12.0\n","1.13.0\n","1.16.0\n","1.17.0\n","1.2.0\n","1.22.0\n","1.24.0\n","1.25.0\n","1.26.0\n","1.27.0\n","1.28.0\n","1.29.0\n","1.3.0\n","1.30.0\n","1.32.0\n","1.33.0\n","1.34.0\n","1.36.0\n","1.37.0\n","1.38.0\n","1.39.0\n","1.4.0\n","1.40.0\n","1.42.0\n","1.43.0\n","1.44.0\n","1.45.0\n","1.46.0\n","1.47.0\n","1.48.0\n","1.49.0\n","1.5.0\n","1.50.0\n","1.52.0\n","1.53.0\n","1.54.0\n","1.55.0\n","1.56.0\n","1.57.0\n","1.58.0\n","1.59.0\n","1.6.0\n","1.60.0\n","1.61.0\n","1.62.0\n","1.63.0\n","1.7.0\n","1.8.0\n","1.9.0\n","2.0.1\n","2.0.2\n","2.0.3\n","2.0.4\n","2.0.5\n","2.0.6\n","2.0.7\n","2.0.8\n","2.0.9\n","2.1.0\n","2.1.1\n","2.2.0\n","2.2.1\n","2.3.1\n","2.4.0\n","2.4.1\n","2.4.11\n","2.4.12\n","2.4.13\n","2.4.2\n","2.4.3\n","2.4.4\n","2.4.7\n","2.4.8\n","2.4.9\n","총 78개의 고유 값이 있습니다.\n","\n","Checking 'reviewCreatedVersion' for 피터팬...\n","피터팬 - reviewCreatedVersion에 포함된 고유 값:\n","1.0.07\n","1.0.08\n","1.0.10\n","1.0.11\n","1.0.12\n","1.0.14\n","1.0.15\n","1.0.16\n","1.0.17\n","1.0.18\n","1.0.19\n","1.0.21\n","1.0.22\n","1.0.24\n","1.0.25\n","1.0.26\n","1.1.00\n","1.1.01\n","1.1.02\n","1.1.03\n","1.1.07\n","1.1.08\n","1.1.09\n","1.1.10\n","1.1.11\n","1.1.12\n","1.1.13\n","1.1.14\n","1.1.16\n","1.2.00\n","1.2.02\n","1.2.04\n","1.2.05\n","1.2.07\n","1.2.08\n","1.2.10\n","1.2.11\n","2.0.0\n","2.0.2\n","2.0.3\n","2.0.4\n","2.0.6\n","2.0.7\n","2.0.9\n","2.1.0\n","2.1.2\n","2.1.3\n","2.1.4\n","2.1.5\n","2.1.6\n","2.1.7\n","2.1.8\n","2.10.2\n","2.10.3\n","2.10.6\n","2.10.7\n","2.11.1\n","2.11.10\n","2.11.11\n","2.11.12\n","2.11.13\n","2.11.3\n","2.11.5\n","2.11.6\n","2.11.7\n","2.11.8\n","2.12.11\n","2.12.12\n","2.12.13\n","2.12.14\n","2.12.15\n","2.12.16\n","2.12.17\n","2.12.18\n","2.12.19\n","2.12.2\n","2.12.4\n","2.12.5\n","2.12.6\n","2.12.7\n","2.12.8\n","2.12.9\n","2.13.0\n","2.13.1\n","2.13.10\n","2.13.11\n","2.13.12\n","2.13.13\n","2.13.14\n","2.13.2\n","2.13.3\n","2.13.4\n","2.13.6\n","2.13.7\n","2.13.8\n","2.13.9\n","2.14.0\n","2.14.1\n","2.14.10\n","2.14.11\n","2.14.12\n","2.14.13\n","2.14.14\n","2.14.15\n","2.14.16\n","2.14.17\n","2.14.18\n","2.14.19\n","2.14.2\n","2.14.20\n","2.14.22\n","2.14.23\n","2.14.24\n","2.14.25\n","2.14.26\n","2.14.28\n","2.14.29\n","2.14.3\n","2.14.30\n","2.14.31\n","2.14.32\n","2.14.33\n","2.14.34\n","2.14.36\n","2.14.37\n","2.14.38\n","2.14.39\n","2.14.4\n","2.14.40\n","2.14.41\n","2.14.42\n","2.14.43\n","2.14.44\n","2.14.45\n","2.14.48\n","2.14.49\n","2.14.5\n","2.14.50\n","2.14.51\n","2.14.53\n","2.14.55\n","2.14.56\n","2.14.57\n","2.14.58\n","2.14.59\n","2.14.6\n","2.14.60\n","2.14.61\n","2.14.62\n","2.14.63\n","2.14.64\n","2.14.65\n","2.14.66\n","2.14.67\n","2.14.68\n","2.14.69\n","2.14.7\n","2.14.70\n","2.14.71\n","2.14.8\n","2.14.9\n","2.15.02\n","2.15.03\n","2.15.04\n","2.15.05\n","2.15.06\n","2.15.07\n","2.15.08\n","2.15.09\n","2.15.10\n","2.15.11\n","2.15.12\n","2.15.13\n","2.15.14\n","2.15.16\n","2.15.17\n","2.15.19\n","2.15.20\n","2.15.21\n","2.15.22\n","2.15.23\n","2.15.24\n","2.15.25\n","2.15.26\n","2.15.27\n","2.15.28\n","2.15.30\n","2.15.31\n","2.15.34\n","2.15.37\n","2.15.39\n","2.15.40\n","2.15.42\n","2.15.43\n","2.15.44\n","2.15.45\n","2.16.1\n","2.16.10\n","2.16.11\n","2.16.12\n","2.16.13\n","2.16.14\n","2.16.16\n","2.16.2\n","2.16.3\n","2.16.6\n","2.16.7\n","2.16.8\n","2.17.0\n","2.17.12\n","2.17.13\n","2.17.14\n","2.17.2\n","2.17.3\n","2.17.5\n","2.17.6\n","2.17.9\n","2.18.1\n","2.18.10\n","2.18.12\n","2.18.14\n","2.18.17\n","2.18.19\n","2.18.2\n","2.18.20\n","2.18.21\n","2.18.23\n","2.18.4\n","2.18.5\n","2.18.8\n","2.18.9\n","2.19.2\n","2.19.3\n","2.19.5\n","2.19.6\n","2.19.7\n","2.19.8\n","2.19.9\n","2.2.1\n","2.2.2\n","2.2.7\n","2.2.8\n","2.20.02\n","2.20.10\n","2.20.100\n","2.20.101\n","2.20.20\n","2.20.21\n","2.20.23\n","2.20.33\n","2.20.50\n","2.20.60\n","2.20.70\n","2.20.72\n","2.20.80\n","2.20.90\n","2.20.92\n","2.3.0.2\n","2.4.0.0\n","2.4.0.1\n","2.4.0.2\n","2.4.0.3\n","2.4.0.5\n","2.4.0.6\n","2.4.0.7\n","2.4.1.0\n","2.4.1.1\n","2.4.2.1\n","2.4.2.2\n","2.4.3.0\n","2.4.3.1\n","2.4.3.3\n","2.4.3.4\n","2.4.3.5\n","2.4.4.2\n","2.4.4.3\n","2.4.4.4\n","2.4.4.6\n","2.4.4.8\n","2.4.4.9\n","2.4.5.0\n","2.4.5.1\n","2.4.5.2\n","2.4.5.6\n","2.4.5.7\n","2.4.5.8\n","2.4.6.0\n","2.4.6.1\n","2.4.6.2\n","2.4.6.3\n","2.9.0\n","2.9.1\n","2.9.4\n","총 293개의 고유 값이 있습니다.\n","\n","Checking 'reviewCreatedVersion' for 호갱노노...\n","호갱노노 - reviewCreatedVersion에 포함된 고유 값:\n","1.0.1\n","1.0.3\n","1.0.4\n","1.1.0\n","1.2.0\n","1.2.1\n","1.3.0\n","1.3.1\n","1.4.1\n","1.4.2\n","1.5.0\n","1.6.0\n","1.6.3\n","1.6.4\n","1.7.0\n","1.7.1\n","1.7.2\n","1.7.3\n","1.7.4\n","1.7.7\n","1.7.8\n","1.7.9\n","1.8.0\n","1.8.1\n","1.8.10\n","1.8.12\n","1.8.13\n","1.8.16\n","1.8.18\n","1.8.19\n","1.8.20\n","1.8.21\n","1.8.22\n","1.8.3\n","1.8.4\n","1.8.5\n","1.8.6\n","1.8.7\n","1.8.8\n","1.9.0\n","1.9.1\n","1.9.10\n","1.9.11\n","1.9.13\n","1.9.14\n","1.9.15\n","1.9.16\n","1.9.17\n","1.9.18\n","1.9.19\n","1.9.2\n","1.9.20\n","1.9.21\n","1.9.22\n","1.9.23\n","1.9.25\n","1.9.3\n","1.9.4\n","1.9.5\n","1.9.6\n","1.9.7\n","1.9.8\n","1.9.9\n","총 63개의 고유 값이 있습니다.\n","\n"]}]},{"cell_type":"markdown","source":["## 직방** 버전별 모델링 MSE, R2score 계산"],"metadata":{"id":"ZB1fTx_NDGOC"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['직방']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 결과 저장용 딕셔너리\n","model_results = {}\n","\n","# 파일별 데이터 처리\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 데이터 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # 소버전 기준 그룹화 (예: 1.0, 1.1)\n","        data['grouped_version'] = data['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n","\n","        # 그룹별 결과 저장\n","        version_results = {}\n","\n","        # 소버전별 데이터 그룹화\n","        for version, group in data.groupby('grouped_version'):\n","            print(f\"  Processing version group: {version}\")\n","\n","            # 비어 있는 데이터 제거\n","            group = group[group['nouns_without_stopwords'].notnull() & (group['nouns_without_stopwords'].str.strip() != \"[]\")]\n","            if group.empty:\n","                print(f\"    Skipping version group {version}: No valid text data.\")\n","                continue\n","\n","            # 텍스트 데이터 벡터화\n","            texts = group['nouns_without_stopwords'].apply(lambda x: ' '.join(eval(x)))\n","            tfidf = TfidfVectorizer(max_features=1000)\n","            try:\n","                X_text = tfidf.fit_transform(texts)\n","            except ValueError as e:\n","                print(f\"    Error processing version group {version}: {e}\")\n","                continue\n","\n","            # 독립 변수와 종속 변수\n","            X = pd.DataFrame(X_text.toarray())\n","            y = group['score']\n","\n","            # 데이터가 충분한지 확인 (최소 10개의 데이터 필요)\n","            if len(group) < 10:\n","                print(f\"    Skipping version group {version}: Not enough data ({len(group)} rows)\")\n","                continue\n","\n","            # 데이터 분리\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","            # 모델 학습\n","            model = RandomForestRegressor(random_state=42)\n","            model.fit(X_train, y_train)\n","\n","            # 평가\n","            y_pred = model.predict(X_test)\n","            mse = mean_squared_error(y_test, y_pred)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            print(f\"    Version group {version}: MSE = {mse}, R2 Score = {r2}\")\n","\n","            # 중요 피처 분석\n","            feature_importances = pd.Series(model.feature_importances_, index=tfidf.get_feature_names_out()).sort_values(ascending=False)\n","            print(f\"    {version} 상위 중요한 피처:\")\n","            print(feature_importances.head(5))\n","\n","            # 저장\n","            version_results[version] = {\n","                'MSE': mse,\n","                'R2 Score': r2,\n","                'Important Features': feature_importances.head(10).to_dict()\n","            }\n","\n","        # 앱 결과 저장\n","        model_results[app] = version_results\n","\n","# 결과 요약 출력\n","print(\"\\n모델링 결과 요약:\")\n","for app, version_data in model_results.items():\n","    print(f\"App: {app}\")\n","    for version, result in version_data.items():\n","        print(f\"  Version group {version}: MSE = {result['MSE']}, R2 Score = {result['R2 Score']}\")\n","        print(\"  상위 중요한 피처:\")\n","        for feature, importance in result['Important Features'].items():\n","            print(f\"    - {feature}: {importance}\")"],"metadata":{"id":"Ado3CMcbDA7U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733810605488,"user_tz":-540,"elapsed":206911,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"8d0733e5-bd9b-4b56-8816-da85c5332ab7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 직방...\n","  Processing version group: 1.0\n","    Skipping version group 1.0: Not enough data (1 rows)\n","  Processing version group: 1.1\n","    Skipping version group 1.1: Not enough data (6 rows)\n","  Processing version group: 3.0\n","    Version group 3.0: MSE = 0.9342962326973244, R2 Score = -0.12207145593551205\n","    3.0 상위 중요한 피처:\n","관악구    0.111044\n","별로     0.093192\n","몰랏네    0.079022\n","사실     0.071540\n","가짜     0.055537\n","dtype: float64\n","  Processing version group: 4.0\n","    Version group 4.0: MSE = 3.2302500000000003, R2 Score = -0.43566666666666687\n","    4.0 상위 중요한 피처:\n","서울     0.376113\n","지역     0.294412\n","사진     0.083603\n","설명     0.065989\n","그대로    0.056421\n","dtype: float64\n","  Processing version group: 4.1\n","    Version group 4.1: MSE = 2.9812639021329645, R2 Score = -0.012583669215687765\n","    4.1 상위 중요한 피처:\n","방이    0.081174\n","그냥    0.065750\n","대해    0.058531\n","집도    0.053811\n","사진    0.053651\n","dtype: float64\n","  Processing version group: 4.10\n","    Version group 4.10: MSE = 1.7457319876748174, R2 Score = 0.358197261505833\n","    4.10 상위 중요한 피처:\n","허위    0.084719\n","광고    0.040574\n","초코    0.025910\n","실행    0.019911\n","전화    0.019084\n","dtype: float64\n","  Processing version group: 4.11\n","    Version group 4.11: MSE = 3.7350884175670425, R2 Score = -0.735358684023889\n","    4.11 상위 중요한 피처:\n","매물     0.205690\n","가입     0.059880\n","다시     0.059199\n","방이     0.058342\n","포인트    0.053838\n","dtype: float64\n","  Processing version group: 4.12\n","    Version group 4.12: MSE = 2.2693131553238195, R2 Score = 0.24900427953312443\n","    4.12 상위 중요한 피처:\n","허위      0.085331\n","직거래     0.072135\n","광고      0.061313\n","업데이트    0.031004\n","정보      0.026404\n","dtype: float64\n","  Processing version group: 4.13\n","    Version group 4.13: MSE = 1.6463107333124167, R2 Score = 0.4013727258274955\n","    4.13 상위 중요한 피처:\n","매물      0.161997\n","허위      0.083846\n","광고      0.034849\n","다방      0.019330\n","업데이트    0.017537\n","dtype: float64\n","  Processing version group: 4.14\n","    Version group 4.14: MSE = 2.664308666556227, R2 Score = -0.03974873560874426\n","    4.14 상위 중요한 피처:\n","매물     0.100082\n","허위     0.078415\n","광고     0.045017\n","중개사    0.044345\n","낫다     0.027966\n","dtype: float64\n","  Processing version group: 4.15\n","    Version group 4.15: MSE = 2.174870681430912, R2 Score = 0.25307340824826785\n","    4.15 상위 중요한 피처:\n","업데이트    0.109957\n","매물      0.090693\n","허위      0.078093\n","광고      0.022330\n","화면      0.019368\n","dtype: float64\n","  Processing version group: 4.2\n","    Version group 4.2: MSE = 1.1068711448208106, R2 Score = -0.01849029798605062\n","    4.2 상위 중요한 피처:\n","낚시      0.042975\n","설치      0.032480\n","계속      0.030854\n","업데이트    0.029605\n","별로      0.027568\n","dtype: float64\n","  Processing version group: 4.5\n","    Version group 4.5: MSE = 1.796669192239859, R2 Score = 0.04256444360902256\n","    4.5 상위 중요한 피처:\n","업데이트    0.152640\n","포인트     0.142680\n","어플      0.108990\n","계속      0.066461\n","오류      0.065809\n","dtype: float64\n","  Processing version group: 4.6\n","    Version group 4.6: MSE = 2.482823893980421, R2 Score = -0.0578988765655708\n","    4.6 상위 중요한 피처:\n","검색     0.094406\n","실행     0.081692\n","자꾸     0.058061\n","인터넷    0.054696\n","오류     0.051804\n","dtype: float64\n","  Processing version group: 4.7\n","    Version group 4.7: MSE = 1.5861200000000002, R2 Score = -0.6522083333333333\n","    4.7 상위 중요한 피처:\n","원래     0.314378\n","쪼아용    0.225690\n","친구     0.103079\n","추천     0.095117\n","오류     0.064705\n","dtype: float64\n","  Processing version group: 4.8\n","    Version group 4.8: MSE = 2.191541955248053, R2 Score = 0.16817385640219873\n","    4.8 상위 중요한 피처:\n","계속    0.067823\n","광고    0.043607\n","실행    0.041753\n","자꾸    0.041529\n","화면    0.039023\n","dtype: float64\n","  Processing version group: 4.9\n","    Version group 4.9: MSE = 1.2465730810460658, R2 Score = 0.3980467167485098\n","    4.9 상위 중요한 피처:\n","허위    0.096466\n","직방    0.080353\n","계속    0.028635\n","매물    0.027709\n","광고    0.022893\n","dtype: float64\n","  Processing version group: 5.0\n","    Version group 5.0: MSE = 2.945083140243982, R2 Score = 0.06495171199461747\n","    5.0 상위 중요한 피처:\n","매물      0.071020\n","업데이트    0.039423\n","계속      0.026950\n","부동산     0.025334\n","직방      0.023824\n","dtype: float64\n","  Processing version group: 5.1\n","    Version group 5.1: MSE = 1.812020832129658, R2 Score = 0.38179640402943016\n","    5.1 상위 중요한 피처:\n","로그인     0.096756\n","허위      0.050175\n","정보      0.046390\n","매물      0.045857\n","업데이트    0.022604\n","dtype: float64\n","  Processing version group: 5.10\n","    Version group 5.10: MSE = 2.876027049765144, R2 Score = -0.055181305279890625\n","    5.10 상위 중요한 피처:\n","허위     0.095185\n","매물     0.083564\n","직방     0.045512\n","중개사    0.038033\n","취소     0.025366\n","dtype: float64\n","  Processing version group: 5.11\n","    Version group 5.11: MSE = 1.9421232692307693, R2 Score = -0.009904099999999971\n","    5.11 상위 중요한 피처:\n","아주    0.072391\n","매물    0.059990\n","사진    0.056276\n","추천    0.043600\n","접수    0.043432\n","dtype: float64\n","  Processing version group: 5.12\n","    Version group 5.12: MSE = 3.4800800991960674, R2 Score = -0.01034583525047128\n","    5.12 상위 중요한 피처:\n","매물      0.070140\n","연락      0.047197\n","업데이트    0.032601\n","직거래     0.029953\n","아주      0.029934\n","dtype: float64\n","  Processing version group: 5.13\n","    Version group 5.13: MSE = 3.123126484567901, R2 Score = -0.020053408266129003\n","    5.13 상위 중요한 피처:\n","매물     0.197166\n","아파트    0.067242\n","어플     0.043262\n","직방     0.039099\n","여러     0.037379\n","dtype: float64\n","  Processing version group: 5.14\n","    Skipping version group 5.14: Not enough data (1 rows)\n","  Processing version group: 5.2\n","    Version group 5.2: MSE = 2.8252296564096833, R2 Score = -0.23003195925319542\n","    5.2 상위 중요한 피처:\n","매물      0.059443\n","허위      0.038316\n","다방      0.037662\n","업데이트    0.033209\n","도움      0.029947\n","dtype: float64\n","  Processing version group: 5.3\n","    Version group 5.3: MSE = 3.0625277712574777, R2 Score = -0.06579446584954862\n","    5.3 상위 중요한 피처:\n","매물    0.057776\n","정보    0.043426\n","직방    0.038732\n","최고    0.037209\n","허위    0.033817\n","dtype: float64\n","  Processing version group: 5.4\n","    Version group 5.4: MSE = 2.798837017381952, R2 Score = -0.054897987941493476\n","    5.4 상위 중요한 피처:\n","매물    0.067099\n","직방    0.055302\n","어플    0.047189\n","허위    0.032636\n","투어    0.026858\n","dtype: float64\n","  Processing version group: 5.5\n","    Version group 5.5: MSE = 2.32, R2 Score = -0.07407407407407396\n","    5.5 상위 중요한 피처:\n","정보    0.293798\n","이제    0.124771\n","허위    0.104021\n","매물    0.055280\n","전세    0.042922\n","dtype: float64\n","  Processing version group: 5.6\n","    Version group 5.6: MSE = 2.3270317040489696, R2 Score = 0.2370181113431462\n","    5.6 상위 중요한 피처:\n","정보    0.061936\n","허위    0.046916\n","이용    0.042562\n","아주    0.040699\n","매물    0.038890\n","dtype: float64\n","  Processing version group: 5.7\n","    Version group 5.7: MSE = 2.9060277358922058, R2 Score = -0.004127769964869188\n","    5.7 상위 중요한 피처:\n","사용    0.046312\n","매물    0.039565\n","어플    0.039126\n","최고    0.029949\n","허위    0.024577\n","dtype: float64\n","  Processing version group: 5.8\n","    Version group 5.8: MSE = 2.1591467998964258, R2 Score = 0.215973599173509\n","    5.8 상위 중요한 피처:\n","허위    0.061623\n","최고    0.042349\n","매물    0.041519\n","정보    0.036744\n","다방    0.028446\n","dtype: float64\n","  Processing version group: 5.9\n","    Version group 5.9: MSE = 1.8194357161688148, R2 Score = -0.014940233290891669\n","    5.9 상위 중요한 피처:\n","계약     0.063714\n","직방     0.047867\n","옵션     0.043730\n","중개사    0.040504\n","답변     0.036242\n","dtype: float64\n","\n","모델링 결과 요약:\n","App: 직방\n","  Version group 3.0: MSE = 0.9342962326973244, R2 Score = -0.12207145593551205\n","  상위 중요한 피처:\n","    - 관악구: 0.11104369290177642\n","    - 별로: 0.09319233502474346\n","    - 몰랏네: 0.07902235581728662\n","    - 사실: 0.07154026950450913\n","    - 가짜: 0.055537108794748574\n","    - 검색: 0.04588514619891908\n","    - 범위: 0.04316305142721194\n","    - 지역: 0.028290981975815827\n","    - 가능성: 0.023886554893630486\n","    - 지방: 0.022493325509898063\n","  Version group 4.0: MSE = 3.2302500000000003, R2 Score = -0.43566666666666687\n","  상위 중요한 피처:\n","    - 서울: 0.3761125086942815\n","    - 지역: 0.2944122830727184\n","    - 사진: 0.08360257742411652\n","    - 설명: 0.06598890124818002\n","    - 그대로: 0.056421309577953646\n","    - 번호: 0.043085632250940996\n","    - 나오니: 0.022281431994470174\n","    - 주변: 0.01607365958842632\n","    - 구분: 0.011238471119435385\n","    - 대학가: 0.006785231393181164\n","  Version group 4.1: MSE = 2.9812639021329645, R2 Score = -0.012583669215687765\n","  상위 중요한 피처:\n","    - 방이: 0.08117390189864299\n","    - 그냥: 0.06575037932644316\n","    - 대해: 0.058531456026837715\n","    - 집도: 0.05381118668418445\n","    - 사진: 0.053650580543586485\n","    - 아파트: 0.0417892406533852\n","    - 다운: 0.033404248936438515\n","    - 갑자기: 0.032557508563368254\n","    - 어플: 0.0313801763970645\n","    - 가격: 0.02516945463239926\n","  Version group 4.10: MSE = 1.7457319876748174, R2 Score = 0.358197261505833\n","  상위 중요한 피처:\n","    - 허위: 0.08471934307351565\n","    - 광고: 0.040573605659625284\n","    - 초코: 0.02590998967932486\n","    - 실행: 0.01991114849875872\n","    - 전화: 0.01908355959032112\n","    - 장난: 0.0189904486279755\n","    - 그냥: 0.018799054955505993\n","    - 최악: 0.018704040511874104\n","    - 계속: 0.015200134389383025\n","    - 중지: 0.014154133009914336\n","  Version group 4.11: MSE = 3.7350884175670425, R2 Score = -0.735358684023889\n","  상위 중요한 피처:\n","    - 매물: 0.20569038362914255\n","    - 가입: 0.059879635588416316\n","    - 다시: 0.059198828742772075\n","    - 방이: 0.05834244533001421\n","    - 포인트: 0.05383847141672536\n","    - 최악: 0.05244905094771943\n","    - 갑자기: 0.05088895166626024\n","    - 게임: 0.047624664558242186\n","    - 보기: 0.04340693168135366\n","    - 그냥: 0.03258539803108309\n","  Version group 4.12: MSE = 2.2693131553238195, R2 Score = 0.24900427953312443\n","  상위 중요한 피처:\n","    - 허위: 0.08533149278104787\n","    - 직거래: 0.07213453675400497\n","    - 광고: 0.06131290810716105\n","    - 업데이트: 0.0310038531414421\n","    - 정보: 0.026403753411476587\n","    - 매물: 0.024228691238059867\n","    - 직방: 0.023469163039767874\n","    - 최고: 0.0179292916407763\n","    - 그냥: 0.01615747122598583\n","    - 경우: 0.015941626514307587\n","  Version group 4.13: MSE = 1.6463107333124167, R2 Score = 0.4013727258274955\n","  상위 중요한 피처:\n","    - 매물: 0.16199719685369957\n","    - 허위: 0.0838463075328404\n","    - 광고: 0.03484896659888173\n","    - 다방: 0.019329963095351513\n","    - 업데이트: 0.017537491338460297\n","    - 부동산: 0.015993282731179087\n","    - 검색: 0.015522979896900766\n","    - 계속: 0.015356954957597558\n","    - 사람: 0.014148416682011276\n","    - 그냥: 0.01398687101437462\n","  Version group 4.14: MSE = 2.664308666556227, R2 Score = -0.03974873560874426\n","  상위 중요한 피처:\n","    - 매물: 0.10008230218191062\n","    - 허위: 0.07841499500515695\n","    - 광고: 0.04501709822752682\n","    - 중개사: 0.04434466130652655\n","    - 낫다: 0.027966251211149998\n","    - 공인: 0.023786227859641938\n","    - 업데이트: 0.02288176120037596\n","    - 아파트: 0.022515289073837624\n","    - 개뿔: 0.022211916722843002\n","    - 점도: 0.02209947332914332\n","  Version group 4.15: MSE = 2.174870681430912, R2 Score = 0.25307340824826785\n","  상위 중요한 피처:\n","    - 업데이트: 0.10995661271035669\n","    - 매물: 0.09069261133982176\n","    - 허위: 0.07809306495279533\n","    - 광고: 0.02233010126630399\n","    - 화면: 0.019367942479884485\n","    - 삭제: 0.013665053129634215\n","    - 실행: 0.013648994550900235\n","    - 다방: 0.012830046589035813\n","    - 부동산: 0.011771486863886354\n","    - 필터: 0.011235669703673313\n","  Version group 4.2: MSE = 1.1068711448208106, R2 Score = -0.01849029798605062\n","  상위 중요한 피처:\n","    - 낚시: 0.04297460275183901\n","    - 설치: 0.03248017762068997\n","    - 계속: 0.030854240903764242\n","    - 업데이트: 0.02960515933394188\n","    - 별로: 0.027568269731400964\n","    - 삭제: 0.023501077929878163\n","    - 전혀: 0.02020543813568257\n","    - 자꾸: 0.019901839838481185\n","    - 업뎃: 0.019457326745618553\n","    - 형식: 0.018216755799252807\n","  Version group 4.5: MSE = 1.796669192239859, R2 Score = 0.04256444360902256\n","  상위 중요한 피처:\n","    - 업데이트: 0.15263951263716802\n","    - 포인트: 0.14268014671128657\n","    - 어플: 0.10899032665315378\n","    - 계속: 0.06646086206685792\n","    - 오류: 0.06580854362961762\n","    - 직방: 0.04053845760606916\n","    - 현상: 0.03469157567509959\n","    - 제발: 0.031245040759678922\n","    - 강요: 0.030423927684775653\n","    - 수가: 0.02931398818557747\n","  Version group 4.6: MSE = 2.482823893980421, R2 Score = -0.0578988765655708\n","  상위 중요한 피처:\n","    - 검색: 0.09440635213585774\n","    - 실행: 0.08169161550371783\n","    - 자꾸: 0.05806132089795434\n","    - 인터넷: 0.05469560003555393\n","    - 오류: 0.05180415666325086\n","    - 화면: 0.048296184668738855\n","    - 광고: 0.04822599393419184\n","    - 무용지물: 0.04445076536005286\n","    - 계속: 0.04302826119636218\n","    - 제주도: 0.04253075370309627\n","  Version group 4.7: MSE = 1.5861200000000002, R2 Score = -0.6522083333333333\n","  상위 중요한 피처:\n","    - 원래: 0.3143777676526001\n","    - 쪼아용: 0.22568967232960363\n","    - 친구: 0.10307943858864918\n","    - 추천: 0.0951169722557344\n","    - 오류: 0.06470521881155006\n","    - 조만간: 0.04387471346828882\n","    - 실행: 0.022050916344280344\n","    - 인터넷: 0.02043639917139924\n","    - 검색: 0.019920446553908542\n","    - 처리: 0.015947556033768427\n","  Version group 4.8: MSE = 2.191541955248053, R2 Score = 0.16817385640219873\n","  상위 중요한 피처:\n","    - 계속: 0.0678228458398708\n","    - 광고: 0.04360734406446975\n","    - 실행: 0.04175323919511877\n","    - 자꾸: 0.041529192421925154\n","    - 화면: 0.039022577628617584\n","    - 최악: 0.037585132788007326\n","    - 제대로: 0.022926975283774326\n","    - 도화지: 0.021766393617057435\n","    - 오류: 0.021625511800443652\n","    - 매물도: 0.021401481521530492\n","  Version group 4.9: MSE = 1.2465730810460658, R2 Score = 0.3980467167485098\n","  상위 중요한 피처:\n","    - 허위: 0.09646614321140991\n","    - 직방: 0.08035325532995292\n","    - 계속: 0.028635197273029735\n","    - 매물: 0.027708931201415515\n","    - 광고: 0.022892747792552796\n","    - 다시: 0.01746216071339578\n","    - 그냥: 0.017362250256597225\n","    - 전화: 0.016552386559255453\n","    - 최악: 0.012504793771681084\n","    - 어플: 0.012370642413251379\n","  Version group 5.0: MSE = 2.945083140243982, R2 Score = 0.06495171199461747\n","  상위 중요한 피처:\n","    - 매물: 0.07102011059112934\n","    - 업데이트: 0.03942264901129789\n","    - 계속: 0.026949695544016553\n","    - 부동산: 0.025334056999112606\n","    - 직방: 0.02382377290946588\n","    - 허위: 0.023062195003686184\n","    - 아파트: 0.02182703382664832\n","    - 어플: 0.021623760501096167\n","    - 다방: 0.018005372422016216\n","    - 로그인: 0.017607503841189344\n","  Version group 5.1: MSE = 1.812020832129658, R2 Score = 0.38179640402943016\n","  상위 중요한 피처:\n","    - 로그인: 0.0967562583265659\n","    - 허위: 0.05017479678120405\n","    - 정보: 0.046390303641588825\n","    - 매물: 0.04585716989993958\n","    - 업데이트: 0.02260351007358734\n","    - 아주: 0.02222772634894196\n","    - 계속: 0.019015715839502255\n","    - 사용: 0.0186493065106682\n","    - 검색: 0.017734116496573072\n","    - 관심: 0.016651456931171676\n","  Version group 5.10: MSE = 2.876027049765144, R2 Score = -0.055181305279890625\n","  상위 중요한 피처:\n","    - 허위: 0.09518519081926104\n","    - 매물: 0.0835635459297654\n","    - 직방: 0.04551172796757067\n","    - 중개사: 0.03803266499918247\n","    - 취소: 0.02536581472163064\n","    - 사용: 0.022202102216135753\n","    - 사장: 0.02052577439865308\n","    - 최고: 0.02035517794691637\n","    - 지금: 0.01861580056836354\n","    - 선택: 0.018356193998200782\n","  Version group 5.11: MSE = 1.9421232692307693, R2 Score = -0.009904099999999971\n","  상위 중요한 피처:\n","    - 아주: 0.07239116840769895\n","    - 매물: 0.059990076698216814\n","    - 사진: 0.056275941128562205\n","    - 추천: 0.0436000337664208\n","    - 접수: 0.043431998465934665\n","    - 대한: 0.0322321505351344\n","    - 어플: 0.029091821691058634\n","    - 중개사: 0.028523318304031396\n","    - 입자: 0.026163589839988642\n","    - 감사: 0.0235884099661471\n","  Version group 5.12: MSE = 3.4800800991960674, R2 Score = -0.01034583525047128\n","  상위 중요한 피처:\n","    - 매물: 0.07013983458613984\n","    - 연락: 0.04719742156228158\n","    - 업데이트: 0.03260089288936658\n","    - 직거래: 0.029953179770947753\n","    - 아주: 0.029934282958035227\n","    - 삭제: 0.02904663857844644\n","    - 김경수: 0.02789296184286754\n","    - 임대: 0.02454552789988021\n","    - 어플: 0.023297369720612013\n","    - 필터: 0.021468787532607076\n","  Version group 5.13: MSE = 3.123126484567901, R2 Score = -0.020053408266129003\n","  상위 중요한 피처:\n","    - 매물: 0.19716613771723737\n","    - 아파트: 0.06724235503799475\n","    - 어플: 0.043262020446345584\n","    - 직방: 0.0390994038408244\n","    - 여러: 0.037378595357775726\n","    - 아주: 0.03521224296789382\n","    - 지금: 0.02353528720976409\n","    - 도움: 0.023174961432007243\n","    - 점검: 0.022991275398260583\n","    - 킼비: 0.020158662807157265\n","  Version group 5.2: MSE = 2.8252296564096833, R2 Score = -0.23003195925319542\n","  상위 중요한 피처:\n","    - 매물: 0.05944250813015896\n","    - 허위: 0.03831628561249471\n","    - 다방: 0.037662289983399745\n","    - 업데이트: 0.033209345088563144\n","    - 도움: 0.029947256303617817\n","    - 직방: 0.026699393777951882\n","    - 최고: 0.025682856761118734\n","    - 광고: 0.020466414551048903\n","    - 별로: 0.019185215396717855\n","    - 기능: 0.017656251101510513\n","  Version group 5.3: MSE = 3.0625277712574777, R2 Score = -0.06579446584954862\n","  상위 중요한 피처:\n","    - 매물: 0.0577760057741539\n","    - 정보: 0.04342587513322787\n","    - 직방: 0.038732034639139636\n","    - 최고: 0.037208834832296686\n","    - 허위: 0.03381659718682274\n","    - 아파트: 0.027873638058075263\n","    - 보기: 0.027172313674501004\n","    - 사진: 0.025270678020361793\n","    - 업데이트: 0.016526456231269453\n","    - 어플: 0.01305000614436256\n","  Version group 5.4: MSE = 2.798837017381952, R2 Score = -0.054897987941493476\n","  상위 중요한 피처:\n","    - 매물: 0.06709949000220827\n","    - 직방: 0.05530165624203389\n","    - 어플: 0.04718923381190364\n","    - 허위: 0.03263636664821379\n","    - 투어: 0.026857516500550193\n","    - 계약: 0.026379765181749414\n","    - 종료: 0.025573017099118602\n","    - 정보: 0.02492015137633197\n","    - 아파트: 0.02079369375640767\n","    - 보기: 0.018695009902310645\n","  Version group 5.5: MSE = 2.32, R2 Score = -0.07407407407407396\n","  상위 중요한 피처:\n","    - 정보: 0.2937981187427251\n","    - 이제: 0.12477087431581975\n","    - 허위: 0.10402148848700611\n","    - 매물: 0.05528007794210736\n","    - 전세: 0.042921527648131536\n","    - 빌라: 0.03806275956238556\n","    - 문의: 0.035384283655668196\n","    - 삭제: 0.023799382606352212\n","    - 부동산: 0.02301496172505933\n","    - 찾기: 0.02232616062535111\n","  Version group 5.6: MSE = 2.3270317040489696, R2 Score = 0.2370181113431462\n","  상위 중요한 피처:\n","    - 정보: 0.06193586109524002\n","    - 허위: 0.04691560609250619\n","    - 이용: 0.04256234181820123\n","    - 아주: 0.040698681602922865\n","    - 매물: 0.03889035810985426\n","    - 사용: 0.03878260504237712\n","    - 보고: 0.0227138302315966\n","    - 덕분: 0.021767608360652654\n","    - 최고: 0.020150068467969292\n","    - 어플: 0.01955090001375882\n","  Version group 5.7: MSE = 2.9060277358922058, R2 Score = -0.004127769964869188\n","  상위 중요한 피처:\n","    - 사용: 0.04631168768229445\n","    - 매물: 0.03956540628522327\n","    - 어플: 0.039126153441822575\n","    - 최고: 0.02994900843998379\n","    - 허위: 0.02457669657133563\n","    - 업데이트: 0.024069490220607313\n","    - 다방: 0.023072851416784\n","    - 쓰레기: 0.021549874532590555\n","    - 기능: 0.020834363149426778\n","    - 삭제: 0.019651252056319863\n","  Version group 5.8: MSE = 2.1591467998964258, R2 Score = 0.215973599173509\n","  상위 중요한 피처:\n","    - 허위: 0.0616230961331202\n","    - 최고: 0.04234919138632015\n","    - 매물: 0.041519249356554176\n","    - 정보: 0.03674366858153313\n","    - 다방: 0.028445939638269784\n","    - 내용: 0.028340912794678055\n","    - 사진: 0.02052759775614819\n","    - 이용: 0.019898608028247614\n","    - 연락: 0.016679907036153338\n","    - 직방: 0.01571804029415428\n","  Version group 5.9: MSE = 1.8194357161688148, R2 Score = -0.014940233290891669\n","  상위 중요한 피처:\n","    - 계약: 0.0637142999826093\n","    - 직방: 0.04786689364908473\n","    - 옵션: 0.04373017022492399\n","    - 중개사: 0.04050412454981644\n","    - 답변: 0.03624239854672062\n","    - 매우: 0.034994175797249276\n","    - 굿굿둣: 0.03182724480571826\n","    - 지금: 0.031593957831140836\n","    - 허위: 0.027576856916271347\n","    - 방향: 0.02674385485401146\n"]}]},{"cell_type":"markdown","source":["### 다방 버전별 모델링 MSE, R2score 계산"],"metadata":{"id":"hwCt1it1DQFi"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['다방']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 결과 저장용 딕셔너리\n","model_results = {}\n","\n","# 파일별 데이터 처리\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 데이터 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # 소버전 기준 그룹화 (예: 1.0, 1.1)\n","        data['grouped_version'] = data['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n","\n","        # 그룹별 결과 저장\n","        version_results = {}\n","\n","        # 소버전별 데이터 그룹화\n","        for version, group in data.groupby('grouped_version'):\n","            print(f\"  Processing version group: {version}\")\n","\n","            # 비어 있는 데이터 제거\n","            group = group[group['nouns_without_stopwords'].notnull() & (group['nouns_without_stopwords'].str.strip() != \"[]\")]\n","            if group.empty:\n","                print(f\"    Skipping version group {version}: No valid text data.\")\n","                continue\n","\n","            # 텍스트 데이터 벡터화\n","            texts = group['nouns_without_stopwords'].apply(lambda x: ' '.join(eval(x)))\n","            tfidf = TfidfVectorizer(max_features=1000)\n","            try:\n","                X_text = tfidf.fit_transform(texts)\n","            except ValueError as e:\n","                print(f\"    Error processing version group {version}: {e}\")\n","                continue\n","\n","            # 독립 변수와 종속 변수\n","            X = pd.DataFrame(X_text.toarray())\n","            y = group['score']\n","\n","            # 데이터가 충분한지 확인 (최소 10개의 데이터 필요)\n","            if len(group) < 10:\n","                print(f\"    Skipping version group {version}: Not enough data ({len(group)} rows)\")\n","                continue\n","\n","            # 데이터 분리\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","            # 모델 학습\n","            model = RandomForestRegressor(random_state=42)\n","            model.fit(X_train, y_train)\n","\n","            # 평가\n","            y_pred = model.predict(X_test)\n","            mse = mean_squared_error(y_test, y_pred)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            print(f\"    Version group {version}: MSE = {mse}, R2 Score = {r2}\")\n","\n","            # 중요 피처 분석\n","            feature_importances = pd.Series(model.feature_importances_, index=tfidf.get_feature_names_out()).sort_values(ascending=False)\n","            print(f\"    {version} 상위 중요한 피처:\")\n","            print(feature_importances.head(5))\n","\n","            # 저장\n","            version_results[version] = {\n","                'MSE': mse,\n","                'R2 Score': r2,\n","                'Important Features': feature_importances.head(10).to_dict()\n","            }\n","\n","        # 앱 결과 저장\n","        model_results[app] = version_results\n","\n","# 결과 요약 출력\n","print(\"\\n모델링 결과 요약:\")\n","for app, version_data in model_results.items():\n","    print(f\"App: {app}\")\n","    for version, result in version_data.items():\n","        print(f\"  Version group {version}: MSE = {result['MSE']}, R2 Score = {result['R2 Score']}\")\n","        print(\"  상위 중요한 피처:\")\n","        for feature, importance in result['Important Features'].items():\n","            print(f\"    - {feature}: {importance}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVr1fmGbC57u","executionInfo":{"status":"ok","timestamp":1733810670517,"user_tz":-540,"elapsed":65060,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"78fac273-037e-47b3-a04e-175fd110e0e6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 다방...\n","  Processing version group: 1.0\n","    Version group 1.0: MSE = 0.2, R2 Score = -0.2500000000000002\n","    1.0 상위 중요한 피처:\n","거래     0.0\n","준비     0.0\n","안드네    0.0\n","어플     0.0\n","완전     0.0\n","dtype: float64\n","  Processing version group: 1.1\n","    Version group 1.1: MSE = 1.05064, R2 Score = -0.6416250000000001\n","    1.1 상위 중요한 피처:\n","위치    0.237112\n","조건    0.153146\n","검색    0.090757\n","지금    0.072076\n","개인    0.068511\n","dtype: float64\n","  Processing version group: 1.2\n","    Skipping version group 1.2: Not enough data (4 rows)\n","  Processing version group: 1.3\n","    Skipping version group 1.3: Not enough data (9 rows)\n","  Processing version group: 1.4\n","    Skipping version group 1.4: Not enough data (7 rows)\n","  Processing version group: 1.5\n","    Version group 1.5: MSE = 0.22439963315087932, R2 Score = -0.4727536671047201\n","    1.5 상위 중요한 피처:\n","필요    0.129233\n","자꾸    0.096957\n","최고    0.085826\n","완전    0.084886\n","다시    0.084597\n","dtype: float64\n","  Processing version group: 1.6\n","    Skipping version group 1.6: Not enough data (2 rows)\n","  Processing version group: 1.7\n","    Version group 1.7: MSE = 2.6686833333333335, R2 Score = -0.20090750000000002\n","    1.7 상위 중요한 피처:\n","검색     0.390926\n","안성은    0.122818\n","보기     0.106623\n","시가     0.085506\n","개선     0.079349\n","dtype: float64\n","  Processing version group: 1.8\n","    Version group 1.8: MSE = 1.3333333333333333, R2 Score = -0.4999999999999998\n","    1.8 상위 중요한 피처:\n","방법     0.213284\n","탈퇴     0.202338\n","오지     0.152541\n","스팸함    0.125008\n","메일     0.124367\n","dtype: float64\n","  Processing version group: 1.9\n","    Version group 1.9: MSE = 4.750933333333333, R2 Score = -0.33619999999999983\n","    1.9 상위 중요한 피처:\n","하라    0.174622\n","아예    0.104239\n","먹통    0.085465\n","런가    0.081415\n","사진    0.079437\n","dtype: float64\n","  Processing version group: 2.0\n","    Skipping version group 2.0: Not enough data (3 rows)\n","  Processing version group: 2.1\n","    Version group 2.1: MSE = 0.059914242337590594, R2 Score = -0.3088246598420683\n","    2.1 상위 중요한 피처:\n","전세    0.146328\n","직방    0.108985\n","탈퇴    0.086035\n","시도    0.048183\n","관심    0.034633\n","dtype: float64\n","  Processing version group: 2.10\n","    Skipping version group 2.10: Not enough data (6 rows)\n","  Processing version group: 2.11\n","    Version group 2.11: MSE = 2.14328393978782, R2 Score = 0.29159586475815724\n","    2.11 상위 중요한 피처:\n","허위    0.122820\n","사진    0.057866\n","필요    0.054945\n","매물    0.052307\n","별루    0.042483\n","dtype: float64\n","  Processing version group: 2.12\n","    Version group 2.12: MSE = 4.603966666666667, R2 Score = -0.6648272321428572\n","    2.12 상위 중요한 피처:\n","매물    0.110337\n","최고    0.101717\n","보고    0.086800\n","어플    0.078673\n","허위    0.066148\n","dtype: float64\n","  Processing version group: 2.13\n","    Version group 2.13: MSE = 1.707506448601663, R2 Score = 0.3775166364591406\n","    2.13 상위 중요한 피처:\n","허위    0.089814\n","모습    0.053109\n","그냥    0.045206\n","고생    0.037742\n","티몬    0.037610\n","dtype: float64\n","  Processing version group: 2.14\n","    Version group 2.14: MSE = 2.849934468480726, R2 Score = 0.05865087746301367\n","    2.14 상위 중요한 피처:\n","매물    0.112761\n","다방    0.102720\n","허위    0.098830\n","보고    0.042000\n","보기    0.038217\n","dtype: float64\n","  Processing version group: 2.15\n","    Version group 2.15: MSE = 2.924645454545454, R2 Score = 0.022425138121547228\n","    2.15 상위 중요한 피처:\n","허위     0.194269\n","다방     0.163239\n","매물     0.088368\n","연락     0.058761\n","똑바로    0.037816\n","dtype: float64\n","  Processing version group: 2.16\n","    Version group 2.16: MSE = 4.532322222222223, R2 Score = -0.7316891509433965\n","    2.16 상위 중요한 피처:\n","허위    0.152846\n","어플    0.104423\n","검색    0.079641\n","보기    0.053755\n","직방    0.046791\n","dtype: float64\n","  Processing version group: 2.17\n","    Version group 2.17: MSE = 1.821761538461539, R2 Score = 0.36124958506224036\n","    2.17 상위 중요한 피처:\n","매물    0.078043\n","다방    0.069624\n","허위    0.059636\n","보고    0.055297\n","처음    0.054516\n","dtype: float64\n","  Processing version group: 2.18\n","    Version group 2.18: MSE = 1.9823720585201294, R2 Score = 0.18672717283740448\n","    2.18 상위 중요한 피처:\n","허위    0.252586\n","다방    0.046750\n","어플    0.029781\n","원룸    0.023272\n","매물    0.018290\n","dtype: float64\n","  Processing version group: 2.2\n","    Version group 2.2: MSE = 4.391042857142858, R2 Score = -0.43440733333333315\n","    2.2 상위 중요한 피처:\n","허위     0.114948\n","전국     0.099720\n","보고     0.082332\n","매물     0.077508\n","부동산    0.047550\n","dtype: float64\n","  Processing version group: 2.3\n","    Version group 2.3: MSE = 1.3227682660410522, R2 Score = -0.10132414819960811\n","    2.3 상위 중요한 피처:\n","제주도    0.087806\n","기본     0.043313\n","방도     0.041971\n","춘천     0.036729\n","별로     0.030750\n","dtype: float64\n","  Processing version group: 2.4\n","    Version group 2.4: MSE = 0.3486152093653141, R2 Score = 0.039047993876437315\n","    2.4 상위 중요한 피처:\n","삭제    0.045408\n","오류    0.044966\n","거임    0.033313\n","튕기    0.029920\n","혜리    0.029239\n","dtype: float64\n","  Processing version group: 2.5\n","    Version group 2.5: MSE = 3.7285779136733006, R2 Score = -0.22772463207167637\n","    2.5 상위 중요한 피처:\n","매물      0.122731\n","부동산     0.048087\n","게임머니    0.046512\n","방이      0.039777\n","전혀      0.027758\n","dtype: float64\n","  Processing version group: 2.6\n","    Version group 2.6: MSE = 3.6347398609221453, R2 Score = -0.1895512272108837\n","    2.6 상위 중요한 피처:\n","허위    0.181473\n","삭제    0.065334\n","자동    0.047510\n","정보    0.035085\n","매물    0.032177\n","dtype: float64\n","  Processing version group: 2.7\n","    Version group 2.7: MSE = 10.25, R2 Score = -2.813953488372093\n","    2.7 상위 중요한 피처:\n","계약    0.282173\n","지금    0.103895\n","예전    0.095275\n","매물    0.088188\n","제제    0.083042\n","dtype: float64\n","  Processing version group: 2.8\n","    Version group 2.8: MSE = 6.105620000000001, R2 Score = -1.008427631578947\n","    2.8 상위 중요한 피처:\n","허위    0.277264\n","방이    0.181301\n","다방    0.045427\n","사진    0.039479\n","검색    0.023790\n","dtype: float64\n","  Processing version group: 2.9\n","    Version group 2.9: MSE = 2.51, R2 Score = 0.040990566037735876\n","    2.9 상위 중요한 피처:\n","부분    0.112866\n","허위    0.088006\n","별로    0.069009\n","다방    0.057279\n","정직    0.048844\n","dtype: float64\n","  Processing version group: 3.0\n","    Version group 3.0: MSE = 1.9925342743757524, R2 Score = 0.32658926050282133\n","    3.0 상위 중요한 피처:\n","허위      0.282391\n","매물      0.044062\n","업데이트    0.043902\n","어플      0.034656\n","방이      0.025895\n","dtype: float64\n","  Processing version group: 3.1\n","    Version group 3.1: MSE = 2.092081395348837, R2 Score = 0.3699904723127039\n","    3.1 상위 중요한 피처:\n","매물    0.107407\n","어플    0.086473\n","허위    0.075891\n","다방    0.074921\n","정보    0.052460\n","dtype: float64\n","  Processing version group: 3.10\n","    Version group 3.10: MSE = 1.0095159997050012, R2 Score = 0.58736296377133\n","    3.10 상위 중요한 피처:\n","허위      0.483287\n","광고      0.021903\n","삭제      0.013724\n","업데이트    0.012498\n","쿠키      0.011470\n","dtype: float64\n","  Processing version group: 3.2\n","    Version group 3.2: MSE = 1.6166584246030584, R2 Score = 0.5236551617433541\n","    3.2 상위 중요한 피처:\n","허위    0.340800\n","정보    0.036223\n","다방    0.032242\n","사진    0.023647\n","매물    0.023599\n","dtype: float64\n","  Processing version group: 3.3\n","    Version group 3.3: MSE = 1.5304312892819365, R2 Score = 0.5891140562179894\n","    3.3 상위 중요한 피처:\n","허위      0.363627\n","네트워크    0.129240\n","다방      0.031879\n","오류      0.020621\n","관리      0.016617\n","dtype: float64\n","  Processing version group: 3.4\n","    Version group 3.4: MSE = 1.021703421571463, R2 Score = 0.7285759526519915\n","    3.4 상위 중요한 피처:\n","허위      0.520830\n","자체      0.038702\n","업데이트    0.028224\n","네트워크    0.024562\n","관리      0.024292\n","dtype: float64\n","  Processing version group: 3.5\n","    Version group 3.5: MSE = 1.2690840425531915, R2 Score = 0.5708195575627681\n","    3.5 상위 중요한 피처:\n","허위     0.431769\n","자체     0.109615\n","삭제     0.050567\n","회원     0.035728\n","매물도    0.022114\n","dtype: float64\n","  Processing version group: 3.6\n","    Version group 3.6: MSE = 0.8541878286322498, R2 Score = 0.740871261166099\n","    3.6 상위 중요한 피처:\n","허위      0.562403\n","오류      0.122908\n","네트워크    0.042794\n","다운      0.018244\n","직접      0.012678\n","dtype: float64\n","  Processing version group: 3.7\n","    Version group 3.7: MSE = 1.0975183333333334, R2 Score = 0.6766457156886816\n","    3.7 상위 중요한 피처:\n","허위      0.609787\n","사진      0.025518\n","전화      0.023315\n","매매      0.022706\n","네트워크    0.020697\n","dtype: float64\n","  Processing version group: 3.8\n","    Version group 3.8: MSE = 0.24214339837147, R2 Score = 0.9172334711781134\n","    3.8 상위 중요한 피처:\n","허위     0.470444\n","계속     0.194283\n","삭제     0.125451\n","주기도    0.116910\n","보기     0.017989\n","dtype: float64\n","  Processing version group: 3.9\n","    Version group 3.9: MSE = 1.202922289805409, R2 Score = 0.5496313312459428\n","    3.9 상위 중요한 피처:\n","허위    0.709825\n","연락    0.018392\n","개선    0.013580\n","가격    0.012563\n","대출    0.012458\n","dtype: float64\n","  Processing version group: 4.0\n","    Version group 4.0: MSE = 3.6734846153846155, R2 Score = -0.12876163636363636\n","    4.0 상위 중요한 피처:\n","매물    0.316091\n","연락    0.083432\n","사진    0.083269\n","로드    0.066114\n","불편    0.052578\n","dtype: float64\n","  Processing version group: 4.1\n","    Version group 4.1: MSE = 2.188671428571429, R2 Score = -0.19161000000000006\n","    4.1 상위 중요한 피처:\n","어플    0.204655\n","자금    0.091893\n","전세    0.089179\n","옵션    0.080734\n","선택    0.079518\n","dtype: float64\n","  Processing version group: 4.10\n","    Version group 4.10: MSE = 2.0827989133324385, R2 Score = -0.029986859880835937\n","    4.10 상위 중요한 피처:\n","매물    0.202886\n","허위    0.150566\n","사진    0.055922\n","전세    0.042126\n","중개    0.041176\n","dtype: float64\n","  Processing version group: 4.11\n","    Version group 4.11: MSE = 0.004814285714285713, R2 Score = 0.0\n","    4.11 상위 중요한 피처:\n","무제한    0.090687\n","핑계     0.072224\n","본인     0.071763\n","반복     0.070209\n","미끼     0.056516\n","dtype: float64\n","  Processing version group: 4.12\n","    Version group 4.12: MSE = 2.5127588235294116, R2 Score = 0.13754477434679346\n","    4.12 상위 중요한 피처:\n","매물      0.125020\n","연락      0.108034\n","부동산     0.083290\n","허위      0.080575\n","업데이트    0.071726\n","dtype: float64\n","  Processing version group: 4.13\n","    Version group 4.13: MSE = 1.9735083677248677, R2 Score = -0.07446566687242817\n","    4.13 상위 중요한 피처:\n","보기     0.117527\n","매물     0.083982\n","계약     0.069782\n","허위     0.069470\n","정보공    0.066085\n","dtype: float64\n","  Processing version group: 4.14\n","    Version group 4.14: MSE = 3.491499834873551, R2 Score = -0.8368325218247814\n","    4.14 상위 중요한 피처:\n","매물     0.130985\n","문맹     0.114569\n","부동산    0.100862\n","어플     0.077222\n","매몰     0.044134\n","dtype: float64\n","  Processing version group: 4.15\n","    Version group 4.15: MSE = 4.19971, R2 Score = -0.2499136904761905\n","    4.15 상위 중요한 피처:\n","매물      0.228647\n","어플      0.112679\n","허위      0.064106\n","업데이트    0.050335\n","실행      0.035739\n","dtype: float64\n","  Processing version group: 4.16\n","    Skipping version group 4.16: Not enough data (8 rows)\n","  Processing version group: 4.17\n","    Version group 4.17: MSE = 2.6840499999999996, R2 Score = -0.19291111111111103\n","    4.17 상위 중요한 피처:\n","어플    0.142702\n","스브    0.093387\n","조절    0.074558\n","사용    0.062748\n","광고    0.060087\n","dtype: float64\n","  Processing version group: 4.18\n","    Version group 4.18: MSE = 2.8556142857142857, R2 Score = -0.14692704918032806\n","    4.18 상위 중요한 피처:\n","허위     0.130777\n","오타     0.080371\n","중개사    0.077069\n","헛걸음    0.041797\n","계약     0.031393\n","dtype: float64\n","  Processing version group: 4.19\n","    Skipping version group 4.19: Not enough data (5 rows)\n","  Processing version group: 4.2\n","    Version group 4.2: MSE = 4.765427777777777, R2 Score = -0.6355917372881359\n","    4.2 상위 중요한 피처:\n","찾기      0.087463\n","보기      0.086728\n","반려동물    0.085477\n","데이터     0.072117\n","다방      0.067943\n","dtype: float64\n","  Processing version group: 4.20\n","    Skipping version group 4.20: Not enough data (9 rows)\n","  Processing version group: 4.3\n","    Version group 4.3: MSE = 2.330055555555555, R2 Score = -0.04852500000000015\n","    4.3 상위 중요한 피처:\n","덕분    0.095531\n","아주    0.082415\n","조건    0.075521\n","이용    0.075444\n","대박    0.071800\n","dtype: float64\n","  Processing version group: 4.4\n","    Version group 4.4: MSE = 4.515514285714286, R2 Score = -1.595427565982404\n","    4.4 상위 중요한 피처:\n","허위     0.590929\n","아파트    0.034610\n","해도     0.032061\n","자꾸     0.028210\n","사용     0.021327\n","dtype: float64\n","  Processing version group: 4.5\n","    Version group 4.5: MSE = 2.967683333333333, R2 Score = 0.1653390625000002\n","    4.5 상위 중요한 피처:\n","다방    0.104345\n","여러    0.092653\n","허위    0.081403\n","매물    0.078119\n","보고    0.072991\n","dtype: float64\n","  Processing version group: 4.6\n","    Version group 4.6: MSE = 1.3861371707942438, R2 Score = 0.48509814606743396\n","    4.6 상위 중요한 피처:\n","완전     0.059050\n","매물     0.057772\n","다방     0.054746\n","허위     0.053619\n","굿굿굿    0.045368\n","dtype: float64\n","  Processing version group: 4.7\n","    Version group 4.7: MSE = 3.6296571428571425, R2 Score = -0.22657379310344816\n","    4.7 상위 중요한 피처:\n","업데이트    0.313826\n","허위      0.259688\n","버전      0.044852\n","최신      0.038145\n","완료      0.034901\n","dtype: float64\n","  Processing version group: 4.8\n","    Version group 4.8: MSE = 2.6487249999999998, R2 Score = 0.18500769230769243\n","    4.8 상위 중요한 피처:\n","허위    0.262195\n","필터    0.122644\n","장난    0.078424\n","대출    0.038570\n","로드    0.034468\n","dtype: float64\n","  Processing version group: 4.9\n","    Version group 4.9: MSE = 2.4025899951971534, R2 Score = 0.23381972594106526\n","    4.9 상위 중요한 피처:\n","허위     0.414840\n","방이     0.038977\n","부동산    0.029264\n","어려움    0.026718\n","별로     0.024180\n","dtype: float64\n","  Processing version group: 5.0\n","    Version group 5.0: MSE = 0.7004133333333333, R2 Score = -0.382394736842105\n","    5.0 상위 중요한 피처:\n","주택      0.108751\n","여기저기    0.067400\n","사람      0.055191\n","자체      0.051223\n","검색      0.044175\n","dtype: float64\n","\n","모델링 결과 요약:\n","App: 다방\n","  Version group 1.0: MSE = 0.2, R2 Score = -0.2500000000000002\n","  상위 중요한 피처:\n","    - 거래: 0.0\n","    - 준비: 0.0\n","    - 안드네: 0.0\n","    - 어플: 0.0\n","    - 완전: 0.0\n","    - 원룸: 0.0\n","    - 위주: 0.0\n","    - 위해: 0.0\n","    - 인제: 0.0\n","    - 전체: 0.0\n","  Version group 1.1: MSE = 1.05064, R2 Score = -0.6416250000000001\n","  상위 중요한 피처:\n","    - 위치: 0.237111560623874\n","    - 조건: 0.15314594281406807\n","    - 검색: 0.09075677915381443\n","    - 지금: 0.0720758461997005\n","    - 개인: 0.0685107973904119\n","    - 쓰리룸: 0.04409989655298137\n","    - 방도: 0.04087654172149191\n","    - 마음: 0.04060569163681653\n","    - 라오: 0.03185424534842081\n","    - 알림: 0.030652307516968038\n","  Version group 1.5: MSE = 0.22439963315087932, R2 Score = -0.4727536671047201\n","  상위 중요한 피처:\n","    - 필요: 0.12923319809987366\n","    - 자꾸: 0.09695698778944495\n","    - 최고: 0.08582641576714747\n","    - 완전: 0.08488593036055399\n","    - 다시: 0.08459714539867448\n","    - 그냥: 0.07246128946036606\n","    - 작성: 0.061411234269761514\n","    - 굿방: 0.050514452085881956\n","    - 정보: 0.04185350022280954\n","    - 굿굿: 0.04108755348165602\n","  Version group 1.7: MSE = 2.6686833333333335, R2 Score = -0.20090750000000002\n","  상위 중요한 피처:\n","    - 검색: 0.39092604830477146\n","    - 안성은: 0.12281847194471594\n","    - 보기: 0.10662271177597989\n","    - 시가: 0.08550570825505245\n","    - 개선: 0.07934943042812907\n","    - 글씨: 0.07356753908844639\n","    - 뒤죽박죽: 0.027066354941135514\n","    - 편이: 0.01941316740213513\n","    - 정도: 0.01638604302873394\n","    - 집중: 0.016330252529017698\n","  Version group 1.8: MSE = 1.3333333333333333, R2 Score = -0.4999999999999998\n","  상위 중요한 피처:\n","    - 방법: 0.21328418823773565\n","    - 탈퇴: 0.20233815338649036\n","    - 오지: 0.15254097542588413\n","    - 스팸함: 0.1250084331344726\n","    - 메일: 0.1243671188152206\n","    - 이메일: 0.10937271873495487\n","    - 확인: 0.07308841226524163\n","    - 열람: 0.0\n","    - 역시: 0.0\n","    - 웨딩: 0.0\n","  Version group 1.9: MSE = 4.750933333333333, R2 Score = -0.33619999999999983\n","  상위 중요한 피처:\n","    - 하라: 0.17462164868744182\n","    - 아예: 0.10423886925732201\n","    - 먹통: 0.08546471013304564\n","    - 런가: 0.08141474058413546\n","    - 사진: 0.07943700334032891\n","    - 조절: 0.06006035605780213\n","    - 월세: 0.039155916808487304\n","    - 크게: 0.03616556388507606\n","    - 직방: 0.03197990169028522\n","    - 선택: 0.026789321789321818\n","  Version group 2.1: MSE = 0.059914242337590594, R2 Score = -0.3088246598420683\n","  상위 중요한 피처:\n","    - 전세: 0.1463278859074971\n","    - 직방: 0.10898476874668012\n","    - 탈퇴: 0.08603508701053028\n","    - 시도: 0.048182829675778596\n","    - 관심: 0.03463276003192714\n","    - 취지: 0.0343900119764205\n","    - 추천: 0.03369519524815039\n","    - 로딩: 0.03216929728931108\n","    - 인지: 0.03154547746496196\n","    - 유저: 0.03137461079795225\n","  Version group 2.11: MSE = 2.14328393978782, R2 Score = 0.29159586475815724\n","  상위 중요한 피처:\n","    - 허위: 0.12281977247910003\n","    - 사진: 0.05786577120121703\n","    - 필요: 0.05494528842269972\n","    - 매물: 0.05230694632862373\n","    - 별루: 0.04248321346519871\n","    - 보고: 0.040541400946459104\n","    - 생각: 0.033468078462833374\n","    - 덕분: 0.025739094915802993\n","    - 삭제: 0.02362262733386965\n","    - 자꾸: 0.023110776548550527\n","  Version group 2.12: MSE = 4.603966666666667, R2 Score = -0.6648272321428572\n","  상위 중요한 피처:\n","    - 매물: 0.11033652585307684\n","    - 최고: 0.10171742303838618\n","    - 보고: 0.08680037205905095\n","    - 어플: 0.0786733519406496\n","    - 허위: 0.06614788459775411\n","    - 집도: 0.055182929168529994\n","    - 나이: 0.05343068677532896\n","    - 전화: 0.03314435982376834\n","    - 나름: 0.03086625263774749\n","    - 꾸벅: 0.02444616613789362\n","  Version group 2.13: MSE = 1.707506448601663, R2 Score = 0.3775166364591406\n","  상위 중요한 피처:\n","    - 허위: 0.08981443619134116\n","    - 모습: 0.05310876500369796\n","    - 그냥: 0.045205851195326774\n","    - 고생: 0.037741566308181054\n","    - 티몬: 0.03761018358687138\n","    - 어플: 0.03518656710410066\n","    - 이만: 0.034613102560509465\n","    - 월세: 0.032995919029529246\n","    - 필터: 0.029331792893346764\n","    - 직접: 0.025899225113953928\n","  Version group 2.14: MSE = 2.849934468480726, R2 Score = 0.05865087746301367\n","  상위 중요한 피처:\n","    - 매물: 0.11276076991415951\n","    - 다방: 0.10271966623225796\n","    - 허위: 0.09882997397349257\n","    - 보고: 0.04200003382045194\n","    - 보기: 0.03821717192413846\n","    - 사람: 0.028579205186453602\n","    - 방이: 0.02594509694797611\n","    - 관리: 0.024745614599797953\n","    - 헛걸음: 0.02296246065291062\n","    - 위치: 0.022711008680049462\n","  Version group 2.15: MSE = 2.924645454545454, R2 Score = 0.022425138121547228\n","  상위 중요한 피처:\n","    - 허위: 0.19426925439246112\n","    - 다방: 0.16323940589569094\n","    - 매물: 0.08836764911852345\n","    - 연락: 0.058760764279148656\n","    - 똑바로: 0.03781562766764988\n","    - 군데: 0.03667171825098273\n","    - 그냥: 0.03401516510030601\n","    - 계약: 0.025682600488490713\n","    - 원룸: 0.022068614553170673\n","    - 사진: 0.021462260810853912\n","  Version group 2.16: MSE = 4.532322222222223, R2 Score = -0.7316891509433965\n","  상위 중요한 피처:\n","    - 허위: 0.15284578487399603\n","    - 어플: 0.10442285781084426\n","    - 검색: 0.07964064870114936\n","    - 보기: 0.05375509840048754\n","    - 직방: 0.046791429807703525\n","    - 사기꾼: 0.03931000772086237\n","    - 설정: 0.028946558074373407\n","    - 구조도: 0.027299302296140943\n","    - 사진: 0.025270013631684584\n","    - 전기: 0.02297074622849518\n","  Version group 2.17: MSE = 1.821761538461539, R2 Score = 0.36124958506224036\n","  상위 중요한 피처:\n","    - 매물: 0.078042556602685\n","    - 다방: 0.06962431786936617\n","    - 허위: 0.05963585700015979\n","    - 보고: 0.055296932274661245\n","    - 처음: 0.05451588203994785\n","    - 업데이트: 0.0463965500860453\n","    - 가요: 0.029040284393447004\n","    - 다시: 0.027002071234639758\n","    - 깔대기: 0.025739990766923803\n","    - 거래: 0.024720756993737266\n","  Version group 2.18: MSE = 1.9823720585201294, R2 Score = 0.18672717283740448\n","  상위 중요한 피처:\n","    - 허위: 0.25258615971817294\n","    - 다방: 0.04674971730140157\n","    - 어플: 0.029781362440521778\n","    - 원룸: 0.023271742799023765\n","    - 매물: 0.018290316753253412\n","    - 다시: 0.01823254141233033\n","    - 장난: 0.015974977975932846\n","    - 삭제: 0.01514656463550555\n","    - 사진: 0.015131381538590035\n","    - 정보: 0.01496362654418768\n","  Version group 2.2: MSE = 4.391042857142858, R2 Score = -0.43440733333333315\n","  상위 중요한 피처:\n","    - 허위: 0.11494837362160265\n","    - 전국: 0.09972049973813588\n","    - 보고: 0.08233226465569611\n","    - 매물: 0.077508363085051\n","    - 부동산: 0.047549851420235066\n","    - 사진: 0.04203308510748735\n","    - 제주시: 0.03909194521830559\n","    - 삭제: 0.034984097685559566\n","    - 방이: 0.0344196141391254\n","    - 제주도: 0.027014119134093552\n","  Version group 2.3: MSE = 1.3227682660410522, R2 Score = -0.10132414819960811\n","  상위 중요한 피처:\n","    - 제주도: 0.0878056294306109\n","    - 기본: 0.043312987057222835\n","    - 방도: 0.04197130438604954\n","    - 춘천: 0.036728561435341416\n","    - 별로: 0.030749837337869512\n","    - 오류: 0.030653387507056182\n","    - 매매: 0.02437286668543843\n","    - 대체: 0.021984373258740163\n","    - 신고: 0.02155508042466943\n","    - 자동: 0.02124872576956093\n","  Version group 2.4: MSE = 0.3486152093653141, R2 Score = 0.039047993876437315\n","  상위 중요한 피처:\n","    - 삭제: 0.045407537673779155\n","    - 오류: 0.04496608140033355\n","    - 거임: 0.033312590796782574\n","    - 튕기: 0.02991994375339616\n","    - 혜리: 0.02923868921564866\n","    - 신고: 0.02914218687082179\n","    - 제대로: 0.025578155508284107\n","    - 임돈땜: 0.02446963829057609\n","    - 귀귓: 0.024280245133737912\n","    - 헛돌기: 0.022371341167941858\n","  Version group 2.5: MSE = 3.7285779136733006, R2 Score = -0.22772463207167637\n","  상위 중요한 피처:\n","    - 매물: 0.12273132746793561\n","    - 부동산: 0.04808701323945556\n","    - 게임머니: 0.04651234809991187\n","    - 방이: 0.03977693965092251\n","    - 전혀: 0.027758128024816482\n","    - 도움: 0.02704965948980991\n","    - 지영: 0.026223005482498982\n","    - 캐무: 0.025334001161116053\n","    - 웹툰: 0.024541084927220205\n","    - 다방: 0.018842088377398914\n","  Version group 2.6: MSE = 3.6347398609221453, R2 Score = -0.1895512272108837\n","  상위 중요한 피처:\n","    - 허위: 0.1814728214513101\n","    - 삭제: 0.06533437097736364\n","    - 자동: 0.04750977314013228\n","    - 정보: 0.035085349976745756\n","    - 매물: 0.03217690115515255\n","    - 다방: 0.02956125371523764\n","    - 방구: 0.029084605267868446\n","    - 전화: 0.02600893756019411\n","    - 사람: 0.02552772431405576\n","    - 최고: 0.025215368353217874\n","  Version group 2.7: MSE = 10.25, R2 Score = -2.813953488372093\n","  상위 중요한 피처:\n","    - 계약: 0.28217268893822045\n","    - 지금: 0.10389517996791406\n","    - 예전: 0.09527530182198092\n","    - 매물: 0.08818756804376164\n","    - 제제: 0.08304220970496812\n","    - 실속: 0.05741987843188611\n","    - 방구: 0.04560690937662305\n","    - 계속: 0.04512653491900688\n","    - 사진: 0.04185566252814056\n","    - 장난: 0.040779519013536096\n","  Version group 2.8: MSE = 6.105620000000001, R2 Score = -1.008427631578947\n","  상위 중요한 피처:\n","    - 허위: 0.27726356722777945\n","    - 방이: 0.1813006507301621\n","    - 다방: 0.04542655822732758\n","    - 사진: 0.039478547073714364\n","    - 검색: 0.023789649174700615\n","    - 매물: 0.018921306972585965\n","    - 매물도: 0.018021499989950684\n","    - 관리: 0.016590223706422113\n","    - 업댓: 0.015960053018487057\n","    - 지고: 0.014493355749388509\n","  Version group 2.9: MSE = 2.51, R2 Score = 0.040990566037735876\n","  상위 중요한 피처:\n","    - 부분: 0.11286604156293752\n","    - 허위: 0.08800603392166732\n","    - 별로: 0.06900871373442102\n","    - 다방: 0.05727859465099699\n","    - 정직: 0.04884389712136876\n","    - 조건: 0.03814846343442441\n","    - 소통: 0.03519024062285907\n","    - 직방: 0.032730070041352914\n","    - 직원: 0.031674294604017536\n","    - 매물: 0.0314468364501864\n","  Version group 3.0: MSE = 1.9925342743757524, R2 Score = 0.32658926050282133\n","  상위 중요한 피처:\n","    - 허위: 0.28239065818335235\n","    - 매물: 0.04406213525501809\n","    - 업데이트: 0.04390154560754489\n","    - 어플: 0.0346557680940977\n","    - 방이: 0.025894739421459593\n","    - 문의: 0.025117155160119548\n","    - 정보: 0.02143992234025301\n","    - 로그인: 0.02140955234066983\n","    - 문제: 0.020483945904179273\n","    - 자동: 0.018971065521033538\n","  Version group 3.1: MSE = 2.092081395348837, R2 Score = 0.3699904723127039\n","  상위 중요한 피처:\n","    - 매물: 0.10740720181355808\n","    - 어플: 0.08647325461222145\n","    - 허위: 0.07589103590323969\n","    - 다방: 0.07492055973080232\n","    - 정보: 0.05246043448020951\n","    - 부동산: 0.022361035701689083\n","    - 계약: 0.02214953826498496\n","    - 평수: 0.022120788243550543\n","    - 빡세: 0.020361873671340142\n","    - 계속: 0.01697651199103046\n","  Version group 3.10: MSE = 1.0095159997050012, R2 Score = 0.58736296377133\n","  상위 중요한 피처:\n","    - 허위: 0.4832870389335279\n","    - 광고: 0.021902753214273724\n","    - 삭제: 0.013724154659692856\n","    - 업데이트: 0.01249754581000502\n","    - 쿠키: 0.011469682348612342\n","    - 찾기: 0.00987133996073376\n","    - 막상: 0.009500283112379592\n","    - 가입: 0.00904864084469322\n","    - 회원: 0.008881403537375602\n","    - 거래: 0.008730281198372585\n","  Version group 3.2: MSE = 1.6166584246030584, R2 Score = 0.5236551617433541\n","  상위 중요한 피처:\n","    - 허위: 0.34079983598739816\n","    - 정보: 0.03622339997209552\n","    - 다방: 0.03224235456151667\n","    - 사진: 0.02364671625484808\n","    - 매물: 0.023599296389439382\n","    - 광고: 0.022856385961013616\n","    - 네트워크: 0.016857511323580248\n","    - 장난: 0.016065800545656747\n","    - 방이: 0.0157658266262464\n","    - 관리: 0.015641532821194622\n","  Version group 3.3: MSE = 1.5304312892819365, R2 Score = 0.5891140562179894\n","  상위 중요한 피처:\n","    - 허위: 0.3636272314407134\n","    - 네트워크: 0.12923992841405962\n","    - 다방: 0.03187945392828597\n","    - 오류: 0.020621262827247397\n","    - 관리: 0.016617192342818415\n","    - 매물: 0.01612963748531937\n","    - 연락: 0.015456310714778534\n","    - 사기꾼: 0.014210726653543978\n","    - 매물도: 0.012364893971901483\n","    - 실행: 0.012285837417412031\n","  Version group 3.4: MSE = 1.021703421571463, R2 Score = 0.7285759526519915\n","  상위 중요한 피처:\n","    - 허위: 0.520829714257265\n","    - 자체: 0.03870193646242863\n","    - 업데이트: 0.028224411772555195\n","    - 네트워크: 0.024561703413984188\n","    - 관리: 0.024291565378817336\n","    - 원투: 0.01877791421525917\n","    - 로그인: 0.01836862989256514\n","    - 이건: 0.01640441489477853\n","    - 가짐: 0.015175313234532976\n","    - 삭제: 0.014908275873684948\n","  Version group 3.5: MSE = 1.2690840425531915, R2 Score = 0.5708195575627681\n","  상위 중요한 피처:\n","    - 허위: 0.43176923299202263\n","    - 자체: 0.10961494131266844\n","    - 삭제: 0.05056676472376721\n","    - 회원: 0.03572845315421627\n","    - 매물도: 0.022113876071945825\n","    - 등록: 0.021821362812673842\n","    - 방이: 0.020669782969246656\n","    - 확인: 0.019969009372213548\n","    - 이사: 0.019546518453858602\n","    - 필터: 0.019331899467013917\n","  Version group 3.6: MSE = 0.8541878286322498, R2 Score = 0.740871261166099\n","  상위 중요한 피처:\n","    - 허위: 0.56240348484326\n","    - 오류: 0.12290787047947486\n","    - 네트워크: 0.04279417269171603\n","    - 다운: 0.01824405595427625\n","    - 직접: 0.012678333990216633\n","    - 매매: 0.012477219500635177\n","    - 사기: 0.011504806995242001\n","    - 신축: 0.01077943979350063\n","    - 광고: 0.01067486059171121\n","    - 불편: 0.010336878454462574\n","  Version group 3.7: MSE = 1.0975183333333334, R2 Score = 0.6766457156886816\n","  상위 중요한 피처:\n","    - 허위: 0.6097865223163119\n","    - 사진: 0.025517559913632405\n","    - 전화: 0.023314585384230865\n","    - 매매: 0.02270648305026421\n","    - 네트워크: 0.02069680422825184\n","    - 날짜: 0.019439855418513997\n","    - 로그인: 0.017870579569410728\n","    - 라임: 0.016222279340179956\n","    - 짜증: 0.014505235760253768\n","    - 연락: 0.014481323168988211\n","  Version group 3.8: MSE = 0.24214339837147, R2 Score = 0.9172334711781134\n","  상위 중요한 피처:\n","    - 허위: 0.4704444439660873\n","    - 계속: 0.19428276115431406\n","    - 삭제: 0.12545081536395503\n","    - 주기도: 0.11690956425996618\n","    - 보기: 0.017988799916877535\n","    - 직방: 0.016049484820778673\n","    - 휴대폰: 0.01225456315121478\n","    - 문제: 0.009446113205765301\n","    - 선택: 0.004681563496626235\n","    - 프로: 0.004415421180127066\n","  Version group 3.9: MSE = 1.202922289805409, R2 Score = 0.5496313312459428\n","  상위 중요한 피처:\n","    - 허위: 0.7098250766089202\n","    - 연락: 0.018391880072332042\n","    - 개선: 0.01358015705467631\n","    - 가격: 0.012562861252853321\n","    - 대출: 0.012457796417329471\n","    - 오류: 0.011787667742077103\n","    - 그냥: 0.010473475811375543\n","    - 물건: 0.01002650279239852\n","    - 매물도: 0.009540189633540246\n","    - 개도: 0.009490980334560514\n","  Version group 4.0: MSE = 3.6734846153846155, R2 Score = -0.12876163636363636\n","  상위 중요한 피처:\n","    - 매물: 0.3160906699633187\n","    - 연락: 0.08343193063645522\n","    - 사진: 0.08326921448582464\n","    - 로드: 0.06611374245066728\n","    - 불편: 0.05257774257080112\n","    - 방이: 0.04773403969167402\n","    - 짜증: 0.024530676430867877\n","    - 확인: 0.02250756351828806\n","    - 설정: 0.021883752989509432\n","    - 버전: 0.019383848207033955\n","  Version group 4.1: MSE = 2.188671428571429, R2 Score = -0.19161000000000006\n","  상위 중요한 피처:\n","    - 어플: 0.2046551544690073\n","    - 자금: 0.09189348865368756\n","    - 전세: 0.08917879468405858\n","    - 옵션: 0.08073429301593503\n","    - 선택: 0.07951835398112095\n","    - 태안군: 0.0770074105408354\n","    - 지역: 0.056564979245131077\n","    - 기능: 0.051671089252517115\n","    - 집땅: 0.05114463506862963\n","    - 충남: 0.04944693495155685\n","  Version group 4.10: MSE = 2.0827989133324385, R2 Score = -0.029986859880835937\n","  상위 중요한 피처:\n","    - 매물: 0.20288639818421877\n","    - 허위: 0.15056624083277317\n","    - 사진: 0.055921729938310384\n","    - 전세: 0.04212640115228341\n","    - 중개: 0.041176208253565064\n","    - 직접: 0.03766737736624722\n","    - 방이: 0.03500178995137308\n","    - 전체: 0.029367567826305355\n","    - 반려동물: 0.024998764023059287\n","    - 사기꾼: 0.02056885121766716\n","  Version group 4.11: MSE = 0.004814285714285713, R2 Score = 0.0\n","  상위 중요한 피처:\n","    - 무제한: 0.09068657319371404\n","    - 핑계: 0.07222407576770834\n","    - 본인: 0.07176271903963836\n","    - 반복: 0.07020871268812766\n","    - 미끼: 0.05651566832092348\n","    - 매물: 0.04727838109850237\n","    - 지역: 0.0448728258787853\n","    - 아무: 0.043590163025916465\n","    - 전체: 0.03623672972648799\n","    - 유도: 0.03365778518289379\n","  Version group 4.12: MSE = 2.5127588235294116, R2 Score = 0.13754477434679346\n","  상위 중요한 피처:\n","    - 매물: 0.125020187866306\n","    - 연락: 0.10803394563857487\n","    - 부동산: 0.08328976023381392\n","    - 허위: 0.08057544477810692\n","    - 업데이트: 0.07172605566071623\n","    - 이유: 0.06035161595142014\n","    - 검색: 0.043826360391373456\n","    - 선택: 0.04281930767385293\n","    - 실제: 0.036875977068476756\n","    - 뉴스: 0.028860928488464284\n","  Version group 4.13: MSE = 1.9735083677248677, R2 Score = -0.07446566687242817\n","  상위 중요한 피처:\n","    - 보기: 0.11752721172602912\n","    - 매물: 0.0839823742103139\n","    - 계약: 0.06978233571699297\n","    - 허위: 0.06946965372236175\n","    - 정보공: 0.06608537919761906\n","    - 반려동물: 0.04180733351617442\n","    - 신생아: 0.03222439911577678\n","    - 정부: 0.03142585178737535\n","    - 가요: 0.027276370658627973\n","    - 사기꾼: 0.02493884690143058\n","  Version group 4.14: MSE = 3.491499834873551, R2 Score = -0.8368325218247814\n","  상위 중요한 피처:\n","    - 매물: 0.1309850411674253\n","    - 문맹: 0.11456941094379593\n","    - 부동산: 0.10086151692949305\n","    - 어플: 0.07722153991178692\n","    - 매몰: 0.04413376712970974\n","    - 전화: 0.03999879629970775\n","    - 계속: 0.038257403038408855\n","    - 다시: 0.031058991013519603\n","    - 사람: 0.030899533193355908\n","    - 도면: 0.029250595771138064\n","  Version group 4.15: MSE = 4.19971, R2 Score = -0.2499136904761905\n","  상위 중요한 피처:\n","    - 매물: 0.22864686700930612\n","    - 어플: 0.11267942322550008\n","    - 허위: 0.06410598409396562\n","    - 업데이트: 0.05033540207585451\n","    - 실행: 0.035739248832449604\n","    - 오전: 0.028930478332346406\n","    - 화면: 0.026473734568952287\n","    - 항목: 0.026168261865072234\n","    - 눌림: 0.022558485737610056\n","    - 서초동: 0.02237271278224178\n","  Version group 4.17: MSE = 2.6840499999999996, R2 Score = -0.19291111111111103\n","  상위 중요한 피처:\n","    - 어플: 0.14270193502836043\n","    - 스브: 0.09338665993427908\n","    - 조절: 0.07455848621971305\n","    - 사용: 0.06274793983691598\n","    - 광고: 0.06008685734121093\n","    - 주차: 0.05943262524934542\n","    - 직원: 0.05911821604727537\n","    - 해고: 0.05084261083747906\n","    - 민폐: 0.04994808969227345\n","    - 가면: 0.04209357769056355\n","  Version group 4.18: MSE = 2.8556142857142857, R2 Score = -0.14692704918032806\n","  상위 중요한 피처:\n","    - 허위: 0.1307773633635704\n","    - 오타: 0.08037091322577554\n","    - 중개사: 0.07706925386006516\n","    - 헛걸음: 0.041796910114745726\n","    - 계약: 0.0313925038435898\n","    - 통일: 0.03079032099213611\n","    - 전남: 0.029856280405878812\n","    - 표기: 0.02821837059666962\n","    - 면적: 0.027953348025535334\n","    - 지역: 0.027736524776204474\n","  Version group 4.2: MSE = 4.765427777777777, R2 Score = -0.6355917372881359\n","  상위 중요한 피처:\n","    - 찾기: 0.08746268455978233\n","    - 보기: 0.08672825914775086\n","    - 반려동물: 0.08547655263930669\n","    - 데이터: 0.07211668033326597\n","    - 다방: 0.06794254644632647\n","    - 방도: 0.055363549262459594\n","    - 기능: 0.05109345935194835\n","    - 삭제: 0.046008831887667086\n","    - 업글: 0.02891630641486123\n","    - 정신: 0.028333948899761752\n","  Version group 4.3: MSE = 2.330055555555555, R2 Score = -0.04852500000000015\n","  상위 중요한 피처:\n","    - 덕분: 0.09553084800571487\n","    - 아주: 0.08241527128577918\n","    - 조건: 0.07552084972993114\n","    - 이용: 0.07544376343050901\n","    - 대박: 0.07180045028160574\n","    - 매물: 0.0641815496827322\n","    - 정보: 0.05460069085353275\n","    - 어플: 0.04810410544405679\n","    - 허위: 0.043568314238490814\n","    - 확인: 0.03348956738296861\n","  Version group 4.4: MSE = 4.515514285714286, R2 Score = -1.595427565982404\n","  상위 중요한 피처:\n","    - 허위: 0.5909292063202274\n","    - 아파트: 0.03460958805620583\n","    - 해도: 0.03206078228269941\n","    - 자꾸: 0.02820973298481546\n","    - 사용: 0.02132696937464364\n","    - 수가: 0.021204898156131455\n","    - 안눌림: 0.01866717936049246\n","    - 그냥: 0.018531987929145326\n","    - 처리: 0.01781155172521468\n","    - 보기: 0.017784008230748414\n","  Version group 4.5: MSE = 2.967683333333333, R2 Score = 0.1653390625000002\n","  상위 중요한 피처:\n","    - 다방: 0.10434512203897642\n","    - 여러: 0.09265342652913247\n","    - 허위: 0.08140337736518516\n","    - 매물: 0.0781192116389301\n","    - 보고: 0.07299146509565131\n","    - 지고: 0.04612253182719337\n","    - 거래: 0.03911821750870493\n","    - 받아랏: 0.03550782750369094\n","    - 개도: 0.03361806965186087\n","    - 낭비: 0.026056699896477707\n","  Version group 4.6: MSE = 1.3861371707942438, R2 Score = 0.48509814606743396\n","  상위 중요한 피처:\n","    - 완전: 0.05905029611954608\n","    - 매물: 0.05777193606787927\n","    - 다방: 0.0547458492522879\n","    - 허위: 0.05361868220006211\n","    - 굿굿굿: 0.04536772557355634\n","    - 덕분: 0.0427609864459214\n","    - 한눈: 0.04156054904046335\n","    - 비교: 0.03766844884587973\n","    - 중개인: 0.03676670035195883\n","    - 업데이트: 0.024278567132424992\n","  Version group 4.7: MSE = 3.6296571428571425, R2 Score = -0.22657379310344816\n","  상위 중요한 피처:\n","    - 업데이트: 0.3138261950475335\n","    - 허위: 0.259687886678468\n","    - 버전: 0.044852000100781254\n","    - 최신: 0.038145141786798474\n","    - 완료: 0.03490103386509733\n","    - 업뎃: 0.032270908608489086\n","    - 낫굿: 0.027695261560345824\n","    - 가성: 0.02440582828437334\n","    - 그냥: 0.023252208328996504\n","    - 사람: 0.019660760095215904\n","  Version group 4.8: MSE = 2.6487249999999998, R2 Score = 0.18500769230769243\n","  상위 중요한 피처:\n","    - 허위: 0.2621949053171\n","    - 필터: 0.12264399444620838\n","    - 장난: 0.07842394358017078\n","    - 대출: 0.03857029445566891\n","    - 로드: 0.03446792929486958\n","    - 전세: 0.031113191559742136\n","    - 문제: 0.02636544343872358\n","    - 로그인: 0.02589531692969376\n","    - 자꾸: 0.02501785880170386\n","    - 혜리: 0.021691870203917846\n","  Version group 4.9: MSE = 2.4025899951971534, R2 Score = 0.23381972594106526\n","  상위 중요한 피처:\n","    - 허위: 0.4148400863612201\n","    - 방이: 0.038976524298235324\n","    - 부동산: 0.0292644583089671\n","    - 어려움: 0.026717830267516746\n","    - 별로: 0.024180264501557986\n","    - 굿굿굿: 0.02339225013908188\n","    - 폭주족: 0.023314235319066522\n","    - 현물: 0.022542598040440516\n","    - 다방: 0.022172493333925257\n","    - 답변: 0.019295937016935275\n","  Version group 5.0: MSE = 0.7004133333333333, R2 Score = -0.382394736842105\n","  상위 중요한 피처:\n","    - 주택: 0.10875121247193091\n","    - 여기저기: 0.06739999692950843\n","    - 사람: 0.05519131659555906\n","    - 자체: 0.05122301837249482\n","    - 검색: 0.044175288593371685\n","    - 전입: 0.0419835055900586\n","    - 상가: 0.039803520479886376\n","    - 때문: 0.03606651083387013\n","    - 등록: 0.033401627168648085\n","    - 가능도: 0.028650358486621945\n"]}]},{"cell_type":"markdown","source":["### 네이버부동산 버전별 모델링 MSE, R2score 계산 (네이버 대버전 기준)"],"metadata":{"id":"zl46OsIVC01w"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['네이버부동산']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 결과 저장용 딕셔너리\n","model_results = {}\n","\n","# 파일별 데이터 처리\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 데이터 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # 버전 그룹화 (1.x → 그룹 1, 2.x → 그룹 2)\n","        data['grouped_version'] = data['reviewCreatedVersion'].apply(lambda x: x.split('.')[0])\n","\n","        # 그룹별 결과 저장\n","        version_results = {}\n","\n","        # 버전별 데이터 그룹화\n","        for version, group in data.groupby('grouped_version'):\n","            print(f\"  Processing version group: {version}\")\n","\n","            # 비어 있는 데이터 제거\n","            group = group[group['nouns_without_stopwords'].notnull() & (group['nouns_without_stopwords'].str.strip() != \"[]\")]\n","            if group.empty:\n","                print(f\"    Skipping version group {version}: No valid text data.\")\n","                continue\n","\n","            # 텍스트 데이터 벡터화\n","            texts = group['nouns_without_stopwords'].apply(lambda x: ' '.join(eval(x)))\n","            tfidf = TfidfVectorizer(max_features=1000)\n","            try:\n","                X_text = tfidf.fit_transform(texts)\n","            except ValueError as e:\n","                print(f\"    Error processing version group {version}: {e}\")\n","                continue\n","\n","            # 독립 변수와 종속 변수\n","            X = pd.DataFrame(X_text.toarray())\n","            y = group['score']\n","\n","            # 데이터가 충분한지 확인 (최소 10개의 데이터 필요)\n","            if len(group) < 10:\n","                print(f\"    Skipping version group {version}: Not enough data ({len(group)} rows)\")\n","                continue\n","\n","            # 데이터 분리\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","            # 모델 학습\n","            model = RandomForestRegressor(random_state=42)\n","            model.fit(X_train, y_train)\n","\n","            # 평가\n","            y_pred = model.predict(X_test)\n","            mse = mean_squared_error(y_test, y_pred)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            print(f\"    Version group {version}: MSE = {mse}, R2 Score = {r2}\")\n","\n","            # 중요 피처 분석\n","            feature_importances = pd.Series(model.feature_importances_, index=tfidf.get_feature_names_out()).sort_values(ascending=False)\n","            important_features = feature_importances[feature_importances > 0.05]  # 중요도 > 0.05만 포함\n","            print(f\"    {version} 상위 중요한 피처:\")\n","            print(important_features.head(5))\n","\n","            # 저장\n","            version_results[version] = {\n","                'MSE': mse,\n","                'R2 Score': r2,\n","                'Important Features': important_features.head(10).to_dict()\n","            }\n","\n","        # 앱 결과 저장\n","        model_results[app] = version_results\n","\n","# 결과 요약 출력\n","print(\"\\n모델링 결과 요약:\")\n","for app, version_data in model_results.items():\n","    print(f\"App: {app}\")\n","    for version, result in version_data.items():\n","        print(f\"  Version group {version}: MSE = {result['MSE']}, R2 Score = {result['R2 Score']}\")\n","        print(\"  상위 중요한 피처:\")\n","        for feature, importance in result['Important Features'].items():\n","            print(f\"    - {feature}: {importance}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"DgDDMPab-Cz9","executionInfo":{"status":"error","timestamp":1733766184485,"user_tz":-540,"elapsed":12249,"user":{"displayName":"이수빈","userId":"05038481129381091037"}},"outputId":"acf4c093-70a7-4e3f-ebd7-b2f71e70fcbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 네이버부동산...\n","  Processing version group: 1\n","    Version group 1: MSE = 2.642605123467446, R2 Score = 0.10324044673030985\n","    1 상위 중요한 피처:\n","부동산    0.067575\n","버전     0.063554\n","dtype: float64\n","  Processing version group: 2\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-255f94e57a95>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         tree._fit(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### 네이버부동산 버전별 모델링 MSE, R2score 계산 (네이버 세부버전 기준)\n"],"metadata":{"id":"OAaEbnFvCrYp"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['네이버부동산']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 결과 저장용 딕셔너리\n","model_results = {}\n","\n","# 파일별 데이터 처리\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 데이터 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # 소버전 기준 그룹화 (예: 1.0, 1.1)\n","        data['grouped_version'] = data['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n","\n","        # 그룹별 결과 저장\n","        version_results = {}\n","\n","        # 소버전별 데이터 그룹화\n","        for version, group in data.groupby('grouped_version'):\n","            print(f\"  Processing version group: {version}\")\n","\n","            # 비어 있는 데이터 제거\n","            group = group[group['nouns_without_stopwords'].notnull() & (group['nouns_without_stopwords'].str.strip() != \"[]\")]\n","            if group.empty:\n","                print(f\"    Skipping version group {version}: No valid text data.\")\n","                continue\n","\n","            # 텍스트 데이터 벡터화\n","            texts = group['nouns_without_stopwords'].apply(lambda x: ' '.join(eval(x)))\n","            tfidf = TfidfVectorizer(max_features=1000)\n","            try:\n","                X_text = tfidf.fit_transform(texts)\n","            except ValueError as e:\n","                print(f\"    Error processing version group {version}: {e}\")\n","                continue\n","\n","            # 독립 변수와 종속 변수\n","            X = pd.DataFrame(X_text.toarray())\n","            y = group['score']\n","\n","            # 데이터가 충분한지 확인 (최소 10개의 데이터 필요)\n","            if len(group) < 10:\n","                print(f\"    Skipping version group {version}: Not enough data ({len(group)} rows)\")\n","                continue\n","\n","            # 데이터 분리\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","            # 모델 학습\n","            model = RandomForestRegressor(random_state=42)\n","            model.fit(X_train, y_train)\n","\n","            # 평가\n","            y_pred = model.predict(X_test)\n","            mse = mean_squared_error(y_test, y_pred)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            print(f\"    Version group {version}: MSE = {mse}, R2 Score = {r2}\")\n","\n","            # 중요 피처 분석\n","            feature_importances = pd.Series(model.feature_importances_, index=tfidf.get_feature_names_out()).sort_values(ascending=False)\n","            print(f\"    {version} 상위 중요한 피처:\")\n","            print(feature_importances.head(5))\n","\n","            # 저장\n","            version_results[version] = {\n","                'MSE': mse,\n","                'R2 Score': r2,\n","                'Important Features': feature_importances.head(10).to_dict()\n","            }\n","\n","        # 앱 결과 저장\n","        model_results[app] = version_results\n","\n","# 결과 요약 출력\n","print(\"\\n모델링 결과 요약:\")\n","for app, version_data in model_results.items():\n","    print(f\"App: {app}\")\n","    for version, result in version_data.items():\n","        print(f\"  Version group {version}: MSE = {result['MSE']}, R2 Score = {result['R2 Score']}\")\n","        print(\"  상위 중요한 피처:\")\n","        for feature, importance in result['Important Features'].items():\n","            print(f\"    - {feature}: {importance}\")\n"],"metadata":{"id":"KSqt621m_2yo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 피터팬 버전별 모델링 MSE, R2score 계산"],"metadata":{"id":"OMvjLpcqCjI-"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['피터팬']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 결과 저장용 딕셔너리\n","model_results = {}\n","\n","# 파일별 데이터 처리\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 데이터 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # 소버전 기준 그룹화 (예: 1.0, 1.1)\n","        data['grouped_version'] = data['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n","\n","        # 그룹별 결과 저장\n","        version_results = {}\n","\n","        # 소버전별 데이터 그룹화\n","        for version, group in data.groupby('grouped_version'):\n","            print(f\"  Processing version group: {version}\")\n","\n","            # 비어 있는 데이터 제거\n","            group = group[group['nouns_without_stopwords'].notnull() & (group['nouns_without_stopwords'].str.strip() != \"[]\")]\n","            if group.empty:\n","                print(f\"    Skipping version group {version}: No valid text data.\")\n","                continue\n","\n","            # 텍스트 데이터 벡터화\n","            texts = group['nouns_without_stopwords'].apply(lambda x: ' '.join(eval(x)))\n","            tfidf = TfidfVectorizer(max_features=1000)\n","            try:\n","                X_text = tfidf.fit_transform(texts)\n","            except ValueError as e:\n","                print(f\"    Error processing version group {version}: {e}\")\n","                continue\n","\n","            # 독립 변수와 종속 변수\n","            X = pd.DataFrame(X_text.toarray())\n","            y = group['score']\n","\n","            # 데이터가 충분한지 확인 (최소 10개의 데이터 필요)\n","            if len(group) < 10:\n","                print(f\"    Skipping version group {version}: Not enough data ({len(group)} rows)\")\n","                continue\n","\n","            # 데이터 분리\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","            # 모델 학습\n","            model = RandomForestRegressor(random_state=42)\n","            model.fit(X_train, y_train)\n","\n","            # 평가\n","            y_pred = model.predict(X_test)\n","            mse = mean_squared_error(y_test, y_pred)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            print(f\"    Version group {version}: MSE = {mse}, R2 Score = {r2}\")\n","\n","            # 중요 피처 분석\n","            feature_importances = pd.Series(model.feature_importances_, index=tfidf.get_feature_names_out()).sort_values(ascending=False)\n","            print(f\"    {version} 상위 중요한 피처:\")\n","            print(feature_importances.head(5))\n","\n","            # 저장\n","            version_results[version] = {\n","                'MSE': mse,\n","                'R2 Score': r2,\n","                'Important Features': feature_importances.head(10).to_dict()\n","            }\n","\n","        # 앱 결과 저장\n","        model_results[app] = version_results\n","\n","# 결과 요약 출력\n","print(\"\\n모델링 결과 요약:\")\n","for app, version_data in model_results.items():\n","    print(f\"App: {app}\")\n","    for version, result in version_data.items():\n","        print(f\"  Version group {version}: MSE = {result['MSE']}, R2 Score = {result['R2 Score']}\")\n","        print(\"  상위 중요한 피처:\")\n","        for feature, importance in result['Important Features'].items():\n","            print(f\"    - {feature}: {importance}\")\n"],"metadata":{"id":"DObXmMkyB_VH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 호갱노노 버전별 모델링 MSE, R2score 계산"],"metadata":{"id":"oOGH5PpoCYl_"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['호갱노노']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 결과 저장용 딕셔너리\n","model_results = {}\n","\n","# 파일별 데이터 처리\n","for app, file_path in files.items():\n","    if os.path.exists(file_path):  # 파일 존재 여부 확인\n","        print(f\"Processing {app}...\")\n","\n","        # 데이터 읽기\n","        data = pd.read_csv(file_path)\n","\n","        # 소버전 기준 그룹화 (예: 1.0, 1.1)\n","        data['grouped_version'] = data['reviewCreatedVersion'].apply(lambda x: '.'.join(x.split('.')[:2]))\n","\n","        # 그룹별 결과 저장\n","        version_results = {}\n","\n","        # 소버전별 데이터 그룹화\n","        for version, group in data.groupby('grouped_version'):\n","            print(f\"  Processing version group: {version}\")\n","\n","            # 비어 있는 데이터 제거\n","            group = group[group['nouns_without_stopwords'].notnull() & (group['nouns_without_stopwords'].str.strip() != \"[]\")]\n","            if group.empty:\n","                print(f\"    Skipping version group {version}: No valid text data.\")\n","                continue\n","\n","            # 텍스트 데이터 벡터화\n","            texts = group['nouns_without_stopwords'].apply(lambda x: ' '.join(eval(x)))\n","            tfidf = TfidfVectorizer(max_features=1000)\n","            try:\n","                X_text = tfidf.fit_transform(texts)\n","            except ValueError as e:\n","                print(f\"    Error processing version group {version}: {e}\")\n","                continue\n","\n","            # 독립 변수와 종속 변수\n","            X = pd.DataFrame(X_text.toarray())\n","            y = group['score']\n","\n","            # 데이터가 충분한지 확인 (최소 10개의 데이터 필요)\n","            if len(group) < 10:\n","                print(f\"    Skipping version group {version}: Not enough data ({len(group)} rows)\")\n","                continue\n","\n","            # 데이터 분리\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","            # 모델 학습\n","            model = RandomForestRegressor(random_state=42)\n","            model.fit(X_train, y_train)\n","\n","            # 평가\n","            y_pred = model.predict(X_test)\n","            mse = mean_squared_error(y_test, y_pred)\n","            r2 = r2_score(y_test, y_pred)\n","\n","            print(f\"    Version group {version}: MSE = {mse}, R2 Score = {r2}\")\n","\n","            # 중요 피처 분석\n","            feature_importances = pd.Series(model.feature_importances_, index=tfidf.get_feature_names_out()).sort_values(ascending=False)\n","            print(f\"    {version} 상위 중요한 피처:\")\n","            print(feature_importances.head(5))\n","\n","            # 저장\n","            version_results[version] = {\n","                'MSE': mse,\n","                'R2 Score': r2,\n","                'Important Features': feature_importances.head(10).to_dict()\n","            }\n","\n","        # 앱 결과 저장\n","        model_results[app] = version_results\n","\n","# 결과 요약 출력\n","print(\"\\n모델링 결과 요약:\")\n","for app, version_data in model_results.items():\n","    print(f\"App: {app}\")\n","    for version, result in version_data.items():\n","        print(f\"  Version group {version}: MSE = {result['MSE']}, R2 Score = {result['R2 Score']}\")\n","        print(\"  상위 중요한 피처:\")\n","        for feature, importance in result['Important Features'].items():\n","            print(f\"    - {feature}: {importance}\")\n"],"metadata":{"id":"SxRuonidCLEN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 피터팬에 대해"],"metadata":{"id":"bsJCzGmIJ8s3"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","\n","# 앱 이름 및 파일 경로\n","selected_apps = ['피터팬']\n","files = {app: os.path.join(output_path, f\"cleaned_{app}_별점.csv\") for app in selected_apps}\n","\n","# 파일 처리 및 분석\n","for app, file_path in files.items():\n","    print(f\"Analyzing data for app: {app}\")\n","\n","    # 데이터 로드\n","    data = pd.read_csv(file_path)\n","\n","    # 필요한 열만 선택\n","    if 'nouns_without_stopwords' not in data.columns or 'score' not in data.columns:\n","        print(f\"Error: Missing required columns in file {file_path}\")\n","        continue\n","\n","    data = data[['nouns_without_stopwords', 'score']].dropna()\n","\n","    # TF-IDF 벡터화\n","    vectorizer = TfidfVectorizer(max_features=500)  # 상위 500개의 단어만 사용\n","    X = vectorizer.fit_transform(data['nouns_without_stopwords']).toarray()\n","    y = data['score']\n","\n","    # 학습 및 테스트 데이터 분리\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # 모델 학습\n","    model = RandomForestRegressor(random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    # 예측\n","    y_pred = model.predict(X_test)\n","\n","    # 평가\n","    mse = mean_squared_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","\n","    print(f\"Results for {app}:\")\n","    print(f\"Mean Squared Error: {mse}\")\n","    print(f\"R-squared: {r2}\\n\")\n"],"metadata":{"id":"DvMtD2SVH7Lb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733810702461,"user_tz":-540,"elapsed":31964,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"7dfaaaf5-eb74-4e9a-853c-2dcd3dbb8e79"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Analyzing data for app: 피터팬\n","Results for 피터팬:\n","Mean Squared Error: 1.120017749173\n","R-squared: 0.5221009646695718\n","\n"]}]},{"cell_type":"code","source":["# 특정 단어가 포함된 경우 예상 평점 계산 함수\n","def predict_score_for_word(word, vectorizer, model):\n","    \"\"\"\n","    특정 단어의 예상 평점을 계산합니다.\n","    :param word: 예상 평점을 확인할 단어 (str)\n","    :param vectorizer: 학습에 사용된 TfidfVectorizer\n","    :param model: 학습된 모델 (RandomForestRegressor)\n","    :return: 예상 평점 (float)\n","    \"\"\"\n","    # 입력 단어를 TF-IDF 벡터로 변환\n","    word_vector = vectorizer.transform([word]).toarray()\n","\n","    # 모델을 통해 예상 평점 예측\n","    predicted_score = model.predict(word_vector)[0]\n","\n","    return predicted_score\n","\n","# 단어 별 예상 평점 예측\n","word_to_test = '짜증'  # 확인할 단어\n","predicted_score = predict_score_for_word(word_to_test, vectorizer, model)\n","print(f\"단어 '{word_to_test}'에 대한 예상 평점: {predicted_score:.2f}\")\n"],"metadata":{"id":"X3nkYLngI6oE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733810702461,"user_tz":-540,"elapsed":19,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"1ee6cc54-a4d3-4cd3-d165-0c64777e7796"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 '짜증'에 대한 예상 평점: 1.96\n"]}]},{"cell_type":"markdown","source":["### 전체 모든 앱에 대해 한번에 실행해버림\n","def process_app(app_name, file_path, test_word):\n","\n","'test_word' 칸에 이런 단어 들어가있을때 대충 이 점수일것이다 를 알고싶은 단어 집어넣기."],"metadata":{"id":"MahpW0YJKpQJ"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 로드 함수\n","def load_data(file_path):\n","    data = pd.read_csv(file_path)\n","    if 'nouns_without_stopwords' not in data.columns or 'score' not in data.columns:\n","        raise ValueError(f\"Required columns missing in {file_path}\")\n","    return data[['nouns_without_stopwords', 'score']].dropna()\n","\n","# TF-IDF 벡터화 및 모델 학습 함수\n","def train_model(data):\n","    vectorizer = TfidfVectorizer(max_features=500)\n","    X = vectorizer.fit_transform(data['nouns_without_stopwords']).toarray()\n","    y = data['score']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    model = RandomForestRegressor(random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    y_pred = model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","\n","    print(f\"Mean Squared Error: {mse}\")\n","    print(f\"R-squared: {r2}\")\n","    return vectorizer, model\n","\n","# 특정 단어 예상 평점 계산 함수\n","def predict_score_for_word(word, vectorizer, model):\n","    word_vector = vectorizer.transform([word]).toarray()\n","    predicted_score = model.predict(word_vector)[0]\n","    return predicted_score\n","\n","# 앱 데이터 처리\n","def process_app(app_name, file_path, test_word):\n","    print(f\"Processing app: {app_name}\")\n","    data = load_data(file_path)\n","    vectorizer, model = train_model(data)\n","    predicted_score = predict_score_for_word(test_word, vectorizer, model)\n","    print(f\"Predicted score for '{test_word}' in {app_name}: {predicted_score:.2f}\\n\")\n","\n","# 앱별 파일 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","apps = {\n","    '피터팬': f\"{output_path}/cleaned_피터팬_별점.csv\",\n","    '다방': f\"{output_path}/cleaned_다방_별점.csv\",\n","    '직방': f\"{output_path}/cleaned_직방_별점.csv\",\n","    '호갱노노': f\"{output_path}/cleaned_호갱노노_별점.csv\",\n","    '네이버부동산': f\"{output_path}/cleaned_네이버부동산_별점.csv\"\n","}\n","\n","# 앱별 독립적 분석\n","process_app('피터팬', apps['피터팬'], '사기')\n","process_app('다방', apps['다방'], '사기')\n","process_app('직방', apps['직방'], '사기')\n","process_app('호갱노노', apps['호갱노노'], '사기')\n","process_app('네이버부동산', apps['네이버부동산'], '사기')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QiFRESMJo-W","executionInfo":{"status":"ok","timestamp":1733811357891,"user_tz":-540,"elapsed":386509,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"b612a542-d0b2-41e2-f129-7582a4e89206"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing app: 피터팬\n","Mean Squared Error: 1.120017749173\n","R-squared: 0.5221009646695718\n","Predicted score for '사기' in 피터팬: 1.24\n","\n","Processing app: 다방\n","Mean Squared Error: 1.069345658571159\n","R-squared: 0.57218462385512\n","Predicted score for '사기' in 다방: 1.00\n","\n","Processing app: 직방\n","Mean Squared Error: 1.549488268641228\n","R-squared: 0.40939370520237206\n","Predicted score for '사기' in 직방: 1.94\n","\n","Processing app: 호갱노노\n","Mean Squared Error: 1.8844002539901519\n","R-squared: 0.3646737711082856\n","Predicted score for '사기' in 호갱노노: 4.60\n","\n","Processing app: 네이버부동산\n","Mean Squared Error: 1.656851364777668\n","R-squared: 0.21276960386111832\n","Predicted score for '사기' in 네이버부동산: 3.40\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import pickle\n","\n","# 데이터 로드 함수\n","def load_data(file_path):\n","    data = pd.read_csv(file_path)\n","    if 'nouns_without_stopwords' not in data.columns or 'score' not in data.columns:\n","        raise ValueError(f\"Required columns missing in {file_path}\")\n","    return data[['nouns_without_stopwords', 'score']].dropna()\n","\n","# 모델 학습 및 저장 함수\n","def train_and_save_model(app_name, file_path):\n","    data = load_data(file_path)\n","    vectorizer = TfidfVectorizer(max_features=500)\n","    X = vectorizer.fit_transform(data['nouns_without_stopwords']).toarray()\n","    y = data['score']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    model = RandomForestRegressor(random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    y_pred = model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","\n","    print(f\"{app_name} - Mean Squared Error: {mse}\")\n","    print(f\"{app_name} - R-squared: {r2}\")\n","\n","    # 모델과 벡터라이저 저장\n","    with open(f\"{app_name}_vectorizer.pkl\", 'wb') as vec_file:\n","        pickle.dump(vectorizer, vec_file)\n","    with open(f\"{app_name}_model.pkl\", 'wb') as model_file:\n","        pickle.dump(model, model_file)\n","    print(f\"Model and vectorizer saved for {app_name}\")\n","\n","# 앱별 파일 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","apps = {\n","    '피터팬': f\"{output_path}/cleaned_피터팬_별점.csv\",\n","    '다방': f\"{output_path}/cleaned_다방_별점.csv\",\n","    '직방': f\"{output_path}/cleaned_직방_별점.csv\",\n","    '호갱노노': f\"{output_path}/cleaned_호갱노노_별점.csv\",\n","    '네이버부동산': f\"{output_path}/cleaned_네이버부동산_별점.csv\"\n","}\n","\n","# 모든 앱에 대해 모델 학습 및 저장\n","for app_name, file_path in apps.items():\n","    try:\n","        train_and_save_model(app_name, file_path)\n","    except Exception as e:\n","        print(f\"Error processing {app_name}: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWPaUZWAOXki","outputId":"0a69271f-df7a-4051-c472-3e205ca73314","executionInfo":{"status":"ok","timestamp":1733812001798,"user_tz":-540,"elapsed":643908,"user":{"displayName":"Soobin","userId":"01300891231025069619"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["피터팬 - Mean Squared Error: 1.120017749173\n","피터팬 - R-squared: 0.5221009646695718\n","Model and vectorizer saved for 피터팬\n","다방 - Mean Squared Error: 1.069345658571159\n","다방 - R-squared: 0.57218462385512\n","Model and vectorizer saved for 다방\n","직방 - Mean Squared Error: 1.549488268641228\n","직방 - R-squared: 0.40939370520237206\n","Model and vectorizer saved for 직방\n","호갱노노 - Mean Squared Error: 1.8844002539901519\n","호갱노노 - R-squared: 0.3646737711082856\n","Model and vectorizer saved for 호갱노노\n","네이버부동산 - Mean Squared Error: 1.656851364777668\n","네이버부동산 - R-squared: 0.21276960386111832\n","Model and vectorizer saved for 네이버부동산\n"]}]},{"cell_type":"code","source":["# 모델 로드 함수\n","def load_model_and_vectorizer(app_name):\n","    with open(f\"{app_name}_vectorizer.pkl\", 'rb') as vec_file:\n","        vectorizer = pickle.load(vec_file)\n","    with open(f\"{app_name}_model.pkl\", 'rb') as model_file:\n","        model = pickle.load(model_file)\n","    print(f\"Loaded vectorizer and model for {app_name}\")\n","    return vectorizer, model\n","\n","# 특정 단어 예상 점수 계산 함수\n","def predict_scores_for_words(app_name, test_words):\n","    vectorizer, model = load_model_and_vectorizer(app_name)\n","    for word in test_words:\n","        word_vector = vectorizer.transform([word]).toarray()\n","        predicted_score = model.predict(word_vector)[0]\n","        print(f\"Predicted score for '{word}' in {app_name}: {predicted_score:.2f}\")\n","    print(\"\\n\")\n","\n","# 테스트할 단어\n","test_words = ['사기', '좋아요', '최악', '친절']\n","\n","# 모든 앱에 대해 단어 예측 실행\n","for app_name in apps.keys():\n","    try:\n","        predict_scores_for_words(app_name, test_words)\n","    except Exception as e:\n","        print(f\"Error processing {app_name}: {e}\")\n"],"metadata":{"id":"daIFXezEPTEu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733812001799,"user_tz":-540,"elapsed":8,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"d8a78f79-f43b-4dd6-94f5-320259710a23"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded vectorizer and model for 피터팬\n","Predicted score for '사기' in 피터팬: 1.24\n","Predicted score for '좋아요' in 피터팬: 4.83\n","Predicted score for '최악' in 피터팬: 4.41\n","Predicted score for '친절' in 피터팬: 4.83\n","\n","\n","Loaded vectorizer and model for 다방\n","Predicted score for '사기' in 다방: 1.00\n","Predicted score for '좋아요' in 다방: 4.68\n","Predicted score for '최악' in 다방: 2.29\n","Predicted score for '친절' in 다방: 4.68\n","\n","\n","Loaded vectorizer and model for 직방\n","Predicted score for '사기' in 직방: 1.94\n","Predicted score for '좋아요' in 직방: 4.40\n","Predicted score for '최악' in 직방: 1.00\n","Predicted score for '친절' in 직방: 4.40\n","\n","\n","Loaded vectorizer and model for 호갱노노\n","Predicted score for '사기' in 호갱노노: 4.60\n","Predicted score for '좋아요' in 호갱노노: 4.60\n","Predicted score for '최악' in 호갱노노: 2.69\n","Predicted score for '친절' in 호갱노노: 4.60\n","\n","\n","Loaded vectorizer and model for 네이버부동산\n","Predicted score for '사기' in 네이버부동산: 3.40\n","Predicted score for '좋아요' in 네이버부동산: 2.83\n","Predicted score for '최악' in 네이버부동산: 1.00\n","Predicted score for '친절' in 네이버부동산: 2.83\n","\n","\n"]}]},{"cell_type":"code","source":["!pip uninstall -y tensorflow\n","!pip install tensorflow-cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWrUQooinMSK","executionInfo":{"status":"ok","timestamp":1733812051550,"user_tz":-540,"elapsed":49754,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"918de78b-4554-40e4-f74d-4aac8f1f1185"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.17.1\n","Uninstalling tensorflow-2.17.1:\n","  Successfully uninstalled tensorflow-2.17.1\n","Collecting tensorflow-cpu\n","  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.68.1)\n","Collecting tensorboard<2.19,>=2.18 (from tensorflow-cpu)\n","  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.5.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.26.4)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.12.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n","Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard, tensorflow-cpu\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.1\n","    Uninstalling tensorboard-2.17.1:\n","      Successfully uninstalled tensorboard-2.17.1\n","Successfully installed tensorboard-2.18.0 tensorflow-cpu-2.18.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertTokenizer, BertModel\n","import torch.nn as nn\n","\n","# 데이터 로드 함수\n","def load_data(file_path):\n","    data = pd.read_csv(file_path)\n","    if 'nouns_without_stopwords' not in data.columns or 'score' not in data.columns:\n","        raise ValueError(f\"Required columns missing in {file_path}\")\n","    return data[['nouns_without_stopwords', 'score']].dropna()\n","\n","# 랜덤포레스트 모델 학습 및 평가\n","def random_forest_model(data):\n","    vectorizer = TfidfVectorizer(max_features=500)\n","    X = vectorizer.fit_transform(data['nouns_without_stopwords']).toarray()\n","    y = data['score']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    model = RandomForestRegressor(random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    y_pred = model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse = mean_squared_error(y_test, y_pred, squared=False)  # RMSE\n","    r2 = r2_score(y_test, y_pred)\n","\n","    return vectorizer, model, mse, rmse, r2\n","\n","# BERT 데이터셋 클래스\n","class ReviewDataset(Dataset):\n","    def __init__(self, texts, targets, tokenizer, max_length):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        target = self.targets[idx]\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt',\n","        )\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(0),\n","            'attention_mask': encoding['attention_mask'].squeeze(0),\n","            'target': torch.tensor(target, dtype=torch.float),\n","        }\n","\n","# BERT 모델 정의\n","class BERTRegressor(nn.Module):\n","    def __init__(self, bert_model_name):\n","        super(BERTRegressor, self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model_name)\n","        self.drop = nn.Dropout(p=0.3)\n","        self.out = nn.Linear(self.bert.config.hidden_size, 1)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output\n","        output = self.drop(pooled_output)\n","        return self.out(output)\n","\n","# BERT 모델 학습 및 평가\n","def bert_model(data, bert_model_name='bert-base-uncased', max_length=128, batch_size=16, epochs=3):\n","    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n","    dataset = ReviewDataset(\n","        texts=data['nouns_without_stopwords'].tolist(),\n","        targets=data['score'].tolist(),\n","        tokenizer=tokenizer,\n","        max_length=max_length,\n","    )\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = BERTRegressor(bert_model_name).to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","    criterion = nn.MSELoss()\n","\n","    # 모델 학습\n","    model.train()\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            targets = batch['target'].to(device)\n","\n","            outputs = model(input_ids, attention_mask).squeeze(-1)\n","            loss = criterion(outputs, targets)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","\n","        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader):.4f}\")\n","\n","    # 모델 평가\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            targets = batch['target'].to(device)\n","\n","            outputs = model(input_ids, attention_mask).squeeze(-1)\n","            y_true.extend(targets.tolist())\n","            y_pred.extend(outputs.tolist())\n","\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    return mse, rmse, r2\n","\n","# 앱별 독립적 분석\n","def process_app(app_name, file_path):\n","    print(f\"\\nProcessing app: {app_name}\")\n","    data = load_data(file_path)\n","\n","    # 랜덤포레스트 모델 학습 및 결과 출력\n","    print(\"Training Random Forest Model...\")\n","    vectorizer, rf_model, rf_mse, rf_rmse, rf_r2 = random_forest_model(data)\n","    print(f\"Random Forest Results for {app_name}:\")\n","    print(f\"{'MSE':<10}: {rf_mse:.2f}\")\n","    print(f\"{'RMSE':<10}: {rf_rmse:.2f}\")\n","    print(f\"{'R-squared':<10}: {rf_r2:.2f}\\n\")\n","\n","    # BERT 모델 학습 및 결과 출력\n","    print(\"Training BERT Model...\")\n","    bert_mse, bert_rmse, bert_r2 = bert_model(data)\n","    print(f\"BERT Results for {app_name}:\")\n","    print(f\"{'MSE':<10}: {bert_mse:.2f}\")\n","    print(f\"{'RMSE':<10}: {bert_rmse:.2f}\")\n","    print(f\"{'R-squared':<10}: {bert_r2:.2f}\\n\")\n","\n","# 앱별 파일 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","apps = {\n","    '피터팬': f\"{output_path}/cleaned_피터팬_별점.csv\",\n","    '다방': f\"{output_path}/cleaned_다방_별점.csv\",\n","    '직방': f\"{output_path}/cleaned_직방_별점.csv\",\n","    '호갱노노': f\"{output_path}/cleaned_호갱노노_별점.csv\",\n","    '네이버부동산': f\"{output_path}/cleaned_네이버부동산_별점.csv\"\n","}\n","\n","# 앱별 독립적 분석 실행\n","for app_name, file_path in apps.items():\n","    process_app(app_name, file_path)\n"],"metadata":{"id":"-vTaWIcceHEE","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d22e090f326c46a2addabd25938c3bf5","301658b9f13b4e4ab9698afa9e84078e","a1c2e03e6f804e56be2acc771e18b76b","3d834bd7e10d4727b218360cbba3adba","df7e15759c464347a3b8bd9ddd36c96a","b98ada64f7ad4012aa2a8a028670c2b1","9851a7bd5841420bba2b46225137567d","4f8c8611b04147aebeae027f01541da3","f9b0fbffc15a421c9b6aa43cc7af664b","a9f1608aa1664d24962b68f91c5c0ccd","54a8d483397c43b99d0f529c07aa8548","7d1d17f759704aa3a04367fd1573a052","6406610b2ef04b08a4dbfa2576e18aa0","be690b24fb03468ea17a6b5d4a757116","4c73868dba9845eaaf1601a7d0cad9e2","81e1894e17714bfcab8ab9b3055aa7be","66931a5dcbbd4f7cb515761e9a1b707f","b9bc92c5061b44208352229c7f53161b","a48c9eb04f34460bbae613502fc7870e","6f0ed73e63c145eeb955322057fa475f","d19972b4ddb346dc8fb3705380d84351","5b30f352bf1f4af09a6a492a24f99b5a","09fe0e8a998c437394460a48321e67d9","f737bfa537b74cb8874e3177e0e72763","2772ef6f06234ec2a2968fd23458081f","19fff7e212174ffe912901973b248653","40fe215f0a0148a699783f2c9174500d","7bdc202cd7964022a7af773b492b1dcd","465501d42c65416083a794c527c568dc","171eb1fa692e4ff69a9dfeac8832a6ce","894eb3f8149e4584bd5368536c67c028","ca86e92dbd174731af92f8cc730351bf","a7b11473e72e402ab71b737f8627bd57","7e6e5e176dc241a2bdb7f4ab145038b8","04d1e8ea3b2d4cdbb34bc4392d9e4095","74cf4c840c2141698c722210d26c77ce","38c4ee4f6a0448b39a1ce40121a46cfd","cdeda28e27e84e339898f46355923423","94e8002bf21a423aa011d7134083294b","fdd2a883fda04752ac3326117939737d","d669affab0a54dce8b91e3e7c5a4f1aa","7249436c7daa450c8c280511928b2187","1ac1c728bfd344faae7dbdbc5543e180","a70f9f19123d4e37b4a47c06417f7d3b","3e3a76fe8c7142be844e1f64b7f58536","6754f952cfb948e0b218ed6f5f40921a","bf2acf19e44b46e4ae8a0895c24f98f4","6f8d8e4cd9314621890f14d34114baf4","67fba1c363184b87a1df269665a3361a","69f0a7373af94dc1abf806fd5004a0c5","aaa7942a5bce4672b4ee7cc48243d63c","20debfa94e7e4285a6e62ffca4dc6753","56d5b9e473ec478eb58a90dfbd6164c6","4a703331d0c346469f966cb60cdb2623","793d52ac2e8c422db680d7a776ec5e64"]},"executionInfo":{"status":"ok","timestamp":1733816812044,"user_tz":-540,"elapsed":1526167,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"c19ea139-4a25-4926-fea3-665b5cd49059"},"execution_count":17,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Processing app: 피터팬\n","Training Random Forest Model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Random Forest Results for 피터팬:\n","MSE       : 1.12\n","RMSE      : 1.06\n","R-squared : 0.52\n","\n","Training BERT Model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d22e090f326c46a2addabd25938c3bf5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d1d17f759704aa3a04367fd1573a052","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09fe0e8a998c437394460a48321e67d9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e6e5e176dc241a2bdb7f4ab145038b8","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e3a76fe8c7142be844e1f64b7f58536","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/3, Loss: 2.8208\n","Epoch 2/3, Loss: 1.1889\n","Epoch 3/3, Loss: 1.0785\n","BERT Results for 피터팬:\n","MSE       : 0.96\n","RMSE      : 0.98\n","R-squared : 0.56\n","\n","\n","Processing app: 다방\n","Training Random Forest Model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Random Forest Results for 다방:\n","MSE       : 1.07\n","RMSE      : 1.03\n","R-squared : 0.57\n","\n","Training BERT Model...\n","Epoch 1/3, Loss: 2.0171\n","Epoch 2/3, Loss: 1.1876\n","Epoch 3/3, Loss: 1.0308\n","BERT Results for 다방:\n","MSE       : 0.87\n","RMSE      : 0.93\n","R-squared : 0.65\n","\n","\n","Processing app: 직방\n","Training Random Forest Model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Random Forest Results for 직방:\n","MSE       : 1.55\n","RMSE      : 1.24\n","R-squared : 0.41\n","\n","Training BERT Model...\n","Epoch 1/3, Loss: 1.9626\n","Epoch 2/3, Loss: 1.5530\n","Epoch 3/3, Loss: 1.4258\n","BERT Results for 직방:\n","MSE       : 1.23\n","RMSE      : 1.11\n","R-squared : 0.53\n","\n","\n","Processing app: 호갱노노\n","Training Random Forest Model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Random Forest Results for 호갱노노:\n","MSE       : 1.88\n","RMSE      : 1.37\n","R-squared : 0.36\n","\n","Training BERT Model...\n","Epoch 1/3, Loss: 4.3334\n","Epoch 2/3, Loss: 2.2638\n","Epoch 3/3, Loss: 2.0583\n","BERT Results for 호갱노노:\n","MSE       : 1.82\n","RMSE      : 1.35\n","R-squared : 0.37\n","\n","\n","Processing app: 네이버부동산\n","Training Random Forest Model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Random Forest Results for 네이버부동산:\n","MSE       : 1.66\n","RMSE      : 1.29\n","R-squared : 0.21\n","\n","Training BERT Model...\n","Epoch 1/3, Loss: 2.2488\n","Epoch 2/3, Loss: 1.9019\n","Epoch 3/3, Loss: 1.7964\n","BERT Results for 네이버부동산:\n","MSE       : 1.62\n","RMSE      : 1.27\n","R-squared : 0.21\n","\n"]}]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer\n","AutoModel.from_pretrained(\"bert-base-uncased\")\n","AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"],"metadata":{"id":"yAZDPC2QmJ53","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733816812484,"user_tz":-540,"elapsed":441,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"e664de2a-57af-485f-99c0-b7f474509fb8"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n","\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["!pip install transformers tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHgtcAh_6F2t","executionInfo":{"status":"ok","timestamp":1733816814550,"user_tz":-540,"elapsed":2067,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"422d62da-92ed-4321-b1ef-42fd1fd7268d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertTokenizer, BertModel\n","import torch\n","import torch.nn as nn\n","from tqdm import tqdm\n","\n","# 데이터 로드 함수\n","def load_data(file_path):\n","    data = pd.read_csv(file_path)\n","    if 'nouns_without_stopwords' not in data.columns or 'score' not in data.columns:\n","        raise ValueError(f\"Required columns missing in {file_path}\")\n","    data = data[['nouns_without_stopwords', 'score']].dropna()\n","\n","    # 데이터 크기 줄이기 (10%만 샘플링)\n","    data = data.sample(frac=0.1, random_state=42)\n","    return data\n","\n","# 랜덤포레스트 모델 학습 및 평가\n","def random_forest_model(data):\n","    vectorizer = TfidfVectorizer(max_features=500)\n","    X = vectorizer.fit_transform(data['nouns_without_stopwords']).toarray()\n","    y = data['score']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    model = RandomForestRegressor(random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    y_pred = model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_test, y_pred)\n","\n","    return vectorizer, model, mse, rmse, r2\n","\n","# BERT 데이터셋 클래스\n","class ReviewDataset(Dataset):\n","    def __init__(self, texts, targets, tokenizer, max_length):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        target = self.targets[idx]\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt',\n","        )\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(0),\n","            'attention_mask': encoding['attention_mask'].squeeze(0),\n","            'target': torch.tensor(target, dtype=torch.float),\n","        }\n","\n","# BERT 모델 정의\n","class BERTRegressor(nn.Module):\n","    def __init__(self, bert_model_name):\n","        super(BERTRegressor, self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model_name)\n","        self.drop = nn.Dropout(p=0.3)\n","        self.out = nn.Linear(self.bert.config.hidden_size, 1)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output\n","        output = self.drop(pooled_output)\n","        return self.out(output)\n","\n","# BERT 모델 학습 및 평가\n","def bert_model(data, bert_model_name='bert-base-uncased', max_length=64, batch_size=8, epochs=3):\n","    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n","\n","    # Train-Test Split\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        data['nouns_without_stopwords'], data['score'], test_size=0.2, random_state=42\n","    )\n","\n","    train_dataset = ReviewDataset(\n","        texts=X_train.tolist(),\n","        targets=y_train.tolist(),\n","        tokenizer=tokenizer,\n","        max_length=max_length,\n","    )\n","    test_dataset = ReviewDataset(\n","        texts=X_test.tolist(),\n","        targets=y_test.tolist(),\n","        tokenizer=tokenizer,\n","        max_length=max_length,\n","    )\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = BERTRegressor(bert_model_name).to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","    criterion = nn.MSELoss()\n","\n","    # 모델 학습\n","    model.train()\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        loop = tqdm(train_loader, leave=True, desc=f'Epoch {epoch + 1}/{epochs}')\n","        for batch in loop:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            targets = batch['target'].to(device)\n","\n","            outputs = model(input_ids, attention_mask).squeeze(-1)\n","            loss = criterion(outputs, targets)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","            loop.set_postfix(loss=loss.item())\n","\n","        print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader):.4f}\")\n","\n","    # 모델 평가\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            targets = batch['target'].to(device)\n","\n","            outputs = model(input_ids, attention_mask).squeeze(-1)\n","            y_true.extend(targets.tolist())\n","            y_pred.extend(outputs.tolist())\n","\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    return mse, rmse, r2\n","\n","# 앱별 독립적 분석\n","def process_app(app_name, file_path):\n","    print(f\"\\nProcessing app: {app_name}\")\n","\n","    # GPU 확인\n","    if torch.cuda.is_available():\n","        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n","    else:\n","        print(\"GPU is not available. Using CPU.\")\n","\n","    data = load_data(file_path)\n","\n","    # 랜덤포레스트 모델 학습 및 결과 출력\n","    print(\"Training Random Forest Model...\")\n","    vectorizer, rf_model, rf_mse, rf_rmse, rf_r2 = random_forest_model(data)\n","    print(f\"Random Forest Results for {app_name}:\")\n","    print(f\"{'MSE':<10}: {rf_mse:.2f}\")\n","    print(f\"{'RMSE':<10}: {rf_rmse:.2f}\")\n","    print(f\"{'R-squared':<10}: {rf_r2:.2f}\\n\")\n","\n","    # BERT 모델 학습 및 결과 출력\n","    print(\"Training BERT Model...\")\n","    bert_mse, bert_rmse, bert_r2 = bert_model(data)\n","    print(f\"BERT Results for {app_name}:\")\n","    print(f\"{'MSE':<10}: {bert_mse:.2f}\")\n","    print(f\"{'RMSE':<10}: {bert_rmse:.2f}\")\n","    print(f\"{'R-squared':<10}: {bert_r2:.2f}\\n\")\n","\n","# 앱별 파일 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","apps = {\n","    '피터팬':f\"{output_path}/cleaned_피터팬_별점.csv\",\n","    '다방':f\"{output_path}/cleaned_피터팬_별점.csv\",\n","    '직방': f\"{output_path}/cleaned_직방_별점.csv\",\n","    '호갱노노': f\"{output_path}/cleaned_호갱노노_별점.csv\",\n","    '네이버부동산': f\"{output_path}/cleaned_네이버부동산_별점.csv\"\n","}\n","\n","# 앱별 독립적 분석 실행\n","for app_name, file_path in apps.items():\n","    process_app(app_name, file_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHhh5Y5G732M","executionInfo":{"status":"ok","timestamp":1733816967766,"user_tz":-540,"elapsed":153218,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"ecc731fe-3118-4622-f72b-cda74c42d685"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processing app: 피터팬\n","Using GPU: Tesla T4\n","Training Random Forest Model...\n","Random Forest Results for 피터팬:\n","MSE       : 1.52\n","RMSE      : 1.23\n","R-squared : 0.41\n","\n","Training BERT Model...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3: 100%|██████████| 45/45 [00:05<00:00,  8.13it/s, loss=4.94]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 9.8275\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 45/45 [00:05<00:00,  8.25it/s, loss=1.61]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Loss: 3.0149\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 45/45 [00:05<00:00,  8.18it/s, loss=0.911]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Loss: 1.6876\n","BERT Results for 피터팬:\n","MSE       : 1.52\n","RMSE      : 1.23\n","R-squared : 0.40\n","\n","\n","Processing app: 다방\n","Using GPU: Tesla T4\n","Training Random Forest Model...\n","Random Forest Results for 다방:\n","MSE       : 1.52\n","RMSE      : 1.23\n","R-squared : 0.41\n","\n","Training BERT Model...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3: 100%|██████████| 45/45 [00:05<00:00,  8.12it/s, loss=3.7]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 8.0063\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 45/45 [00:05<00:00,  8.12it/s, loss=2.66]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Loss: 2.4808\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 45/45 [00:05<00:00,  8.16it/s, loss=0.239]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Loss: 1.6621\n","BERT Results for 다방:\n","MSE       : 1.59\n","RMSE      : 1.26\n","R-squared : 0.38\n","\n","\n","Processing app: 직방\n","Using GPU: Tesla T4\n","Training Random Forest Model...\n","Random Forest Results for 직방:\n","MSE       : 1.87\n","RMSE      : 1.37\n","R-squared : 0.33\n","\n","Training BERT Model...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3: 100%|██████████| 221/221 [00:27<00:00,  8.12it/s, loss=2.36]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 3.9071\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 221/221 [00:27<00:00,  8.11it/s, loss=2.65]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Loss: 2.1359\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 221/221 [00:26<00:00,  8.21it/s, loss=2.32]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Loss: 1.8979\n","BERT Results for 직방:\n","MSE       : 1.81\n","RMSE      : 1.34\n","R-squared : 0.35\n","\n","\n","Processing app: 호갱노노\n","Using GPU: Tesla T4\n","Training Random Forest Model...\n","Random Forest Results for 호갱노노:\n","MSE       : 2.06\n","RMSE      : 1.44\n","R-squared : 0.24\n","\n","Training BERT Model...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3: 100%|██████████| 21/21 [00:02<00:00,  8.39it/s, loss=11.7]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 9.8174\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 21/21 [00:02<00:00,  8.27it/s, loss=4.64]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Loss: 4.4287\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 21/21 [00:02<00:00,  8.26it/s, loss=2.76]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Loss: 2.9462\n","BERT Results for 호갱노노:\n","MSE       : 2.40\n","RMSE      : 1.55\n","R-squared : 0.12\n","\n","\n","Processing app: 네이버부동산\n","Using GPU: Tesla T4\n","Training Random Forest Model...\n","Random Forest Results for 네이버부동산:\n","MSE       : 1.97\n","RMSE      : 1.40\n","R-squared : -0.17\n","\n","Training BERT Model...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3: 100%|██████████| 21/21 [00:02<00:00,  8.19it/s, loss=5.47]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 4.0685\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 21/21 [00:02<00:00,  8.20it/s, loss=2.6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Loss: 2.9803\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 21/21 [00:02<00:00,  8.17it/s, loss=0.984]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Loss: 2.6608\n","BERT Results for 네이버부동산:\n","MSE       : 1.79\n","RMSE      : 1.34\n","R-squared : -0.07\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","import pickle\n","\n","# 데이터 로드 함수\n","def load_data(file_path):\n","    data = pd.read_csv(file_path)\n","    if 'nouns_without_stopwords' not in data.columns or 'score' not in data.columns:\n","        raise ValueError(f\"Required columns missing in {file_path}\")\n","    return data[['nouns_without_stopwords', 'score']].dropna()\n","\n","# 커스텀 데이터셋\n","class ReviewDataset(Dataset):\n","    def __init__(self, reviews, scores, tokenizer, max_len=128):\n","        self.reviews = reviews\n","        self.scores = scores\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.reviews)\n","\n","    def __getitem__(self, idx):\n","        review = self.reviews.iloc[idx]\n","        score = self.scores.iloc[idx]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            review,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True\n","        )\n","\n","        return {\n","            'input_ids': torch.tensor(encoding['input_ids'], dtype=torch.long),\n","            'attention_mask': torch.tensor(encoding['attention_mask'], dtype=torch.long),\n","            'score': torch.tensor(score, dtype=torch.float)\n","        }\n","\n","# 모델 학습 및 저장 함수\n","def train_and_save_model(app_name, file_path):\n","    data = load_data(file_path)\n","\n","    # Load tokenizer\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","    # Split data\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        data['nouns_without_stopwords'], data['score'], test_size=0.2, random_state=42\n","    )\n","\n","    # Create datasets and dataloaders\n","    train_dataset = ReviewDataset(X_train, y_train, tokenizer)\n","    test_dataset = ReviewDataset(X_test, y_test, tokenizer)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=16)\n","\n","    # Load BERT model\n","    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n","    model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n","\n","    optimizer = AdamW(model.parameters(), lr=2e-5)\n","\n","    # Training loop\n","    epochs = 3\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in train_loader:\n","            input_ids = batch['input_ids'].to(model.device)\n","            attention_mask = batch['attention_mask'].to(model.device)\n","            scores = batch['score'].to(model.device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=scores.unsqueeze(1))\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f\"{app_name} - Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n","\n","    # Evaluation\n","    model.eval()\n","    y_pred, y_true = [], []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids = batch['input_ids'].to(model.device)\n","            attention_mask = batch['attention_mask'].to(model.device)\n","            scores = batch['score'].to(model.device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits.squeeze().cpu().numpy()\n","            y_pred.extend(logits)\n","            y_true.extend(scores.cpu().numpy())\n","\n","    mse = mean_squared_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    print(f\"{app_name} - Mean Squared Error: {mse}\")\n","    print(f\"{app_name} - R-squared: {r2}\")\n","\n","    # Save model and tokenizer\n","    model.save_pretrained(f\"{app_name}_model\")\n","    tokenizer.save_pretrained(f\"{app_name}_tokenizer\")\n","    print(f\"Model and tokenizer saved for {app_name}\")\n","\n","# 모델 로드 함수\n","def load_model_and_tokenizer(app_name):\n","    model = BertForSequenceClassification.from_pretrained(f\"{app_name}_model\")\n","    tokenizer = BertTokenizer.from_pretrained(f\"{app_name}_tokenizer\")\n","    print(f\"Loaded model and tokenizer for {app_name}\")\n","    return model, tokenizer\n","\n","# 특정 단어 예상 점수 계산 함수\n","def predict_scores_for_words(app_name, test_words):\n","    model, tokenizer = load_model_and_tokenizer(app_name)\n","    model.eval()\n","\n","    predictions = []\n","    for word in test_words:\n","        encoding = tokenizer(\n","            word,\n","            add_special_tokens=True,\n","            max_length=128,\n","            return_tensors=\"pt\",\n","            padding='max_length',\n","            truncation=True\n","        )\n","        input_ids = encoding['input_ids'].to(model.device)\n","        attention_mask = encoding['attention_mask'].to(model.device)\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            predicted_score = outputs.logits.squeeze().item()\n","            predictions.append((word, predicted_score))\n","            print(f\"Predicted score for '{word}' in {app_name}: {predicted_score:.2f}\")\n","\n","    print(\"\\n\")\n","    return predictions\n","\n","# 앱별 파일 경로 설정\n","output_path = '/content/drive/MyDrive/2024/TextMining/reviewmodel'\n","apps = {\n","    '피터팬': f\"{output_path}/cleaned_피터팬_별점.csv\",\n","    '다방': f\"{output_path}/cleaned_다방_별점.csv\",\n","    '직방': f\"{output_path}/cleaned_직방_별점.csv\",\n","    '호갱노노': f\"{output_path}/cleaned_호갱노노_별점.csv\",\n","    '네이버부동산': f\"{output_path}/cleaned_네이버부동산_별점.csv\"\n","}\n","\n","# 모든 앱에 대해 모델 학습 및 저장\n","for app_name, file_path in apps.items():\n","    try:\n","        train_and_save_model(app_name, file_path)\n","    except Exception as e:\n","        print(f\"Error processing {app_name}: {e}\")\n","\n","# 테스트할 단어\n","test_words = ['사기', '좋아요', '최악', '친절']\n","\n","# 모든 앱에 대해 단어 예측 실행\n","for app_name in apps.keys():\n","    try:\n","        predict_scores_for_words(app_name, test_words)\n","    except Exception as e:\n","        print(f\"Error processing {app_name}: {e}\")\n"],"metadata":{"id":"y4OZdbbh76kr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733820762474,"user_tz":-540,"elapsed":2514926,"user":{"displayName":"Soobin","userId":"01300891231025069619"}},"outputId":"cec4d859-05ad-430d-c8b3-f47150e42e62"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["피터팬 - Epoch 1/3, Loss: 2.5641950728495915\n","피터팬 - Epoch 2/3, Loss: 1.268910451663865\n","피터팬 - Epoch 3/3, Loss: 1.1265691538320648\n","피터팬 - Mean Squared Error: 1.1251959800720215\n","피터팬 - R-squared: 0.5198914663228766\n","Model and tokenizer saved for 피터팬\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["다방 - Epoch 1/3, Loss: 1.7968297883509152\n","다방 - Epoch 2/3, Loss: 1.1397271380426894\n","다방 - Epoch 3/3, Loss: 0.9859451511987003\n","다방 - Mean Squared Error: 1.1104443073272705\n","다방 - R-squared: 0.5557422279915839\n","Model and tokenizer saved for 다방\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["직방 - Epoch 1/3, Loss: 1.9749312913720158\n","직방 - Epoch 2/3, Loss: 1.5539025291395576\n","직방 - Epoch 3/3, Loss: 1.4192694938350199\n","직방 - Mean Squared Error: 1.4907722473144531\n","직방 - R-squared: 0.4317740388417002\n","Model and tokenizer saved for 직방\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["호갱노노 - Epoch 1/3, Loss: 3.5301436799414017\n","호갱노노 - Epoch 2/3, Loss: 2.1774538267476884\n","호갱노노 - Epoch 3/3, Loss: 2.0679040294067534\n","호갱노노 - Mean Squared Error: 1.7941641807556152\n","호갱노노 - R-squared: 0.39509691801723357\n","Model and tokenizer saved for 호갱노노\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["네이버부동산 - Epoch 1/3, Loss: 2.17677721906276\n","네이버부동산 - Epoch 2/3, Loss: 1.8801715044748215\n","네이버부동산 - Epoch 3/3, Loss: 1.756026738598233\n","네이버부동산 - Mean Squared Error: 1.7803014516830444\n","네이버부동산 - R-squared: 0.15411402245606276\n","Model and tokenizer saved for 네이버부동산\n","Loaded model and tokenizer for 피터팬\n","Predicted score for '사기' in 피터팬: 3.65\n","Predicted score for '좋아요' in 피터팬: 3.89\n","Predicted score for '최악' in 피터팬: 3.89\n","Predicted score for '친절' in 피터팬: 3.96\n","\n","\n","Loaded model and tokenizer for 다방\n","Predicted score for '사기' in 다방: 3.70\n","Predicted score for '좋아요' in 다방: 4.52\n","Predicted score for '최악' in 다방: 4.52\n","Predicted score for '친절' in 다방: 4.88\n","\n","\n","Loaded model and tokenizer for 직방\n","Predicted score for '사기' in 직방: 2.04\n","Predicted score for '좋아요' in 직방: 4.40\n","Predicted score for '최악' in 직방: 4.40\n","Predicted score for '친절' in 직방: 4.78\n","\n","\n","Loaded model and tokenizer for 호갱노노\n","Predicted score for '사기' in 호갱노노: 3.11\n","Predicted score for '좋아요' in 호갱노노: 4.47\n","Predicted score for '최악' in 호갱노노: 4.47\n","Predicted score for '친절' in 호갱노노: 3.79\n","\n","\n","Loaded model and tokenizer for 네이버부동산\n","Predicted score for '사기' in 네이버부동산: 3.01\n","Predicted score for '좋아요' in 네이버부동산: 3.14\n","Predicted score for '최악' in 네이버부동산: 3.14\n","Predicted score for '친절' in 네이버부동산: 1.62\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0b4nkqkbnubl"},"execution_count":null,"outputs":[]}]}