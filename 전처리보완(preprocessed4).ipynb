{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":13706,"status":"ok","timestamp":1733471795211,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"WhMu_baUaaux","outputId":"2ac67a73-1202-49fe-96ef-5f5e264fa6f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n","  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-z4krqnyf\n","  Running command git clone --filter=blob:none --quiet https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-z4krqnyf\n","  Resolved https://github.com/haven-jeon/PyKoSpacing.git to commit b32a889cbd10b006d2f4aba118f0cd5b677e2979\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorflow>=2.16.2 in /usr/local/lib/python3.10/dist-packages (from pykospacing==0.5) (2.17.1)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from pykospacing==0.5) (3.12.1)\n","Collecting argparse>=1.1.0 (from pykospacing==0.5)\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from h5py>=3.10.0->pykospacing==0.5) (1.26.4)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.2->pykospacing==0.5) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.16.2->pykospacing==0.5) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.16.2->pykospacing==0.5) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.16.2->pykospacing==0.5) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.16.2->pykospacing==0.5) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.2->pykospacing==0.5) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.2->pykospacing==0.5) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.2->pykospacing==0.5) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.2->pykospacing==0.5) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.16.2->pykospacing==0.5) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.16.2->pykospacing==0.5) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.16.2->pykospacing==0.5) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow>=2.16.2->pykospacing==0.5) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.16.2->pykospacing==0.5) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.16.2->pykospacing==0.5) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=2.16.2->pykospacing==0.5) (0.1.2)\n","Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Building wheels for collected packages: pykospacing\n","  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pykospacing: filename=pykospacing-0.5-py3-none-any.whl size=2286921 sha256=f1cb5bc45685513c7c2f2a38ba796dda211e6437f3e42fa3ca2385d4abce28ab\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2f0ev_6o/wheels/76/b3/33/dda14886ee76b8e53eb05580a14dfcf9145e9eb9d282c53f28\n","Successfully built pykospacing\n","Installing collected packages: argparse, pykospacing\n","Successfully installed argparse-1.4.0 pykospacing-0.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]},"id":"8ac0a494a8a843b898b13091c6b6bd64"}},"metadata":{}}],"source":["!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26427,"status":"ok","timestamp":1733593618389,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"SfCIDIunaWGU","outputId":"7ff4f4dc-c0e9-40d7-fc0e-6e4fe8008dc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","작업 디렉토리: /content/drive/MyDrive/2024/TextMining/reviews_data\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')\n","\n","# 작업 디렉토리 설정 ('2024'부분을 'TextMining' 바로가기가 있는 본인의 Google Drive 경로로 변경해주세요)\n","base_path = '/content/drive/MyDrive/2024/TextMining'\n","data_path = os.path.join(base_path, 'reviews_data')\n","\n","# 데이터 디렉토리 확인\n","os.makedirs(data_path, exist_ok=True)\n","print(f\"작업 디렉토리: {data_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5801,"status":"ok","timestamp":1733471833365,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"5_L-7d0Bai-t","outputId":"d518dd6f-4754-47fa-c2f9-2f8fe161ed19"},"outputs":[{"output_type":"stream","name":"stdout","text":["교정된 텍스트: 오늘 날씨가 정말 좋네요\n"]}],"source":["from pykospacing import Spacing\n","\n","# 띄어쓰기 교정 함수\n","spacing = Spacing()\n","\n","def correct_spacing(text):\n","    try:\n","        return spacing(text)\n","    except Exception as e:\n","        print(f\"띄어쓰기 교정 중 오류 발생: {e}\")\n","        return text\n","\n","# 테스트 텍스트\n","text = \"오늘 날씨가 정말좋네요\"\n","corrected_text = correct_spacing(text)\n","print(\"교정된 텍스트:\", corrected_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oibRzxtcat5F"},"outputs":[],"source":["# 전처리 파이프라인\n","def preprocess_pipeline(text):\n","    # NaN 값 처리 및 숫자 값을 문자열로 변환\n","    if isinstance(text, float) or text is None:  # NaN 또는 float 값일 경우\n","        text = str(text)  # NaN을 'nan' 문자열로 변환하거나, float 값을 문자열로 변환\n","\n","    if isinstance(text, str):  # 텍스트인 경우만 처리\n","\n","        # 특수문자 및 숫자 제거, 한글만 남기기\n","        text = re.sub(r\"[^\\w\\sㄱ-ㅎㅏ-ㅣ가-힣]\", \" \", text)  # 특수문자 및 숫자를 공백 1개로 바꿈\n","\n","        # 불필요한 공백 제거 (여러 공백을 하나로 통합)\n","        text = re.sub(r\"\\s+\", \" \", text).strip()\n","\n","        # 띄어쓰기 교정 (필요한 경우 함수 작성)\n","        text = correct_spacing(text)\n","    else:\n","        text = \"\"  # 문자열이 아닐 경우 빈 문자열 처리\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":22082,"status":"ok","timestamp":1733471855444,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"ykeyGKW-avE5","outputId":"cd595200-1244-46af-8a05-e9d19e76d3e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (5.3.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n","Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.1 konlpy-0.6.0\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n","  libice-dev libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-11-jre x11-utils\n","Suggested packages:\n","  libice-doc libsm-doc libxt-doc openjdk-11-demo openjdk-11-source visualvm mesa-utils\n","The following NEW packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n","  libice-dev libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-11-jdk openjdk-11-jre\n","  x11-utils\n","0 upgraded, 14 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 5,517 kB of archives.\n","After this operation, 15.8 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.25+9-1ubuntu1~22.04 [216 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.25+9-1ubuntu1~22.04 [1,334 kB]\n","Fetched 5,517 kB in 3s (1,906 kB/s)\n","Selecting previously unselected package fonts-dejavu-core.\n","(Reading database ... 123632 files and directories currently installed.)\n","Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-core (2.37-2build1) ...\n","Selecting previously unselected package fonts-dejavu-extra.\n","Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n","Unpacking fonts-dejavu-extra (2.37-2build1) ...\n","Selecting previously unselected package libfontenc1:amd64.\n","Preparing to unpack .../02-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package libxtst6:amd64.\n","Preparing to unpack .../04-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n","Selecting previously unselected package libxxf86dga1:amd64.\n","Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../06-x11-utils_7.7+5build2_amd64.deb ...\n","Unpacking x11-utils (7.7+5build2) ...\n","Selecting previously unselected package libatk-wrapper-java.\n","Preparing to unpack .../07-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n","Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n","Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n","Preparing to unpack .../08-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n","Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Selecting previously unselected package libice-dev:amd64.\n","Preparing to unpack .../09-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n","Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n","Selecting previously unselected package libsm-dev:amd64.\n","Preparing to unpack .../10-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n","Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Selecting previously unselected package libxt-dev:amd64.\n","Preparing to unpack .../11-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n","Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n","Selecting previously unselected package openjdk-11-jre:amd64.\n","Preparing to unpack .../12-openjdk-11-jre_11.0.25+9-1ubuntu1~22.04_amd64.deb ...\n","Unpacking openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n","Selecting previously unselected package openjdk-11-jdk:amd64.\n","Preparing to unpack .../13-openjdk-11-jdk_11.0.25+9-1ubuntu1~22.04_amd64.deb ...\n","Unpacking openjdk-11-jdk:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n","Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n","Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Setting up openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n","Setting up fonts-dejavu-core (2.37-2build1) ...\n","Setting up fonts-dejavu-extra (2.37-2build1) ...\n","Setting up openjdk-11-jdk:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n","update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up x11-utils (7.7+5build2) ...\n","Setting up libatk-wrapper-java (0.38.0-5build1) ...\n","Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"]}],"source":["!pip install konlpy\n","!apt-get install -y openjdk-11-jdk\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52Ioo2SWa00V"},"outputs":[],"source":["from konlpy.tag import Okt\n","import ast\n","\n","# Okt 초기화 (형태소 분석기)\n","okt = Okt()\n","\n","# 형태소 분석 함수\n","def tokenize(text):\n","    return okt.morphs(text)\n","\n","# 품사 태깅 함수\n","def pos_tagging(text):\n","    return okt.pos(text)"]},{"cell_type":"markdown","metadata":{"id":"hONhhAWzkHGt"},"source":["## 사용자 정의 사전"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1733471857794,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"lv0mbIG4b0J-","outputId":"6de28e89-313a-4585-8d74-c7103f96a7cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/konlpy/__init__.py\n"]}],"source":["import konlpy\n","print(konlpy.__file__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1733471857794,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"dEacxMbgdFxk","outputId":"2fb6288a-1b00-40d1-dc76-23c76b3c3a65"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/konlpy/java\n"]}],"source":["# Java 폴더로 이동\n","os.chdir('/usr/local/lib/python3.10/dist-packages/konlpy/java')\n","# 현재 디렉터리 확인\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1733471857794,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"gMxRUoGwdLMz","outputId":"ab442d6f-d34b-4284-d3f8-a3b77007df1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":8}],"source":["os.system(\"ls -l\")"]},{"cell_type":"markdown","metadata":{"id":"qdCGI7vCkL4c"},"source":["### 고유어 사전"]},{"cell_type":"markdown","metadata":{"id":"E0KfzQ49kLWO"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":651,"status":"ok","timestamp":1733471858439,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"EXIuyFwKdTtv","outputId":"ce67a836-28f7-4d98-c0a2-7165f8949a77"},"outputs":[{"output_type":"stream","name":"stdout","text":["  created: META-INF/\n"," inflated: META-INF/MANIFEST.MF\n","  created: org/\n","  created: org/openkoreantext/\n","  created: org/openkoreantext/processor/\n","  created: org/openkoreantext/processor/normalizer/\n","  created: org/openkoreantext/processor/phrase_extractor/\n","  created: org/openkoreantext/processor/qa/\n","  created: org/openkoreantext/processor/stemmer/\n","  created: org/openkoreantext/processor/tokenizer/\n","  created: org/openkoreantext/processor/tools/\n","  created: org/openkoreantext/processor/util/\n","  created: org/openkoreantext/processor/util/adjective/\n","  created: org/openkoreantext/processor/util/adverb/\n","  created: org/openkoreantext/processor/util/auxiliary/\n","  created: org/openkoreantext/processor/util/freq/\n","  created: org/openkoreantext/processor/util/josa/\n","  created: org/openkoreantext/processor/util/noun/\n","  created: org/openkoreantext/processor/util/substantives/\n","  created: org/openkoreantext/processor/util/typos/\n","  created: org/openkoreantext/processor/util/verb/\n"," inflated: org/openkoreantext/processor/KoreanPosJava.class\n"," inflated: org/openkoreantext/processor/KoreanTokenJava.class\n"," inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer$.class\n"," inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment$.class\n"," inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment.class\n"," inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer.class\n"," inflated: org/openkoreantext/processor/OpenKoreanTextProcessor$.class\n"," inflated: org/openkoreantext/processor/OpenKoreanTextProcessor.class\n"," inflated: org/openkoreantext/processor/OpenKoreanTextProcessorJava.class\n"," inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$.class\n"," inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase$.class\n"," inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase.class\n"," inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer$.class\n"," inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer.class\n"," inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor.class\n"," inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns$.class\n"," inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet$.class\n"," inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet.class\n"," inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns.class\n"," inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets$.class\n"," inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime$.class\n"," inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime.class\n"," inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets.class\n"," inflated: org/openkoreantext/processor/qa/KoreanProcessorSandbox$.class\n"," inflated: org/openkoreantext/processor/qa/KoreanProcessorSandbox.class\n"," inflated: org/openkoreantext/processor/stemmer/KoreanStemmer$.class\n"," inflated: org/openkoreantext/processor/stemmer/KoreanStemmer.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanChunk$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanChunk.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanChunker$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanChunker.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanDetokenizer$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanDetokenizer.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie$.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie.class\n"," inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer.class\n"," inflated: org/openkoreantext/processor/tokenizer/ParsedChunk$.class\n"," inflated: org/openkoreantext/processor/tokenizer/ParsedChunk.class\n"," inflated: org/openkoreantext/processor/tokenizer/Sentence$.class\n"," inflated: org/openkoreantext/processor/tokenizer/Sentence.class\n"," inflated: org/openkoreantext/processor/tokenizer/TokenizerProfile$.class\n"," inflated: org/openkoreantext/processor/tokenizer/TokenizerProfile.class\n"," inflated: org/openkoreantext/processor/tools/CreateChunkParsingCandidates$.class\n"," inflated: org/openkoreantext/processor/tools/CreateChunkParsingCandidates.class\n"," inflated: org/openkoreantext/processor/tools/CreateConjugationExamples$.class\n"," inflated: org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample$.class\n"," inflated: org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample.class\n"," inflated: org/openkoreantext/processor/tools/CreateConjugationExamples.class\n"," inflated: org/openkoreantext/processor/tools/CreateParsingExamples$.class\n"," inflated: org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample$.class\n"," inflated: org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample.class\n"," inflated: org/openkoreantext/processor/tools/CreateParsingExamples.class\n"," inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$.class\n"," inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample$.class\n"," inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample.class\n"," inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples.class\n"," inflated: org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries$.class\n"," inflated: org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries.class\n"," inflated: org/openkoreantext/processor/tools/Runnable.class\n"," inflated: org/openkoreantext/processor/tools/UpdateAllTheExamples$.class\n"," inflated: org/openkoreantext/processor/tools/UpdateAllTheExamples.class\n"," inflated: org/openkoreantext/processor/util/adjective/adjective.txt\n"," inflated: org/openkoreantext/processor/util/adverb/adverb.txt\n"," inflated: org/openkoreantext/processor/util/auxiliary/conjunctions.txt\n"," inflated: org/openkoreantext/processor/util/auxiliary/determiner.txt\n"," inflated: org/openkoreantext/processor/util/auxiliary/exclamation.txt\n"," inflated: org/openkoreantext/processor/util/CharacterUtils$CharacterBuffer.class\n"," inflated: org/openkoreantext/processor/util/CharacterUtils$Java4CharacterUtils.class\n"," inflated: org/openkoreantext/processor/util/CharacterUtils$Java5CharacterUtils.class\n"," inflated: org/openkoreantext/processor/util/CharacterUtils.class\n"," inflated: org/openkoreantext/processor/util/CharArrayMap$1.class\n"," inflated: org/openkoreantext/processor/util/CharArrayMap$EmptyCharArrayMap.class\n"," inflated: org/openkoreantext/processor/util/CharArrayMap$EntryIterator.class\n"," inflated: org/openkoreantext/processor/util/CharArrayMap$EntrySet.class\n"," inflated: org/openkoreantext/processor/util/CharArrayMap$MapEntry.class\n"," inflated: org/openkoreantext/processor/util/CharArrayMap$UnmodifiableCharArrayMap.class\n"," inflated: org/openkoreantext/processor/util/CharArrayMap.class\n"," inflated: org/openkoreantext/processor/util/CharArraySet.class\n"," inflated: org/openkoreantext/processor/util/example_chunks.txt\n"," inflated: org/openkoreantext/processor/util/example_tweets.txt\n"," inflated: org/openkoreantext/processor/util/freq/entity-freq.txt.gz\n"," inflated: org/openkoreantext/processor/util/Hangul$.class\n"," inflated: org/openkoreantext/processor/util/Hangul$DoubleCoda$.class\n"," inflated: org/openkoreantext/processor/util/Hangul$DoubleCoda.class\n"," inflated: org/openkoreantext/processor/util/Hangul$HangulChar$.class\n"," inflated: org/openkoreantext/processor/util/Hangul$HangulChar.class\n"," inflated: org/openkoreantext/processor/util/Hangul.class\n"," inflated: org/openkoreantext/processor/util/josa/josa.txt\n"," inflated: org/openkoreantext/processor/util/KoreanConjugation$.class\n"," inflated: org/openkoreantext/processor/util/KoreanConjugation.class\n"," inflated: org/openkoreantext/processor/util/KoreanDictionaryProvider$.class\n"," inflated: org/openkoreantext/processor/util/KoreanDictionaryProvider.class\n"," inflated: org/openkoreantext/processor/util/KoreanPos$.class\n"," inflated: org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie$.class\n"," inflated: org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie.class\n"," inflated: org/openkoreantext/processor/util/KoreanPos.class\n"," inflated: org/openkoreantext/processor/util/KoreanSubstantive$.class\n"," inflated: org/openkoreantext/processor/util/KoreanSubstantive.class\n"," inflated: org/openkoreantext/processor/util/noun/bible.txt\n"," inflated: org/openkoreantext/processor/util/noun/company_names.txt\n"," inflated: org/openkoreantext/processor/util/noun/congress.txt\n"," inflated: org/openkoreantext/processor/util/noun/entities.txt\n"," inflated: org/openkoreantext/processor/util/noun/foreign.txt\n"," inflated: org/openkoreantext/processor/util/noun/geolocations.txt\n"," inflated: org/openkoreantext/processor/util/noun/kpop.txt\n"," inflated: org/openkoreantext/processor/util/noun/lol.txt\n"," inflated: org/openkoreantext/processor/util/noun/names.txt\n"," inflated: org/openkoreantext/processor/util/noun/nouns.txt\n"," inflated: org/openkoreantext/processor/util/noun/pokemon.txt\n"," inflated: org/openkoreantext/processor/util/noun/profane.txt\n"," inflated: org/openkoreantext/processor/util/noun/slangs.txt\n"," inflated: org/openkoreantext/processor/util/noun/spam.txt\n"," inflated: org/openkoreantext/processor/util/noun/twitter.txt\n"," inflated: org/openkoreantext/processor/util/noun/wikipedia_title_nouns.txt\n"," inflated: org/openkoreantext/processor/util/substantives/family_names.txt\n"," inflated: org/openkoreantext/processor/util/substantives/given_names.txt\n"," inflated: org/openkoreantext/processor/util/substantives/modifier.txt\n"," inflated: org/openkoreantext/processor/util/substantives/suffix.txt\n"," inflated: org/openkoreantext/processor/util/typos/typos.txt\n"," inflated: org/openkoreantext/processor/util/verb/eomi.txt\n"," inflated: org/openkoreantext/processor/util/verb/pre_eomi.txt\n"," inflated: org/openkoreantext/processor/util/verb/verb.txt\n"," inflated: org/openkoreantext/processor/util/verb/verb_prefix.txt\n","  created: META-INF/maven/\n","  created: META-INF/maven/org.openkoreantext/\n","  created: META-INF/maven/org.openkoreantext/open-korean-text/\n"," inflated: META-INF/maven/org.openkoreantext/open-korean-text/pom.xml\n"," inflated: META-INF/maven/org.openkoreantext/open-korean-text/pom.properties\n"]}],"source":["# JAR 파일 압축 해제\n","!jar xvf open-korean-text-2.1.0.jar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmJBcUXhdUB4"},"outputs":[],"source":["# 기존 사전 불러오기\n","with open(\"org/openkoreantext/processor/util/noun/names.txt\", \"r\") as file:\n","    data = file.read()\n","\n","# 새 단어 추가\n","custom_words = [\"호갱노노\", \"허위매물\", \"불편\", \"전유물\", \"공인중개사\", \"중개업소\",\n","                \"e편한세상\", \"실거래\", \"확정일\", \"확정일자\", \"집주인\", \"이사\",\n","                \"스와이프\", \"뒤로가기\", \"로드뷰\", \"스크롤\", \"다운데이트\", \"불안정\",\n","                \"융자금\", \"관리비\", \"임대인\", \"임차인\", \"창출\", \"본인인증\", \"실매물\", \"실매물건\"\n","                ]\n","data += \"\\n\" + \"\\n\".join(custom_words)\n","\n","# 수정된 내용 저장\n","with open(\"org/openkoreantext/processor/util/noun/names.txt\", \"w\") as file:\n","    file.write(data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":628,"status":"ok","timestamp":1733471859065,"user":{"displayName":"김현서","userId":"16609558155508415553"},"user_tz":-540},"id":"6Rl-N6N2jUyQ","outputId":"31e78b80-ebb4-4a01-e238-888ff22cdbf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["added manifest\n","adding: org/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/tokenizer/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer$.class(in = 25564) (out= 8451)(deflated 66%)\n","adding: org/openkoreantext/processor/tokenizer/ParsedChunk.class(in = 20517) (out= 8914)(deflated 56%)\n","adding: org/openkoreantext/processor/tokenizer/ParsedChunk$.class(in = 3973) (out= 1500)(deflated 62%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanDetokenizer.class(in = 1660) (out= 1133)(deflated 31%)\n","adding: org/openkoreantext/processor/tokenizer/Sentence$.class(in = 2339) (out= 1012)(deflated 56%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse$.class(in = 3459) (out= 1111)(deflated 67%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter.class(in = 1092) (out= 712)(deflated 34%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken$.class(in = 3976) (out= 1402)(deflated 64%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch.class(in = 4043) (out= 1704)(deflated 57%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter$.class(in = 3359) (out= 1497)(deflated 55%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie.class(in = 3399) (out= 1429)(deflated 57%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanChunk.class(in = 5611) (out= 2907)(deflated 48%)\n","adding: org/openkoreantext/processor/tokenizer/TokenizerProfile$.class(in = 8169) (out= 2408)(deflated 70%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken.class(in = 6336) (out= 2633)(deflated 58%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch$.class(in = 2893) (out= 1136)(deflated 60%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse.class(in = 4616) (out= 1645)(deflated 64%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanChunker.class(in = 4232) (out= 2887)(deflated 31%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie$.class(in = 2862) (out= 1067)(deflated 62%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanTokenizer.class(in = 6968) (out= 4384)(deflated 37%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanDetokenizer$.class(in = 9889) (out= 4174)(deflated 57%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanChunk$.class(in = 2361) (out= 1010)(deflated 57%)\n","adding: org/openkoreantext/processor/tokenizer/TokenizerProfile.class(in = 16403) (out= 6666)(deflated 59%)\n","adding: org/openkoreantext/processor/tokenizer/KoreanChunker$.class(in = 17975) (out= 6790)(deflated 62%)\n","adding: org/openkoreantext/processor/tokenizer/Sentence.class(in = 5985) (out= 3125)(deflated 47%)\n","adding: org/openkoreantext/processor/tools/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/tools/CreateConjugationExamples$.class(in = 5881) (out= 2385)(deflated 59%)\n","adding: org/openkoreantext/processor/tools/CreateChunkParsingCandidates.class(in = 833) (out= 566)(deflated 32%)\n","adding: org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample.class(in = 3569) (out= 1415)(deflated 60%)\n","adding: org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample.class(in = 3718) (out= 1429)(deflated 61%)\n","adding: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample.class(in = 3825) (out= 1443)(deflated 62%)\n","adding: org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample$.class(in = 2842) (out= 1010)(deflated 64%)\n","adding: org/openkoreantext/processor/tools/Runnable.class(in = 964) (out= 694)(deflated 28%)\n","adding: org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries.class(in = 1117) (out= 823)(deflated 26%)\n","adding: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample$.class(in = 2974) (out= 1020)(deflated 65%)\n","adding: org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries$.class(in = 7154) (out= 3133)(deflated 56%)\n","adding: org/openkoreantext/processor/tools/CreateParsingExamples$.class(in = 5517) (out= 2327)(deflated 57%)\n","adding: org/openkoreantext/processor/tools/CreateConjugationExamples.class(in = 2367) (out= 1659)(deflated 29%)\n","adding: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples.class(in = 2516) (out= 1784)(deflated 29%)\n","adding: org/openkoreantext/processor/tools/UpdateAllTheExamples$.class(in = 4383) (out= 1794)(deflated 59%)\n","adding: org/openkoreantext/processor/tools/CreateChunkParsingCandidates$.class(in = 5487) (out= 2305)(deflated 57%)\n","adding: org/openkoreantext/processor/tools/UpdateAllTheExamples.class(in = 1089) (out= 756)(deflated 30%)\n","adding: org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample$.class(in = 2787) (out= 997)(deflated 64%)\n","adding: org/openkoreantext/processor/tools/CreateParsingExamples.class(in = 2427) (out= 1732)(deflated 28%)\n","adding: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$.class(in = 5989) (out= 2472)(deflated 58%)\n","adding: org/openkoreantext/processor/KoreanTokenJava.class(in = 1976) (out= 931)(deflated 52%)\n","adding: org/openkoreantext/processor/OpenKoreanTextProcessor$.class(in = 7716) (out= 2400)(deflated 68%)\n","adding: org/openkoreantext/processor/util/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/auxiliary/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/auxiliary/exclamation.txt(in = 1759) (out= 757)(deflated 56%)\n","adding: org/openkoreantext/processor/util/auxiliary/conjunctions.txt(in = 398) (out= 189)(deflated 52%)\n","adding: org/openkoreantext/processor/util/auxiliary/determiner.txt(in = 63) (out= 63)(deflated 0%)\n","adding: org/openkoreantext/processor/util/KoreanConjugation$.class(in = 22440) (out= 7972)(deflated 64%)\n","adding: org/openkoreantext/processor/util/KoreanPos$.class(in = 12173) (out= 4669)(deflated 61%)\n","adding: org/openkoreantext/processor/util/adjective/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/adjective/adjective.txt(in = 27250) (out= 9357)(deflated 65%)\n","adding: org/openkoreantext/processor/util/Hangul$DoubleCoda.class(in = 2930) (out= 1348)(deflated 53%)\n","adding: org/openkoreantext/processor/util/CharacterUtils$Java4CharacterUtils.class(in = 2577) (out= 1282)(deflated 50%)\n","adding: org/openkoreantext/processor/util/CharArrayMap.class(in = 11923) (out= 4878)(deflated 59%)\n","adding: org/openkoreantext/processor/util/CharArrayMap$EntryIterator.class(in = 3118) (out= 1270)(deflated 59%)\n","adding: org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie.class(in = 4390) (out= 1610)(deflated 63%)\n","adding: org/openkoreantext/processor/util/josa/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/josa/josa.txt(in = 5219) (out= 1476)(deflated 71%)\n","adding: org/openkoreantext/processor/util/example_chunks.txt(in = 522978) (out= 163253)(deflated 68%)\n","adding: org/openkoreantext/processor/util/Hangul.class(in = 3981) (out= 2731)(deflated 31%)\n","adding: org/openkoreantext/processor/util/CharacterUtils$Java5CharacterUtils.class(in = 2824) (out= 1393)(deflated 50%)\n","adding: org/openkoreantext/processor/util/CharArrayMap$1.class(in = 1531) (out= 571)(deflated 62%)\n","adding: org/openkoreantext/processor/util/CharacterUtils$CharacterBuffer.class(in = 1634) (out= 659)(deflated 59%)\n","adding: org/openkoreantext/processor/util/example_tweets.txt(in = 86271) (out= 38336)(deflated 55%)\n","adding: org/openkoreantext/processor/util/KoreanDictionaryProvider.class(in = 3430) (out= 2003)(deflated 41%)\n","adding: org/openkoreantext/processor/util/CharArraySet.class(in = 4886) (out= 1944)(deflated 60%)\n","adding: org/openkoreantext/processor/util/substantives/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/substantives/modifier.txt(in = 3395) (out= 1346)(deflated 60%)\n","adding: org/openkoreantext/processor/util/substantives/family_names.txt(in = 299) (out= 197)(deflated 34%)\n","adding: org/openkoreantext/processor/util/substantives/given_names.txt(in = 1407) (out= 609)(deflated 56%)\n","adding: org/openkoreantext/processor/util/substantives/suffix.txt(in = 325) (out= 224)(deflated 31%)\n","adding: org/openkoreantext/processor/util/KoreanSubstantive$.class(in = 14990) (out= 6195)(deflated 58%)\n","adding: org/openkoreantext/processor/util/Hangul$HangulChar$.class(in = 2389) (out= 1022)(deflated 57%)\n","adding: org/openkoreantext/processor/util/KoreanConjugation.class(in = 1550) (out= 1237)(deflated 20%)\n","adding: org/openkoreantext/processor/util/CharArrayMap$MapEntry.class(in = 2433) (out= 1078)(deflated 55%)\n","adding: org/openkoreantext/processor/util/CharArrayMap$UnmodifiableCharArrayMap.class(in = 3062) (out= 859)(deflated 71%)\n","adding: org/openkoreantext/processor/util/adverb/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/adverb/adverb.txt(in = 65572) (out= 18741)(deflated 71%)\n","adding: org/openkoreantext/processor/util/noun/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/noun/pokemon.txt(in = 1781) (out= 965)(deflated 45%)\n","adding: org/openkoreantext/processor/util/noun/bible.txt(in = 2032) (out= 1005)(deflated 50%)\n","adding: org/openkoreantext/processor/util/noun/wikipedia_title_nouns.txt(in = 1971964) (out= 686708)(deflated 65%)\n","adding: org/openkoreantext/processor/util/noun/congress.txt(in = 26494) (out= 9351)(deflated 64%)\n","adding: org/openkoreantext/processor/util/noun/profane.txt(in = 569) (out= 337)(deflated 40%)\n","adding: org/openkoreantext/processor/util/noun/lol.txt(in = 1337) (out= 744)(deflated 44%)\n","adding: org/openkoreantext/processor/util/noun/foreign.txt(in = 10485) (out= 4686)(deflated 55%)\n","adding: org/openkoreantext/processor/util/noun/entities.txt(in = 108142) (out= 44095)(deflated 59%)\n","adding: org/openkoreantext/processor/util/noun/kpop.txt(in = 5371) (out= 2495)(deflated 53%)\n","adding: org/openkoreantext/processor/util/noun/twitter.txt(in = 254) (out= 162)(deflated 36%)\n","adding: org/openkoreantext/processor/util/noun/nouns.txt(in = 219319) (out= 84134)(deflated 61%)\n","adding: org/openkoreantext/processor/util/noun/names.txt(in = 1194) (out= 709)(deflated 40%)\n","adding: org/openkoreantext/processor/util/noun/slangs.txt(in = 1565) (out= 921)(deflated 41%)\n","adding: org/openkoreantext/processor/util/noun/spam.txt(in = 202) (out= 157)(deflated 22%)\n","adding: org/openkoreantext/processor/util/noun/geolocations.txt(in = 5423) (out= 2267)(deflated 58%)\n","adding: org/openkoreantext/processor/util/noun/company_names.txt(in = 1631) (out= 905)(deflated 44%)\n","adding: org/openkoreantext/processor/util/Hangul$HangulChar.class(in = 3185) (out= 1421)(deflated 55%)\n","adding: org/openkoreantext/processor/util/verb/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/verb/verb.txt(in = 32758) (out= 10723)(deflated 67%)\n","adding: org/openkoreantext/processor/util/verb/verb_prefix.txt(in = 47) (out= 52)(deflated -10%)\n","adding: org/openkoreantext/processor/util/verb/eomi.txt(in = 12618) (out= 3556)(deflated 71%)\n","adding: org/openkoreantext/processor/util/verb/pre_eomi.txt(in = 285) (out= 185)(deflated 35%)\n","adding: org/openkoreantext/processor/util/CharArrayMap$EmptyCharArrayMap.class(in = 2053) (out= 725)(deflated 64%)\n","adding: org/openkoreantext/processor/util/KoreanDictionaryProvider$.class(in = 20197) (out= 7488)(deflated 62%)\n","adding: org/openkoreantext/processor/util/freq/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/freq/entity-freq.txt.gz(in = 385753) (out= 385873)(deflated 0%)\n","adding: org/openkoreantext/processor/util/KoreanSubstantive.class(in = 1336) (out= 1087)(deflated 18%)\n","adding: org/openkoreantext/processor/util/CharArrayMap$EntrySet.class(in = 2788) (out= 1181)(deflated 57%)\n","adding: org/openkoreantext/processor/util/CharacterUtils.class(in = 3703) (out= 1716)(deflated 53%)\n","adding: org/openkoreantext/processor/util/KoreanPos.class(in = 6890) (out= 3877)(deflated 43%)\n","adding: org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie$.class(in = 3157) (out= 1089)(deflated 65%)\n","adding: org/openkoreantext/processor/util/Hangul$.class(in = 7625) (out= 3114)(deflated 59%)\n","adding: org/openkoreantext/processor/util/Hangul$DoubleCoda$.class(in = 2155) (out= 963)(deflated 55%)\n","adding: org/openkoreantext/processor/util/typos/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/util/typos/typos.txt(in = 5146) (out= 2300)(deflated 55%)\n","adding: org/openkoreantext/processor/OpenKoreanTextProcessorJava.class(in = 5901) (out= 1995)(deflated 66%)\n","adding: org/openkoreantext/processor/OpenKoreanTextProcessor.class(in = 4428) (out= 1997)(deflated 54%)\n","adding: org/openkoreantext/processor/qa/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/qa/BatchGetUnknownNouns$.class(in = 8751) (out= 3532)(deflated 59%)\n","adding: org/openkoreantext/processor/qa/BatchTokenizeTweets$.class(in = 10867) (out= 4401)(deflated 59%)\n","adding: org/openkoreantext/processor/qa/KoreanProcessorSandbox$.class(in = 1464) (out= 823)(deflated 43%)\n","adding: org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime.class(in = 3153) (out= 1446)(deflated 54%)\n","adding: org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet$.class(in = 2376) (out= 952)(deflated 59%)\n","adding: org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime$.class(in = 2418) (out= 1015)(deflated 58%)\n","adding: org/openkoreantext/processor/qa/BatchGetUnknownNouns.class(in = 2307) (out= 1702)(deflated 26%)\n","adding: org/openkoreantext/processor/qa/BatchTokenizeTweets.class(in = 2720) (out= 2031)(deflated 25%)\n","adding: org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet.class(in = 3080) (out= 1338)(deflated 56%)\n","adding: org/openkoreantext/processor/qa/KoreanProcessorSandbox.class(in = 824) (out= 575)(deflated 30%)\n","adding: org/openkoreantext/processor/phrase_extractor/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase.class(in = 6942) (out= 2591)(deflated 62%)\n","adding: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor.class(in = 6005) (out= 3967)(deflated 33%)\n","adding: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$.class(in = 37855) (out= 12404)(deflated 67%)\n","adding: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase$.class(in = 3358) (out= 1148)(deflated 65%)\n","adding: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer$.class(in = 3564) (out= 1087)(deflated 69%)\n","adding: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer.class(in = 4857) (out= 1609)(deflated 66%)\n","adding: org/openkoreantext/processor/stemmer/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/stemmer/KoreanStemmer$.class(in = 7044) (out= 2892)(deflated 58%)\n","adding: org/openkoreantext/processor/stemmer/KoreanStemmer.class(in = 1439) (out= 972)(deflated 32%)\n","adding: org/openkoreantext/processor/KoreanPosJava.class(in = 2457) (out= 1241)(deflated 49%)\n","adding: org/openkoreantext/processor/normalizer/(in = 0) (out= 0)(stored 0%)\n","adding: org/openkoreantext/processor/normalizer/KoreanNormalizer.class(in = 2980) (out= 2181)(deflated 26%)\n","adding: org/openkoreantext/processor/normalizer/KoreanNormalizer$.class(in = 11553) (out= 5102)(deflated 55%)\n","adding: org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment$.class(in = 2577) (out= 989)(deflated 61%)\n","adding: org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment.class(in = 3470) (out= 1422)(deflated 59%)\n"]}],"source":["# JAR 파일 다시 압축\n","!jar cvf open-korean-text-2.1.0.jar org\n","!rm -rf org"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y1QMR9-lJ9Z","outputId":"123bb090-8c68-42a7-bcee-0f5ed879dbc9","executionInfo":{"status":"ok","timestamp":1733471875823,"user_tz":-540,"elapsed":16760,"user":{"displayName":"김현서","userId":"16609558155508415553"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Collecting python-Levenshtein\n","  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n","Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n","  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n","  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n","Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-Levenshtein\n","Successfully installed Levenshtein-0.26.1 fuzzywuzzy-0.18.0 python-Levenshtein-0.26.1 rapidfuzz-3.10.1\n"]}],"source":["!pip install fuzzywuzzy python-Levenshtein"]},{"cell_type":"markdown","metadata":{"id":"pJUerlPBnw5o"},"source":["### 유사어 사전"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TN4BI_uNjjix"},"outputs":[],"source":["# 유사어 사전\n","synonym_dict = {\n","    \"호갱 노노\": \"호갱노노\",\n","    \"직방\": \"직방\",\n","    \"다방\": \"다방\",\n","    \"네이버 부동산\": \"네이버부동산\",\n","    \"피터팬\": \"피터팬\",\n","\n","    \"어플리케이션\": \"앱\",\n","    \"어플\": \"앱\",\n","\n","    \"업뎃\": \"업데이트\",\n","    \"업뎉\": \"업데이트\",\n","    \"업데잍\": \"업데이트\",\n","    \"다운\" : \"다운로드\",\n","    \"다운데이트\" : \"다운데이트\",\n","    \"로긴\" : \"로그인\",\n","    \"본인 인증\" : \"본인인증\",\n","    \"뒤로 가기\" : \"뒤로가기\",\n","    \"로디\" : \"로딩\",\n","    \"로드\" : \"로딩\",\n","    \"버젼\" : \"버전\",\n","    \"에러\" : \"오류\",\n","    \"굳\" : \"좋아요\",\n","    \"굿\" : \"좋아요\",\n","    \"별루\" : \"별로\",\n","\n","    \"집주인\" : \"임대인\",\n","    \"세입자\" : \"임차인\",\n","    \"중계인\" : \"공인중개사\",\n","    \"중개인\" : \"공인중개사\",\n","    \"중개사\" : \"공인중개사\",\n","    \"중계사\" : \"공인중개사\",\n","    \"공인 중개사\" : \"공인중개사\",\n","    \"공인 중계사\" : \"공인중개사\",\n","    \"중개 업소\" : \"공인중개사\",\n","    \"중계 업소\" : \"공인중개사\",\n","    \"중개업소\" : \"공인중개사\",\n","    \"중계업소\" : \"공인중개사\",\n","    \"중개 업자\" : \"공인중개사\",\n","    \"중계 업자\" : \"공인중개사\",\n","    \"중개업자\" : \"공인중개사\",\n","    \"중계업자\" : \"공인중개사\",\n","    \"허위 매물\" : \"허위매물\",\n","    \"실매물건\" : \"실매물\",\n","    \"사기꾼\" : \"사기\",\n","\n","    \"방이\" : \"방\",\n","    \"평\" : \"평수\"\n","\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ddakmhDlFZE"},"outputs":[],"source":["from fuzzywuzzy import process\n","\n","# 철자 교정 및 유사어 통합 함수\n","def correct_and_unify_words(text, synonym_dict, threshold=80):\n","    \"\"\"\n","    철자 오류를 교정하고 유사어를 통합하는 함수.\n","\n","    Args:\n","    - text (str): 입력 텍스트\n","    - synonym_dict (dict): 유사어 사전 (key: 단어 목록, value: 표준 단어)\n","    - threshold (int): 유사도 임계값 (기본값: 80)\n","\n","    Returns:\n","    - str: 교정 및 통합된 텍스트\n","    \"\"\"\n","    words = text.split()  # 공백 기준으로 단어 분리\n","    corrected_words = []\n","\n","    for word in words:\n","        # 유사도 점수 계산 및 가장 비슷한 단어 찾기\n","        best_match = process.extractOne(word, list(synonym_dict.keys()))\n","        if best_match and best_match[1] >= threshold:  # 유사도 임계값 이상일 때만 수정\n","            corrected_word = synonym_dict[best_match[0]]\n","        else:\n","            corrected_word = word  # 유사도가 낮으면 원래 단어 유지\n","        corrected_words.append(corrected_word)\n","\n","    return \" \".join(corrected_words)\n"]},{"cell_type":"markdown","metadata":{"id":"TttJXvzqoR4T"},"source":["### 불용어 처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32HqWslZoTGj"},"outputs":[],"source":["# 불용어 파일 로드\n","stopwords_file = os.path.join(data_path, \"stopwords_241206.txt\")\n","\n","with open(stopwords_file, 'r', encoding='utf-8') as file:\n","    stopwords = file.read().splitlines()  # 파일 내용 한 줄씩 읽어서 리스트로 저장\n","\n","# 불용어 제거 함수\n","def remove_stopwords(nouns):\n","    return [noun for noun in nouns if noun not in stopwords]\n"]},{"cell_type":"markdown","metadata":{"id":"An9RBWoonyfO"},"source":["## 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSHr283DnVsb","outputId":"04bbb357-599d-49f3-b209-2f1be0bd3ab6","executionInfo":{"status":"ok","timestamp":1733475141389,"user_tz":-540,"elapsed":2421653,"user":{"displayName":"김현서","userId":"16609558155508415553"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["'reviews_data_네이버부동산_별점.csv' 데이터 로드 성공\n","'reviews_data_네이버부동산_별점.csv' 전처리 및 토큰화, 품사 태깅 완료:\n","                                              content  \\\n","0  기존에 매물 버튼 오프하고 아파트 봤다가 백 하면 그 컨디션이 유지되었었는데, 어느...   \n","1  폰 하단의 뒤로 가기 버튼 누르면 지도로 돌아가던 게 업데이트 이후 어플 자체가 꺼...   \n","2  업데이트 왜한거지? 업데이트가 아니라 다운데이트다 ㅆ.. 가독성 떨어지고. 새창뜨는...   \n","3  매물 조건을 매번 설정해야하는 거 너무 불편해요. 앱을 종료한것도 아니고 뒤로가기 ...   \n","4  목록볼때 넘어가지 말아야할 좌우영역으로 화면 아웃. 매물묶기도 4개 펼쳐보기하면 5...   \n","\n","                                content_preprocessed  \\\n","0  기존에 허위매물 버튼 오프하고 아파트 봤다가 백 하면 그 컨디션이 유지되었었는데 어...   \n","1  폰 하단의 뒤로가기 뒤로가기 뒤로가기 버튼 누르면 지 도로 돌아가던 게 업데이트 이...   \n","2  업데이트 왜 한 거지 업데이트가 아니라 다운데이트 다방 ㅆ 가독성 떨어지고 새창뜨는...   \n","3  허위매물 조건을 매번 설정해야 하는 거 너무 불편해요 앱을 종료한 것도 아니고 뒤로...   \n","4  목록볼 때 넘어가지 말아야 할 좌우 영역으로 화면 아웃 허위매물 묶기도 4개 펼쳐보...   \n","\n","                                       content_token  \\\n","0  [기존, 에, 허위매물, 버튼, 오프, 하고, 아파트, 봤다가, 백, 하면, 그, ...   \n","1  [폰, 하단, 의, 뒤로가기, 뒤로가기, 뒤로가기, 버튼, 누르면, 지, 도로, 돌...   \n","2  [업데이트, 왜, 한, 거지, 업데이트, 가, 아니라, 다운데이트, 다방, ㅆ, 가...   \n","3  [허위매물, 조건, 을, 매번, 설정, 해야, 하는, 거, 너무, 불편해요, 앱, ...   \n","4  [목록, 볼, 때, 넘어가지, 말아야, 할, 좌우, 영역, 으로, 화면, 아웃, 허...   \n","\n","                                         content_pos  \\\n","0  [(기존, Noun), (에, Josa), (허위매물, Noun), (버튼, Nou...   \n","1  [(폰, Noun), (하단, Noun), (의, Josa), (뒤로가기, Noun...   \n","2  [(업데이트, Noun), (왜, Noun), (한, Verb), (거지, Noun...   \n","3  [(허위매물, Noun), (조건, Noun), (을, Josa), (매번, Nou...   \n","4  [(목록, Noun), (볼, Noun), (때, Noun), (넘어가지, Verb...   \n","\n","                                          nouns_only  \\\n","0  [기존, 허위매물, 버튼, 오프, 아파트, 백, 그, 컨디션, 유지, 순간, 백, ...   \n","1  [폰, 하단, 뒤로가기, 뒤로가기, 뒤로가기, 버튼, 도로, 게, 업데이트, 이후,...   \n","2  [업데이트, 왜, 거지, 업데이트, 다운데이트, 다방, 가독성, 창, 것, 평수, ...   \n","3  [허위매물, 조건, 매번, 설정, 거, 앱, 종료, 것, 뒤로가기, 뒤로가기, 시작...   \n","4  [목록, 볼, 때, 좌우, 영역, 화면, 아웃, 허위매물, 개, 보기, 개, 네이버...   \n","\n","                             nouns_without_stopwords  \n","0  [기존, 허위매물, 버튼, 오프, 아파트, 백, 컨디션, 유지, 순간, 백, 허위매...  \n","1  [폰, 하단, 뒤로가기, 뒤로가기, 뒤로가기, 버튼, 도로, 업데이트, 이후, 앱,...  \n","2  [업데이트, 거지, 업데이트, 다운데이트, 가독성, 창, 평수, 셀프, 계산, 준,...  \n","3  [허위매물, 조건, 설정, 앱, 종료, 뒤로가기, 뒤로가기, 시작, 화면, 조건, ...  \n","4  [목록, 좌우, 영역, 화면, 아웃, 허위매물, 보기, 동일, 허위매물, 동일, 설...  \n","'reviews_data_네이버부동산_별점.csv' 결과 저장 완료: /content/drive/MyDrive/2024/TextMining/reviews_data/preprocessed4_reviews_data_네이버부동산_별점.csv\n","'reviews_data_다방_별점.csv' 데이터 로드 성공\n","'reviews_data_다방_별점.csv' 전처리 및 토큰화, 품사 태깅 완료:\n","                                              content  \\\n","0  아니 왜? 쓰리룸이나 포룸 보는걸 이상한걸로 통합시켜서 짜증나게 만드는거죠 만드는 ...   \n","1  부동산 일하다가 탈출한 사람입니다. 허위매물 안 하고 정직하게 했는데 연락 1도 없...   \n","2  뭐 어떻게 찾으라는건지 모르겠음. 검색은 어떻게 하는건가요. 지도를 다 헤짚어놓으면...   \n","3  허위매물천지임 해리 광고 땜에 유명한것도 사실인데 해리 아무거나 광고하나봄 조폭껴잇...   \n","4    아파트 오피스텔 왜 이따위로 분류 한거지? 진짜 짜증나게 뭣같이 바꼈네 하던데로 해라   \n","\n","                                content_preprocessed  \\\n","0  아니 왜 쓰리룸이나 포룸 보는 걸 이상한 걸로 통합시켜서 짜증나게 만드는 거죠 만드...   \n","1  네이버부동산 일하다가 탈출한 사람입니다 허위매물 안 하고 정직하게 했는데 연락 1도...   \n","2  뭐 어떻게 찾으라는 건지 모르겠음 검색은 어떻게 하는 건가요 지도를 다방 헤 짚어놓...   \n","3  허위매물 천지 임 해리 광고 땜에 유명한 것도 사실인데 해리 아무거나 광고 하나 봄...   \n","4  아파트 오피스텔 왜 네이버부동산 따위로 분류 한 거지 진짜 짜증나게 뭣같이 바꼈네 ...   \n","\n","                                       content_token  \\\n","0  [아니, 왜, 쓰리룸, 이나, 포룸, 보는, 걸, 이상한, 걸, 로, 통합, 시켜서...   \n","1  [네이버, 부동산, 일, 하다가, 탈출, 한, 사람, 입니다, 허위매물, 안, 하고...   \n","2  [뭐, 어떻게, 찾으라는, 건지, 모르겠음, 검색, 은, 어떻게, 하는, 건가, 요...   \n","3  [허위매물, 천지, 임, 해리, 광고, 땜, 에, 유명한, 것, 도, 사실, 인데,...   \n","4  [아파트, 오피스텔, 왜, 네이버, 부동산, 따위, 로, 분류, 한, 거지, 진짜,...   \n","\n","                                         content_pos  \\\n","0  [(아니, Adjective), (왜, Noun), (쓰리룸, Noun), (이나,...   \n","1  [(네이버, Noun), (부동산, Noun), (일, Noun), (하다가, Ve...   \n","2  [(뭐, Noun), (어떻게, Adjective), (찾으라는, Verb), (건...   \n","3  [(허위매물, Noun), (천지, Noun), (임, Noun), (해리, Nou...   \n","4  [(아파트, Noun), (오피스텔, Noun), (왜, Noun), (네이버, N...   \n","\n","                                          nouns_only  \\\n","0               [왜, 쓰리룸, 포룸, 걸, 걸, 통합, 거, 안, 보고, 만드]   \n","1  [네이버, 부동산, 일, 탈출, 사람, 허위매물, 안, 연락, 도, 허위매물, 바로...   \n","2                         [뭐, 검색, 건가, 지도, 다방, 헤, 건가]   \n","3  [허위매물, 천지, 임, 해리, 광고, 땜, 것, 사실, 해리, 거나, 광고, 하나...   \n","4  [아파트, 오피스텔, 왜, 네이버, 부동산, 따위, 분류, 거지, 진짜, 뭣, 바,...   \n","\n","                             nouns_without_stopwords  \n","0                                  [쓰리룸, 포룸, 통합, 만드]  \n","1  [탈출, 사람, 허위매물, 연락, 도, 허위매물, 연락, 정도, 허위매물, 허위매물...  \n","2                                [검색, 건가, 지도, 헤, 건가]  \n","3       [허위매물, 천지, 해리, 광고, 땜, 사실, 해리, 거나, 광고, 봄, 조폭]  \n","4                                [아파트, 오피스텔, 분류, 거지]  \n","'reviews_data_다방_별점.csv' 결과 저장 완료: /content/drive/MyDrive/2024/TextMining/reviews_data/preprocessed4_reviews_data_다방_별점.csv\n","'reviews_data_피터팬_별점.csv' 데이터 로드 성공\n","'reviews_data_피터팬_별점.csv' 전처리 및 토큰화, 품사 태깅 완료:\n","                                              content  \\\n","0  순식간에 결제 됩니다. 완전히 눈뜨고 코 베이는 더러운 기분을 느끼고 싶은분은 앱 ...   \n","1  최악의앱. 사진등록한번 하려면 앨범에서 선택할수가 없음. 권한을 항상허용으로해야하는...   \n","2                                                 먹통   \n","3  아이디 찾기했더니 이메일로 로그인 뜨길래 비밀번호를 몰라 찾기 하니 계속 일시적인 ...   \n","4                                오피스텔 매물 등록 오류로 등록불가   \n","\n","                                content_preprocessed  \\\n","0  순식간에 결제 됩니다 완전히 눈 뜨고 코 베이는 더러운 기분을 느끼고 싶은 분은 앱...   \n","1  최악의 앱 사진 등록 한 번 하려면 앨범에서 선택할 수가 없음 권한을 항상 허용으로...   \n","2                                                 먹통   \n","3  아이디 찾기했더니 네이버부동산 메일로 로그인 뜨길래 비밀번호를 몰라 찾기 하니 계속...   \n","4                             오피스텔 허위매물 등록 오류로 등록 불가   \n","\n","                                       content_token  \\\n","0  [순식간, 에, 결제, 됩니다, 완전히, 눈, 뜨고, 코, 베이, 는, 더러운, 기...   \n","1  [최악, 의, 앱, 사진, 등록, 한, 번, 하려면, 앨범, 에서, 선택, 할, 수...   \n","2                                               [먹통]   \n","3  [아이디, 찾기, 했더니, 네이버, 부동산, 메일, 로, 로그인, 뜨길래, 비밀번호...   \n","4                      [오피스텔, 허위매물, 등록, 오류로, 등록, 불가]   \n","\n","                                         content_pos  \\\n","0  [(순식간, Noun), (에, Josa), (결제, Noun), (됩니다, Ver...   \n","1  [(최악, Noun), (의, Josa), (앱, Noun), (사진, Noun),...   \n","2                                       [(먹통, Noun)]   \n","3  [(아이디, Noun), (찾기, Noun), (했더니, Verb), (네이버, N...   \n","4  [(오피스텔, Noun), (허위매물, Noun), (등록, Noun), (오류로,...   \n","\n","                                          nouns_only  \\\n","0                  [순식간, 결제, 눈, 코, 베이, 기분, 분, 앱, 가입]   \n","1  [최악, 앱, 사진, 등록, 번, 앨범, 선택, 수가, 권한, 항상, 허용, 권한,...   \n","2                                               [먹통]   \n","3  [아이디, 찾기, 네이버, 부동산, 메일, 로그인, 비밀번호, 찾기, 하니, 계속,...   \n","4                      [오피스텔, 허위매물, 등록, 오류로, 등록, 불가]   \n","\n","                             nouns_without_stopwords  \n","0                     [순식간, 결제, 눈, 코, 베이, 기분, 앱, 가입]  \n","1  [최악, 앱, 사진, 등록, 앨범, 선택, 권한, 항상, 허용, 권한, 설정, 앞,...  \n","2                                               [먹통]  \n","3  [아이디, 찾기, 메일, 로그인, 비밀번호, 찾기, 하니, 일시, 오류로, 메일, ...  \n","4                      [오피스텔, 허위매물, 등록, 오류로, 등록, 불가]  \n","'reviews_data_피터팬_별점.csv' 결과 저장 완료: /content/drive/MyDrive/2024/TextMining/reviews_data/preprocessed4_reviews_data_피터팬_별점.csv\n","'reviews_data_호갱노노_별점.csv' 데이터 로드 성공\n","'reviews_data_호갱노노_별점.csv' 전처리 및 토큰화, 품사 태깅 완료:\n","                                              content  \\\n","0  지도에 아파트 분양 광고가 나오는데요, 손가락으로 터치가 아니고 조금만 분양 광고를...   \n","1  문의하기 버튼이 있는데도 사진을 보려면 자동으로 중개사님께 연락이 가던데 그저 아직...   \n","2  호갱노노가 매우 좋았던 점이 가격과 히스토리(과거 매매, 전세 등 이력)가 공개되어...   \n","3  GPS끄는 기능만드세요. 어플정보에는 위치정보 수집하고 보관하지 않는 다는데 회사약...   \n","4  기본적으로 본인 아파트 후기를 남기고 추가로 후기를 남기는 시스템이 아니라 특정한 ...   \n","\n","                                content_preprocessed  \\\n","0  지도에 아파트 분양 광고가 나오는데요 손가락으로 터치가 아니고 조금만 분양 광고를 ...   \n","1  문의하기 버튼이 있는데도 사진을 보려면 자동으로 공인중개사 연락이 가던데 그저 아직...   \n","2  호갱노노 매우 좋았던 점이 가격과 히스토리 과거 매매 전세 등 이력 뒤로가기 공개되...   \n","3  GPS 끄는 기능 만드세요 앱 정보에는 위치정보 수집하고 보관하지 않는 다는 업데이...   \n","4  기본적으로 본인인증 아파트 후기를 남기고 추가로 후기를 남기는 시스템이 아니라 특정...   \n","\n","                                       content_token  \\\n","0  [지도, 에, 아파트, 분양, 광고, 가, 나오는데요, 손가락, 으로, 터치, 가,...   \n","1  [문의, 하기, 버튼, 이, 있는데도, 사진, 을, 보려면, 자동, 으로, 공인중개...   \n","2  [호갱노노, 매우, 좋았던, 점, 이, 가격, 과, 히스토리, 과거, 매매, 전세,...   \n","3  [GPS, 끄는, 기능, 만드세요, 앱, 정보, 에는, 위치, 정보, 수집, 하고,...   \n","4  [기본, 적, 으로, 본인인증, 아파트, 후기, 를, 남기고, 추가, 로, 후기, ...   \n","\n","                                         content_pos  \\\n","0  [(지도, Noun), (에, Josa), (아파트, Noun), (분양, Noun...   \n","1  [(문의, Noun), (하기, Verb), (버튼, Noun), (이, Josa)...   \n","2  [(호갱노노, Noun), (매우, Noun), (좋았던, Adjective), (...   \n","3  [(GPS, Alpha), (끄는, Verb), (기능, Noun), (만드세요, ...   \n","4  [(기본, Noun), (적, Suffix), (으로, Josa), (본인인증, N...   \n","\n","                                          nouns_only  \\\n","0  [지도, 아파트, 분양, 광고, 손가락, 터치, 조금, 분양, 광고, 손가락, 스와...   \n","1  [문의, 버튼, 사진, 자동, 공인중개사, 연락, 관심, 정도, 사람, 강제, 연결...   \n","2  [호갱노노, 매우, 점, 가격, 히스토리, 과거, 매매, 전세, 등, 이력, 뒤로가...   \n","3  [기능, 앱, 정보, 위치, 정보, 수집, 보관, 업데이트, 회사, 약관, 보관, ...   \n","4  [기본, 본인인증, 아파트, 후기, 추가, 후기, 시스템, 목적, 가지, 특정, 아...   \n","\n","                             nouns_without_stopwords  \n","0  [지도, 아파트, 분양, 광고, 손가락, 터치, 분양, 광고, 손가락, 스와이프, ...  \n","1  [문의, 버튼, 사진, 자동, 공인중개사, 연락, 관심, 정도, 사람, 강제, 연결...  \n","2  [가격, 히스토리, 과거, 매매, 전세, 이력, 뒤로가기, 공개, 비교, 히스토리,...  \n","3  [기능, 앱, 정보, 위치, 정보, 수집, 보관, 업데이트, 회사, 약관, 보관, ...  \n","4  [기본, 본인인증, 아파트, 후기, 추가, 후기, 시스템, 목적, 가지, 특정, 아...  \n","'reviews_data_호갱노노_별점.csv' 결과 저장 완료: /content/drive/MyDrive/2024/TextMining/reviews_data/preprocessed4_reviews_data_호갱노노_별점.csv\n"]}],"source":["import pandas as pd\n","import re\n","\n","# 처리할 파일 리스트\n","file_names = [\n","    'reviews_data_네이버부동산_별점.csv',\n","    'reviews_data_다방_별점.csv',\n","    #'reviews_data_직방_별점.csv',\n","    'reviews_data_피터팬_별점.csv',\n","    'reviews_data_호갱노노_별점.csv'\n","]\n","\n","# 데이터 로드, 전처리 및 저장\n","for file_name in file_names:\n","    file_path = os.path.join(data_path, file_name)\n","    try:\n","        # 데이터 로드\n","        df = pd.read_csv(file_path)\n","        print(f\"'{file_name}' 데이터 로드 성공\")\n","\n","        # 전처리 적용\n","        df['content_preprocessed'] = df['content'].apply(preprocess_pipeline)  # 전처리\n","\n","        # NaN 값 처리 (빈 문자열로 대체)\n","        df['content_preprocessed'] = df['content_preprocessed'].fillna('')\n","\n","        # 숫자 값을 문자열로 변환\n","        df['content_preprocessed'] = df['content_preprocessed'].apply(str)\n","\n","        # 철자 교정 및 유사어 통합 적용\n","        df['content_preprocessed'] = df['content_preprocessed'].apply(\n","            lambda x: correct_and_unify_words(x, synonym_dict)\n","        )\n","\n","        # 토큰화 및 품사 태깅\n","        df['content_token'] = df['content_preprocessed'].apply(tokenize)  # 토큰화\n","        df['content_pos'] = df['content_preprocessed'].apply(pos_tagging)  # 품사 태깅\n","\n","        # 문자열로 저장된 리스트를 실제 리스트로 변환\n","        df['content_pos'] = df['content_pos'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n","        # float 타입 값 처리\n","        df['content_pos'] = df['content_pos'].apply(lambda x: x if isinstance(x, list) else [])\n","\n","        # 명사만 추출하여 새로운 칼럼 'nouns_only'에 저장\n","        df['nouns_only'] = df['content_pos'].apply(\n","            lambda x: [word for word, pos in x if pos == 'Noun']\n","            )\n","\n","        # 불용어 제거\n","        df['nouns_without_stopwords'] = df['nouns_only'].apply(remove_stopwords)\n","\n","        # 결과 출력 (샘플)\n","        print(f\"'{file_name}' 전처리 및 토큰화, 품사 태깅 완료:\\n\", df[['content', 'content_preprocessed', 'content_token', 'content_pos', 'nouns_only', 'nouns_without_stopwords']].head())\n","\n","        # 결과 저장\n","        output_path = os.path.join(data_path, f'preprocessed4_{file_name}')\n","        df.to_csv(output_path, index=False)\n","        print(f\"'{file_name}' 결과 저장 완료: {output_path}\")\n","\n","    except Exception as e:\n","        print(f\"'{file_name}' 처리 중 오류 발생: {e}\")\n"]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","\n","# 처리할 파일 리스트\n","file_names = [\n","    #'reviews_data_네이버부동산_별점.csv',\n","    #'reviews_data_다방_별점.csv',\n","    'reviews_data_직방_별점.csv',\n","    #'reviews_data_피터팬_별점.csv',\n","    #'reviews_data_호갱노노_별점.csv'\n","]\n","\n","# 데이터 로드, 전처리 및 저장\n","for file_name in file_names:\n","    file_path = os.path.join(data_path, file_name)\n","    try:\n","        # 데이터 로드\n","        df = pd.read_csv(file_path)\n","        print(f\"'{file_name}' 데이터 로드 성공\")\n","\n","        # 전처리 적용\n","        df['content_preprocessed'] = df['content'].apply(preprocess_pipeline)  # 전처리\n","\n","        # NaN 값 처리 (빈 문자열로 대체)\n","        df['content_preprocessed'] = df['content_preprocessed'].fillna('')\n","\n","        # 숫자 값을 문자열로 변환\n","        df['content_preprocessed'] = df['content_preprocessed'].apply(str)\n","\n","        # 철자 교정 및 유사어 통합 적용\n","        df['content_preprocessed'] = df['content_preprocessed'].apply(\n","            lambda x: correct_and_unify_words(x, synonym_dict)\n","        )\n","\n","        # 토큰화 및 품사 태깅\n","        df['content_token'] = df['content_preprocessed'].apply(tokenize)  # 토큰화\n","        df['content_pos'] = df['content_preprocessed'].apply(pos_tagging)  # 품사 태깅\n","\n","        # 문자열로 저장된 리스트를 실제 리스트로 변환\n","        df['content_pos'] = df['content_pos'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n","        # float 타입 값 처리\n","        df['content_pos'] = df['content_pos'].apply(lambda x: x if isinstance(x, list) else [])\n","\n","        # 명사만 추출하여 새로운 칼럼 'nouns_only'에 저장\n","        df['nouns_only'] = df['content_pos'].apply(\n","            lambda x: [word for word, pos in x if pos == 'Noun']\n","            )\n","\n","        # 불용어 제거\n","        df['nouns_without_stopwords'] = df['nouns_only'].apply(remove_stopwords)\n","\n","        # 결과 출력 (샘플)\n","        print(f\"'{file_name}' 전처리 및 토큰화, 품사 태깅 완료:\\n\", df[['content', 'content_preprocessed', 'content_token', 'content_pos', 'nouns_only', 'nouns_without_stopwords']].head())\n","\n","        # 결과 저장\n","        output_path = os.path.join(data_path, f'preprocessed4_{file_name}')\n","        df.to_csv(output_path, index=False)\n","        print(f\"'{file_name}' 결과 저장 완료: {output_path}\")\n","\n","    except Exception as e:\n","        print(f\"'{file_name}' 처리 중 오류 발생: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRN82QFsd7UP","executionInfo":{"status":"ok","timestamp":1733477090344,"user_tz":-540,"elapsed":240433,"user":{"displayName":"김현서","userId":"16609558155508415553"}},"outputId":"d8196eea-4984-4f85-9744-452e5f1b8ab2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'reviews_data_직방_별점.csv' 데이터 로드 성공\n","'reviews_data_직방_별점.csv' 전처리 및 토큰화, 품사 태깅 완료:\n","                                              content  \\\n","0         아니 왜 모바일 웹사이트는 안들어가지고 무조건 어플을 설치하게 합니까? ㅡㅡ   \n","1  도대체 언제까지 그렇게 우둔한 필터로 쓰라는거죠? 무슨 1층필터도 없고, 그냥 보증...   \n","2       매물도 없으면서 푸시알림만 많이 보내서 지워요 그냥 네이버부동산을 보는게 좋을듯   \n","3  1.지도 옮길때마다 뜨는 건 좋은데 버벅이구요. 클릭했다가 또 다른걸 클릭하면 또 ...   \n","4  매물 알아보고 뭐 할때마다 연락받으셨나요 어떠셨나요 알림 한번이면 모르겠는데 적당히...   \n","\n","                                content_preprocessed  \\\n","0           아니 왜 모바일 웹사이트는 안 들어가지고 무조건 앱 설치하게 합니까 ㅡㅡ   \n","1  도대체 언제까지 그렇게 우둔한 필터로 쓰라는 거죠 무슨 1층 필터도 없고 그냥 보증...   \n","2  매물도 없으면서 푸시 알림만 많이 보내서 지워요 그냥 네이버부동산 부동산을 보는 게...   \n","3  1 지도 옮길 때마다 뜨는 실매물 좋은데 버벅이구요 클릭했다가 또 다른 걸 클릭하면...   \n","4  허위매물 알아보고 뭐 할 때마다 연락받으셨나요 어떠셨나요 알림 한 번이면 모르겠는데...   \n","\n","                                       content_token  \\\n","0  [아니, 왜, 모바일, 웹사이트, 는, 안, 들어가지고, 무조건, 앱, 설치, 하게...   \n","1  [도대체, 언제, 까지, 그렇게, 우둔한, 필터, 로, 쓰라는, 거, 죠, 무슨, ...   \n","2  [매물도, 없으면서, 푸시, 알림, 만, 많이, 보내서, 지워요, 그냥, 네이버, ...   \n","3  [1, 지도, 옮길, 때, 마다, 뜨는, 실매물, 좋은데, 버벅이구, 요, 클릭, ...   \n","4  [허위매물, 알아보고, 뭐, 할, 때, 마다, 연락, 받으셨나요, 어떠셨나요, 알림...   \n","\n","                                         content_pos  \\\n","0  [(아니, Adjective), (왜, Noun), (모바일, Noun), (웹사이...   \n","1  [(도대체, Noun), (언제, Noun), (까지, Josa), (그렇게, Ad...   \n","2  [(매물도, Noun), (없으면서, Adjective), (푸시, Noun), (...   \n","3  [(1, Number), (지도, Noun), (옮길, Verb), (때, Noun...   \n","4  [(허위매물, Noun), (알아보고, Verb), (뭐, Noun), (할, Ve...   \n","\n","                                          nouns_only  \\\n","0                   [왜, 모바일, 웹사이트, 안, 무조건, 앱, 설치, 합]   \n","1  [도대체, 언제, 필터, 거, 무슨, 층, 필터, 그냥, 보증금, 월세, 지층, 제...   \n","2             [매물도, 푸시, 알림, 그냥, 네이버, 부동산, 부동산, 게, 듯]   \n","3  [지도, 때, 실매물, 버벅이구, 클릭, 또, 다른, 걸, 클릭, 또, 버벅입니, ...   \n","4  [허위매물, 뭐, 때, 연락, 알림, 번, 앱, 번, 때, 계속, 알람, 거, 수정...   \n","\n","                             nouns_without_stopwords  \n","0                         [모바일, 웹사이트, 무조건, 앱, 설치, 합]  \n","1  [도대체, 필터, 층, 필터, 보증금, 월세, 지층, 제외, 원룸, 투룸, 정도, ...  \n","2                                      [매물도, 푸시, 알림]  \n","3  [지도, 실매물, 버벅이구, 클릭, 클릭, 버벅입니, 웹, 모바일, 공통, 공인중개...  \n","4                          [허위매물, 연락, 알림, 앱, 알람, 수정]  \n","'reviews_data_직방_별점.csv' 결과 저장 완료: /content/drive/MyDrive/2024/TextMining/reviews_data/preprocessed4_reviews_data_직방_별점.csv\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","import pandas as pd\n","import ast\n","\n","# 처리할 파일 리스트\n","file_names = [\n","    'preprocessed4_reviews_data_네이버부동산_별점.csv',\n","    'preprocessed4_reviews_data_다방_별점.csv',\n","    'preprocessed4_reviews_data_직방_별점.csv',\n","    'preprocessed4_reviews_data_피터팬_별점.csv',\n","    'preprocessed4_reviews_data_호갱노노_별점.csv'\n","]\n","\n","# 각 파일별 단어 빈도 분석\n","for file_name in file_names:\n","    file_path = os.path.join(data_path, file_name)\n","    try:\n","        # 데이터 로드\n","        df = pd.read_csv(file_path)\n","        print(f\"'{file_name}' 데이터 로드 성공\")\n","\n","        # 리스트 변환 (필요 시 ast.literal_eval 적용)\n","        df['nouns_without_stopwords'] = df['nouns_without_stopwords'].apply(\n","            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n","        )\n","\n","        # 1. 리스트 병합 (Flattening)\n","        all_nouns = [word for sublist in df['nouns_without_stopwords'] for word in sublist]\n","\n","        # 2. 단어 빈도 계산\n","        word_counts = Counter(all_nouns)\n","\n","        # 3. 상위 50개 단어 추출\n","        top_50_words = word_counts.most_common(50)\n","\n","        # 4. 결과 출력\n","        print(f\"'{file_name}' 상위 50개 단어:\")\n","        for rank, (word, count) in enumerate(top_50_words, 1):\n","            print(f\"{rank}. {word}: {count}\")\n","\n","    except Exception as e:\n","        print(f\"'{file_name}' 처리 중 오류 발생: {e}\")"],"metadata":{"id":"ADH2B3xlUzPD","executionInfo":{"status":"ok","timestamp":1733477697445,"user_tz":-540,"elapsed":7819,"user":{"displayName":"김현서","userId":"16609558155508415553"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2eadf51a-d4bc-499a-dd50-391da94f248e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'preprocessed4_reviews_data_네이버부동산_별점.csv' 데이터 로드 성공\n","'preprocessed4_reviews_data_네이버부동산_별점.csv' 상위 50개 단어:\n","1. 앱: 724\n","2. 업데이트: 505\n","3. 버전: 412\n","4. 허위매물: 343\n","5. 뒤로가기: 281\n","6. 매물: 177\n","7. 검색: 176\n","8. 지도: 165\n","9. 최악: 162\n","10. 사용: 156\n","11. 보기: 149\n","12. 화면: 130\n","13. 평수: 102\n","14. 정보: 99\n","15. 아파트: 98\n","16. 오류: 93\n","17. 실매물: 93\n","18. 기능: 91\n","19. 공인중개사: 88\n","20. 리뷰: 78\n","21. 선택: 76\n","22. 사진: 76\n","23. 다운로드: 73\n","24. 별로: 71\n","25. 종료: 68\n","26. 확인: 68\n","27. 개선: 65\n","28. 필터: 65\n","29. 설정: 62\n","30. 임대인: 62\n","31. 수정: 60\n","32. 개발자: 59\n","33. 관심: 58\n","34. 쓰기: 56\n","35. 사람: 55\n","36. 버튼: 54\n","37. 조건: 54\n","38. 쓰레기: 54\n","39. 사용자: 53\n","40. 말: 52\n","41. 정도: 52\n","42. 로딩: 50\n","43. 위치: 50\n","44. 삭제: 49\n","45. 클릭: 48\n","46. 면적: 47\n","47. 문제: 47\n","48. 찾기: 47\n","49. 이후: 44\n","50. 지금: 44\n","'preprocessed4_reviews_data_다방_별점.csv' 데이터 로드 성공\n","'preprocessed4_reviews_data_다방_별점.csv' 상위 50개 단어:\n","1. 앱: 6902\n","2. 허위매물: 5497\n","3. 임대인: 3145\n","4. 방: 2383\n","5. 매물: 2305\n","6. 정보: 1531\n","7. 공인중개사: 1167\n","8. 집: 1069\n","9. 원룸: 1055\n","10. 추천: 945\n","11. 이용: 886\n","12. 사진: 880\n","13. 사용: 845\n","14. 최고: 770\n","15. 검색: 769\n","16. 계약: 746\n","17. 보기: 689\n","18. 월세: 679\n","19. 기능: 659\n","20. 필터: 653\n","21. 찾기: 653\n","22. 가격: 629\n","23. 덕분: 620\n","24. 실매물: 614\n","25. 확인: 577\n","26. 말: 575\n","27. 업데이트: 568\n","28. 도움: 556\n","29. 신고: 544\n","30. 사람: 535\n","31. 관리: 506\n","32. 연락: 499\n","33. 직접: 489\n","34. 별로: 483\n","35. 조건: 470\n","36. 이사: 466\n","37. 광고: 465\n","38. 뒤로가기: 460\n","39. 전세: 447\n","40. 필요: 441\n","41. 비교: 405\n","42. 지역: 380\n","43. 정도: 376\n","44. 대박: 374\n","45. 평수: 357\n","46. 짱: 353\n","47. 주변: 340\n","48. 제일: 326\n","49. 마음: 325\n","50. 가장: 322\n","'preprocessed4_reviews_data_직방_별점.csv' 데이터 로드 성공\n","'preprocessed4_reviews_data_직방_별점.csv' 상위 50개 단어:\n","1. 앱: 6909\n","2. 허위매물: 4659\n","3. 방: 3238\n","4. 공인중개사: 1890\n","5. 임대인: 1854\n","6. 매물: 1851\n","7. 사진: 1725\n","8. 정보: 1295\n","9. 검색: 1238\n","10. 업데이트: 1170\n","11. 최고: 1159\n","12. 광고: 1053\n","13. 집: 1028\n","14. 가격: 861\n","15. 실매물: 832\n","16. 사람: 777\n","17. 연락: 775\n","18. 사용: 774\n","19. 말: 769\n","20. 계약: 758\n","21. 원룸: 751\n","22. 보기: 750\n","23. 전화: 701\n","24. 뒤로가기: 669\n","25. 별로: 664\n","26. 월세: 642\n","27. 필터: 636\n","28. 확인: 633\n","29. 평수: 633\n","30. 이용: 615\n","31. 기능: 598\n","32. 아파트: 594\n","33. 신고: 584\n","34. 직접: 567\n","35. 지역: 547\n","36. 삭제: 499\n","37. 추천: 495\n","38. 도움: 473\n","39. 설치: 447\n","40. 전세: 443\n","41. 관리: 439\n","42. 찾기: 409\n","43. 짱: 409\n","44. 다운로드: 406\n","45. 이사: 390\n","46. 발품: 381\n","47. 지도: 371\n","48. 사기: 356\n","49. 등록: 340\n","50. 리뷰: 340\n","'preprocessed4_reviews_data_피터팬_별점.csv' 데이터 로드 성공\n","'preprocessed4_reviews_data_피터팬_별점.csv' 상위 50개 단어:\n","1. 앱: 1807\n","2. 허위매물: 1001\n","3. 대박: 851\n","4. 임대인: 514\n","5. 매물: 450\n","6. 정보: 367\n","7. 최고: 314\n","8. 방: 305\n","9. 사용: 262\n","10. 보기: 235\n","11. 추천: 233\n","12. 직거래: 217\n","13. 공인중개사: 198\n","14. 짱: 193\n","15. 집: 183\n","16. 연락: 162\n","17. 이용: 160\n","18. 사진: 159\n","19. 업데이트: 152\n","20. 수수료: 149\n","21. 확인: 142\n","22. 검색: 126\n","23. 신고: 123\n","24. 찾기: 115\n","25. 도움: 115\n","26. 등록: 112\n","27. 두꺼비: 112\n","28. 말: 108\n","29. 실매물: 107\n","30. 카페: 102\n","31. 필터: 99\n","32. 삭제: 95\n","33. 광고: 94\n","34. 사람: 92\n","35. 짱짱: 92\n","36. 계약: 91\n","37. 뒤로가기: 87\n","38. 원룸: 85\n","39. 전화: 83\n","40. 세상: 83\n","41. 회원: 82\n","42. 관리: 81\n","43. 눈: 80\n","44. 가격: 80\n","45. 이사: 79\n","46. 별로: 76\n","47. 다운로드: 75\n","48. 중개: 75\n","49. 로그인: 73\n","50. 설치: 72\n","'preprocessed4_reviews_data_호갱노노_별점.csv' 데이터 로드 성공\n","'preprocessed4_reviews_data_호갱노노_별점.csv' 상위 50개 단어:\n","1. 앱: 576\n","2. 아파트: 378\n","3. 정보: 294\n","4. 글: 170\n","5. 실거래: 163\n","6. 최고: 144\n","7. 업데이트: 136\n","8. 평수: 120\n","9. 삭제: 113\n","10. 기능: 110\n","11. 사람: 104\n","12. 사용: 102\n","13. 가격: 101\n","14. 허위매물: 99\n","15. 댓글: 87\n","16. 수정: 83\n","17. 오류: 82\n","18. 이야기: 80\n","19. 임대인: 79\n","20. 보기: 76\n","21. 뒤로가기: 75\n","22. 신고: 75\n","23. 문의: 70\n","24. 거래: 70\n","25. 실매물: 70\n","26. 확인: 65\n","27. 지도: 64\n","28. 관리: 64\n","29. 검색: 59\n","30. 알림: 59\n","31. 가입: 58\n","32. 말: 57\n","33. 시세: 57\n","34. 호갱: 53\n","35. 설정: 53\n","36. 주민: 51\n","37. 도움: 51\n","38. 개선: 50\n","39. 공인중개사: 48\n","40. 리뷰: 48\n","41. 분양: 47\n","42. 표시: 47\n","43. 위치: 42\n","44. 등록: 41\n","45. 집값: 41\n","46. 이용: 40\n","47. 반영: 40\n","48. 사진: 38\n","49. 답변: 38\n","50. 별로: 38\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","# 처리된 파일 리스트\n","processed_file_names = [\n","    'preprocessed4_reviews_data_다방_별점.csv',\n","    'preprocessed4_reviews_data_직방_별점.csv',\n","    'preprocessed4_reviews_data_피터팬_별점.csv',\n","    'preprocessed4_reviews_data_네이버부동산_별점.csv',\n","    'preprocessed4_reviews_data_호갱노노_별점.csv'\n","]\n","\n","# 데이터 로드 및 통합\n","dataframes = []\n","for file_name in processed_file_names:\n","    try:\n","        file_path = os.path.join(data_path, file_name)\n","        df = pd.read_csv(file_path, usecols=[\n","            'content',\n","            'content_preprocessed',\n","            'content_token',\n","            'content_pos',\n","            'nouns_only',\n","            'nouns_without_stopwords'\n","        ])\n","        df['source'] = file_name.split('_')[2]  # 소스 앱 이름 추가\n","        dataframes.append(df)\n","    except Exception as e:\n","        print(f\"파일 '{file_name}' 로드 중 오류 발생: {e}\")\n","\n","\n","# 데이터프레임을 직접 출력\n","if dataframes:\n","    combined_df = pd.concat(dataframes, ignore_index=True)\n","    print(combined_df.head())  # 데이터프레임 상위 5행 출력\n","else:\n","    print(\"데이터를 로드할 수 없습니다. 파일 경로 또는 내용 확인이 필요합니다.\")\n"],"metadata":{"id":"SpUBzh9hU6tU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733593631293,"user_tz":-540,"elapsed":5631,"user":{"displayName":"김현서","userId":"16609558155508415553"}},"outputId":"c0382a8b-79a1-4ad5-9a65-b822a77f73fe"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["                                             content  \\\n","0  아니 왜? 쓰리룸이나 포룸 보는걸 이상한걸로 통합시켜서 짜증나게 만드는거죠 만드는 ...   \n","1  부동산 일하다가 탈출한 사람입니다. 허위매물 안 하고 정직하게 했는데 연락 1도 없...   \n","2  뭐 어떻게 찾으라는건지 모르겠음. 검색은 어떻게 하는건가요. 지도를 다 헤짚어놓으면...   \n","3  허위매물천지임 해리 광고 땜에 유명한것도 사실인데 해리 아무거나 광고하나봄 조폭껴잇...   \n","4    아파트 오피스텔 왜 이따위로 분류 한거지? 진짜 짜증나게 뭣같이 바꼈네 하던데로 해라   \n","\n","                                content_preprocessed  \\\n","0  아니 왜 쓰리룸이나 포룸 보는 걸 이상한 걸로 통합시켜서 짜증나게 만드는 거죠 만드...   \n","1  네이버부동산 일하다가 탈출한 사람입니다 허위매물 안 하고 정직하게 했는데 연락 1도...   \n","2  뭐 어떻게 찾으라는 건지 모르겠음 검색은 어떻게 하는 건가요 지도를 다방 헤 짚어놓...   \n","3  허위매물 천지 임 해리 광고 땜에 유명한 것도 사실인데 해리 아무거나 광고 하나 봄...   \n","4  아파트 오피스텔 왜 네이버부동산 따위로 분류 한 거지 진짜 짜증나게 뭣같이 바꼈네 ...   \n","\n","                                       content_token  \\\n","0  ['아니', '왜', '쓰리룸', '이나', '포룸', '보는', '걸', '이상한...   \n","1  ['네이버', '부동산', '일', '하다가', '탈출', '한', '사람', '입...   \n","2  ['뭐', '어떻게', '찾으라는', '건지', '모르겠음', '검색', '은', ...   \n","3  ['허위매물', '천지', '임', '해리', '광고', '땜', '에', '유명한...   \n","4  ['아파트', '오피스텔', '왜', '네이버', '부동산', '따위', '로', ...   \n","\n","                                         content_pos  \\\n","0  [('아니', 'Adjective'), ('왜', 'Noun'), ('쓰리룸', '...   \n","1  [('네이버', 'Noun'), ('부동산', 'Noun'), ('일', 'Noun...   \n","2  [('뭐', 'Noun'), ('어떻게', 'Adjective'), ('찾으라는',...   \n","3  [('허위매물', 'Noun'), ('천지', 'Noun'), ('임', 'Noun...   \n","4  [('아파트', 'Noun'), ('오피스텔', 'Noun'), ('왜', 'Nou...   \n","\n","                                          nouns_only  \\\n","0  ['왜', '쓰리룸', '포룸', '걸', '걸', '통합', '거', '안', '...   \n","1  ['네이버', '부동산', '일', '탈출', '사람', '허위매물', '안', '...   \n","2           ['뭐', '검색', '건가', '지도', '다방', '헤', '건가']   \n","3  ['허위매물', '천지', '임', '해리', '광고', '땜', '것', '사실'...   \n","4  ['아파트', '오피스텔', '왜', '네이버', '부동산', '따위', '분류',...   \n","\n","                             nouns_without_stopwords source  \n","0                          ['쓰리룸', '포룸', '통합', '만드']   data  \n","1  ['탈출', '사람', '허위매물', '연락', '도', '허위매물', '연락', ...   data  \n","2                      ['검색', '건가', '지도', '헤', '건가']   data  \n","3  ['허위매물', '천지', '해리', '광고', '땜', '사실', '해리', '거...   data  \n","4                        ['아파트', '오피스텔', '분류', '거지']   data  \n"]}]},{"cell_type":"code","source":["from IPython.display import display\n","\n","if dataframes:\n","    combined_df = pd.concat(dataframes, ignore_index=True)\n","    display(combined_df)  # 전체 데이터프레임 표시 (셀 크기에 따라 스크롤 가능)\n","else:\n","    print(\"데이터를 로드할 수 없습니다. 파일 경로 또는 내용 확인이 필요합니다.\")\n"],"metadata":{"id":"lEr5QAjjrgGf","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1733593682253,"user_tz":-540,"elapsed":1385,"user":{"displayName":"김현서","userId":"16609558155508415553"}},"outputId":"e997488f-694b-441f-8233-06b4d1893374"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                 content  \\\n","0      아니 왜? 쓰리룸이나 포룸 보는걸 이상한걸로 통합시켜서 짜증나게 만드는거죠 만드는 ...   \n","1      부동산 일하다가 탈출한 사람입니다. 허위매물 안 하고 정직하게 했는데 연락 1도 없...   \n","2      뭐 어떻게 찾으라는건지 모르겠음. 검색은 어떻게 하는건가요. 지도를 다 헤짚어놓으면...   \n","3      허위매물천지임 해리 광고 땜에 유명한것도 사실인데 해리 아무거나 광고하나봄 조폭껴잇...   \n","4        아파트 오피스텔 왜 이따위로 분류 한거지? 진짜 짜증나게 뭣같이 바꼈네 하던데로 해라   \n","...                                                  ...   \n","71123                                            보기 편합니다   \n","71124                                                조와요   \n","71125                                                좋네여   \n","71126                                              굳잡 !!   \n","71127                                                 네~   \n","\n","                                    content_preprocessed  \\\n","0      아니 왜 쓰리룸이나 포룸 보는 걸 이상한 걸로 통합시켜서 짜증나게 만드는 거죠 만드...   \n","1      네이버부동산 일하다가 탈출한 사람입니다 허위매물 안 하고 정직하게 했는데 연락 1도...   \n","2      뭐 어떻게 찾으라는 건지 모르겠음 검색은 어떻게 하는 건가요 지도를 다방 헤 짚어놓...   \n","3      허위매물 천지 임 해리 광고 땜에 유명한 것도 사실인데 해리 아무거나 광고 하나 봄...   \n","4      아파트 오피스텔 왜 네이버부동산 따위로 분류 한 거지 진짜 짜증나게 뭣같이 바꼈네 ...   \n","...                                                  ...   \n","71123                                            보기 편합니다   \n","71124                                                조와요   \n","71125                                                좋네여   \n","71126                                                좋아요   \n","71127                                             네이버부동산   \n","\n","                                           content_token  \\\n","0      ['아니', '왜', '쓰리룸', '이나', '포룸', '보는', '걸', '이상한...   \n","1      ['네이버', '부동산', '일', '하다가', '탈출', '한', '사람', '입...   \n","2      ['뭐', '어떻게', '찾으라는', '건지', '모르겠음', '검색', '은', ...   \n","3      ['허위매물', '천지', '임', '해리', '광고', '땜', '에', '유명한...   \n","4      ['아파트', '오피스텔', '왜', '네이버', '부동산', '따위', '로', ...   \n","...                                                  ...   \n","71123                                     ['보기', '편합니다']   \n","71124                                    ['조', '와', '요']   \n","71125                                    ['좋', '네', '여']   \n","71126                                            ['좋아요']   \n","71127                                     ['네이버', '부동산']   \n","\n","                                             content_pos  \\\n","0      [('아니', 'Adjective'), ('왜', 'Noun'), ('쓰리룸', '...   \n","1      [('네이버', 'Noun'), ('부동산', 'Noun'), ('일', 'Noun...   \n","2      [('뭐', 'Noun'), ('어떻게', 'Adjective'), ('찾으라는',...   \n","3      [('허위매물', 'Noun'), ('천지', 'Noun'), ('임', 'Noun...   \n","4      [('아파트', 'Noun'), ('오피스텔', 'Noun'), ('왜', 'Nou...   \n","...                                                  ...   \n","71123            [('보기', 'Noun'), ('편합니다', 'Adjective')]   \n","71124      [('조', 'Noun'), ('와', 'Josa'), ('요', 'Noun')]   \n","71125  [('좋', 'Adjective'), ('네', 'Determiner'), ('여'...   \n","71126                             [('좋아요', 'Adjective')]   \n","71127                 [('네이버', 'Noun'), ('부동산', 'Noun')]   \n","\n","                                              nouns_only  \\\n","0      ['왜', '쓰리룸', '포룸', '걸', '걸', '통합', '거', '안', '...   \n","1      ['네이버', '부동산', '일', '탈출', '사람', '허위매물', '안', '...   \n","2               ['뭐', '검색', '건가', '지도', '다방', '헤', '건가']   \n","3      ['허위매물', '천지', '임', '해리', '광고', '땜', '것', '사실'...   \n","4      ['아파트', '오피스텔', '왜', '네이버', '부동산', '따위', '분류',...   \n","...                                                  ...   \n","71123                                             ['보기']   \n","71124                                         ['조', '요']   \n","71125                                              ['여']   \n","71126                                                 []   \n","71127                                     ['네이버', '부동산']   \n","\n","                                 nouns_without_stopwords source  \n","0                              ['쓰리룸', '포룸', '통합', '만드']   data  \n","1      ['탈출', '사람', '허위매물', '연락', '도', '허위매물', '연락', ...   data  \n","2                          ['검색', '건가', '지도', '헤', '건가']   data  \n","3      ['허위매물', '천지', '해리', '광고', '땜', '사실', '해리', '거...   data  \n","4                            ['아파트', '오피스텔', '분류', '거지']   data  \n","...                                                  ...    ...  \n","71123                                             ['보기']   data  \n","71124                                              ['조']   data  \n","71125                                                 []   data  \n","71126                                                 []   data  \n","71127                                                 []   data  \n","\n","[71128 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-7a4ade12-3dea-4af8-9f5a-650c19e55b04\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>content_preprocessed</th>\n","      <th>content_token</th>\n","      <th>content_pos</th>\n","      <th>nouns_only</th>\n","      <th>nouns_without_stopwords</th>\n","      <th>source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>아니 왜? 쓰리룸이나 포룸 보는걸 이상한걸로 통합시켜서 짜증나게 만드는거죠 만드는 ...</td>\n","      <td>아니 왜 쓰리룸이나 포룸 보는 걸 이상한 걸로 통합시켜서 짜증나게 만드는 거죠 만드...</td>\n","      <td>['아니', '왜', '쓰리룸', '이나', '포룸', '보는', '걸', '이상한...</td>\n","      <td>[('아니', 'Adjective'), ('왜', 'Noun'), ('쓰리룸', '...</td>\n","      <td>['왜', '쓰리룸', '포룸', '걸', '걸', '통합', '거', '안', '...</td>\n","      <td>['쓰리룸', '포룸', '통합', '만드']</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>부동산 일하다가 탈출한 사람입니다. 허위매물 안 하고 정직하게 했는데 연락 1도 없...</td>\n","      <td>네이버부동산 일하다가 탈출한 사람입니다 허위매물 안 하고 정직하게 했는데 연락 1도...</td>\n","      <td>['네이버', '부동산', '일', '하다가', '탈출', '한', '사람', '입...</td>\n","      <td>[('네이버', 'Noun'), ('부동산', 'Noun'), ('일', 'Noun...</td>\n","      <td>['네이버', '부동산', '일', '탈출', '사람', '허위매물', '안', '...</td>\n","      <td>['탈출', '사람', '허위매물', '연락', '도', '허위매물', '연락', ...</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>뭐 어떻게 찾으라는건지 모르겠음. 검색은 어떻게 하는건가요. 지도를 다 헤짚어놓으면...</td>\n","      <td>뭐 어떻게 찾으라는 건지 모르겠음 검색은 어떻게 하는 건가요 지도를 다방 헤 짚어놓...</td>\n","      <td>['뭐', '어떻게', '찾으라는', '건지', '모르겠음', '검색', '은', ...</td>\n","      <td>[('뭐', 'Noun'), ('어떻게', 'Adjective'), ('찾으라는',...</td>\n","      <td>['뭐', '검색', '건가', '지도', '다방', '헤', '건가']</td>\n","      <td>['검색', '건가', '지도', '헤', '건가']</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>허위매물천지임 해리 광고 땜에 유명한것도 사실인데 해리 아무거나 광고하나봄 조폭껴잇...</td>\n","      <td>허위매물 천지 임 해리 광고 땜에 유명한 것도 사실인데 해리 아무거나 광고 하나 봄...</td>\n","      <td>['허위매물', '천지', '임', '해리', '광고', '땜', '에', '유명한...</td>\n","      <td>[('허위매물', 'Noun'), ('천지', 'Noun'), ('임', 'Noun...</td>\n","      <td>['허위매물', '천지', '임', '해리', '광고', '땜', '것', '사실'...</td>\n","      <td>['허위매물', '천지', '해리', '광고', '땜', '사실', '해리', '거...</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>아파트 오피스텔 왜 이따위로 분류 한거지? 진짜 짜증나게 뭣같이 바꼈네 하던데로 해라</td>\n","      <td>아파트 오피스텔 왜 네이버부동산 따위로 분류 한 거지 진짜 짜증나게 뭣같이 바꼈네 ...</td>\n","      <td>['아파트', '오피스텔', '왜', '네이버', '부동산', '따위', '로', ...</td>\n","      <td>[('아파트', 'Noun'), ('오피스텔', 'Noun'), ('왜', 'Nou...</td>\n","      <td>['아파트', '오피스텔', '왜', '네이버', '부동산', '따위', '분류',...</td>\n","      <td>['아파트', '오피스텔', '분류', '거지']</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>71123</th>\n","      <td>보기 편합니다</td>\n","      <td>보기 편합니다</td>\n","      <td>['보기', '편합니다']</td>\n","      <td>[('보기', 'Noun'), ('편합니다', 'Adjective')]</td>\n","      <td>['보기']</td>\n","      <td>['보기']</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>71124</th>\n","      <td>조와요</td>\n","      <td>조와요</td>\n","      <td>['조', '와', '요']</td>\n","      <td>[('조', 'Noun'), ('와', 'Josa'), ('요', 'Noun')]</td>\n","      <td>['조', '요']</td>\n","      <td>['조']</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>71125</th>\n","      <td>좋네여</td>\n","      <td>좋네여</td>\n","      <td>['좋', '네', '여']</td>\n","      <td>[('좋', 'Adjective'), ('네', 'Determiner'), ('여'...</td>\n","      <td>['여']</td>\n","      <td>[]</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>71126</th>\n","      <td>굳잡 !!</td>\n","      <td>좋아요</td>\n","      <td>['좋아요']</td>\n","      <td>[('좋아요', 'Adjective')]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>data</td>\n","    </tr>\n","    <tr>\n","      <th>71127</th>\n","      <td>네~</td>\n","      <td>네이버부동산</td>\n","      <td>['네이버', '부동산']</td>\n","      <td>[('네이버', 'Noun'), ('부동산', 'Noun')]</td>\n","      <td>['네이버', '부동산']</td>\n","      <td>[]</td>\n","      <td>data</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>71128 rows × 7 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a4ade12-3dea-4af8-9f5a-650c19e55b04')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7a4ade12-3dea-4af8-9f5a-650c19e55b04 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7a4ade12-3dea-4af8-9f5a-650c19e55b04');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1b8ae3ea-4737-4f5f-957c-93c758e23dc1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b8ae3ea-4737-4f5f-957c-93c758e23dc1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1b8ae3ea-4737-4f5f-957c-93c758e23dc1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_0a11519e-b795-410b-bea5-e69e01302669\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0a11519e-b795-410b-bea5-e69e01302669 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('combined_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"combined_df","summary":"{\n  \"name\": \"combined_df\",\n  \"rows\": 71128,\n  \"fields\": [\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 59943,\n        \"samples\": [\n          \"\\ub4dc\\ub7ec\\ub098\\uc9c0 \\uc54a\\uc740  \\ubd80\\uc0b0\\uacfc \\uc6b8\\uc0b0. . .  \\uc624\\ub294\\uad6c\\ub098 \\ubd88\\uad6c\\ud558\\uace0  \\uc5c6\\uace0 \\uc774 \\uadf8. . . ?\",\n          \"\\ud3b8\\ub9ac\\ud558\\uace0 \\uc88b\\uc544\\uc694!!!\",\n          \"\\uc800\\ud76c \\ubd80\\ubaa8\\ub2d8\\uc774 \\uc61b\\ub0a0\\ubd80\\ud130 \\ubd80\\ub3d9\\uc0b0 \\uc911\\uac1c\\uc5c5\\uc18c\\ub97c \\ud558\\uc154\\uc11c \\ubd80\\ub3d9\\uc0b0 \\ucc3e\\ub294 \\ubc95 \\uc54c\\ub824\\ub4dc\\ub9bd\\ub2c8\\ub2e4. \\ubaa8\\ubc14\\uc77c \\uc774\\uc6a9\\ud558\\uc9c0 \\ub9c8\\uc2dc\\uace0 \\ucef4\\ud4e8\\ud130\\ub85c \\ub124\\uc774\\ubc84 \\ubd80\\ub3d9\\uc0b0 \\ub4e4\\uc5b4\\uac00\\uc11c \\ubcf4\\uc138\\uc694. \\ubaa8\\ubc14\\uc77c\\uc774\\ub791 \\ub9ce\\uc774 \\ub2e4\\ub97c\\uac81\\ub2c8\\ub2e4. \\uc798 \\ub098\\uac00\\uace0 \\uc624\\ub798\\ud558\\uc2e0 \\ubd80\\ub3d9\\uc0b0 \\uc911\\uac1c\\uc5c5\\uc18c\\ubd84\\ub4e4\\uc774 \\ub124\\uc774\\ubc84 \\ubd80\\ub3d9\\uc0b0\\uc744 \\uc8fc\\ub85c \\uc774\\uc6a9\\ud569\\ub2c8\\ub2e4. \\ub2e4\\ub978 \\ubaa8\\ubc14\\uc77c \\uc571 \\uc774\\uc6a9\\ud558\\uc9c0 \\ub9c8\\uc2dc\\uace0 \\ucef4\\ud4e8\\ud130 \\ub124\\uc774\\ubc84 \\ubd80\\ub3d9\\uc0b0 \\uc774\\uc6a9\\ud558\\uc2dc\\ub294\\uac70 \\uc801\\uadf9 \\ucd94\\ucc9c\\ub4dc\\ub9bd\\ub2c8\\ub2e4. \\ubaa8\\ubc14\\uc77c \\uc571(\\ub2e4\\ubc29, \\uc9c1\\ubc29\\ub4f1)\\uc744 \\uc774\\uc6a9\\ud558\\ub294 \\ubd80\\ub3d9\\uc0b0\\ub4e4\\uc774 \\uc8fc\\ub85c \\uba87 \\ub144 \\uc548\\ub41c \\ubd80\\ub3d9\\uc0b0 \\uc911\\uac1c\\uc18c\\ub4e4\\uc785\\ub2c8\\ub2e4. \\ud798\\ub4e4\\uace0 \\uc2dc\\uac04\\uc774 \\ub4e4\\uc5b4\\ub3c4 \\uaf2d \\ubd80\\ub3d9\\uc0b0 \\ub9cc\\ud07c\\uc740 \\uc2e0\\uc911\\ud558\\uac8c \\uc9c1\\uc811 \\ub2e4 \\ub458\\ub7ec\\ubcf4\\uc138\\uc694. \\ub9ce\\uc740 \\ub178\\ub825\\uc744 \\ud558\\uc2dc\\uba74 \\uc790\\uae30\\uc5d0\\uac8c \\ub9de\\ub294 \\uc9d1\\uc744 \\ucc3e\\uc73c\\uc2dc\\uace0 \\ud3b8\\uc548\\ud55c \\uc0b6\\uc744 \\uc0ac\\uc2e4 \\uc218 \\uc788\\uc73c\\uc2e4\\uac81\\ub2c8\\ub2e4. \\uc624\\ub298 \\ud558\\ub8e8\\ub3c4 \\ud798\\ub0b4\\uc138\\uc694 \\ud30c\\uc774\\ud305~\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_preprocessed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56703,\n        \"samples\": [\n          \"\\ub124\\uc774\\ubc84\\ubd80\\ub3d9\\uc0b0 \\uac70 \\uc9c4\\uc9dc \\uc88b\\uc740 \\ub4ef \\uac15 \\ucd94 \\ubcc4\\ub85c 5\\uac1c\\uac00 \\uc548 \\uc544\\uae5d\\ub2e4\",\n          \"\\uc11c\\uc6b8 \\ucca8 \\uc62c\\ub77c\\uc654\\ub294\\ub370 \\uc9c1\\ubc29 \\ucc3e\\ub294 \\uac8c \\uc9c4\\uc9dc \\ud798\\ub4e0 \\uc77c\\uc774\\ub124\",\n          \"\\uc9c1\\ubc29 \\uad6c\\ud558\\ub294\\ub370 \\ub9ce\\uc740 \\ub3c4\\uc6c0\\uc774 \\ub420 \\uaebc \\uac19\\uc544\\uc694\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56628,\n        \"samples\": [\n          \"['\\uc5ec\\uae30\\uc800\\uae30', '\\ucc3e\\uc544', '\\ub2e4\\ub2d0', '\\ud544\\uc694', '\\uc5c6\\uc774', '\\ub124\\uc774\\ubc84', '\\ubd80\\ub3d9\\uc0b0', '\\uc571', '\\ud558\\ub098', '\\uba74', '\\uc644\\uc804', '\\ud3b8\\ub9ac\\ud558\\ub124\\uc5ec']\",\n          \"['\\uc0ac\\ucd0c\\uc5b8\\ub2c8', '\\uc790\\ucde8', '\\ubc29', '\\uc774', '\\uac78', '\\ub85c', '\\ucc3e\\uc544\\uc918\\uc57c\\uaca0\\ub124\\uc694', '\\u314e\\u314e']\",\n          \"['\\ud3b8\\ud574\\uc11c', '\\uc88b\\uc544\\uc694', '\\u314e\\u314e']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_pos\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56639,\n        \"samples\": [\n          \"[('\\uc2e0\\ub8b0', 'Noun'), ('\\uac00\\ub4dd\\ud55c', 'Adjective'), ('\\uc9c1\\ubc29', 'Noun')]\",\n          \"[('\\uc5c5\\ub370\\uc774\\ud2b8', 'Noun'), ('\\ub41c', 'Verb'), ('\\uac70', 'Noun'), ('\\ubd88\\ud3b8\\ud574\\uc11c', 'Adjective'), ('\\uc9c0\\uc6e0\\uc5b4\\uc694', 'Verb'), ('\\uc778\\ud130\\ud398\\uc774\\uc2a4', 'Noun'), ('\\ubc14\\uafbc', 'Verb'), ('\\uac8c', 'Noun'), ('\\ubd88\\ud3b8\\ud558\\ub124\\uc694', 'Adjective')]\",\n          \"[('\\uba39\\uace0', 'Verb'), ('\\uc0b4\\uae30', 'Noun'), ('\\ud798\\ub4e0', 'Adjective'), ('\\uac70', 'Noun'), ('\\uc544\\ub294\\ub370', 'Verb'), ('\\ubbf8\\ub07c', 'Noun'), ('\\ub09a\\uc2dc', 'Noun'), ('\\ud5c8\\uc704\\ub9e4\\ubb3c', 'Noun'), ('\\ub300\\ubd80\\ubd84', 'Noun'), ('\\uc774\\ub77c', 'Verb'), ('\\ub124\\uc774\\ubc84', 'Noun'), ('\\ubd80\\ub3d9\\uc0b0', 'Noun'), ('\\uc571', 'Noun'), ('\\uc758', 'Josa'), ('\\uac1c\\uc120', 'Noun'), ('\\uc774', 'Josa'), ('\\uc808\\uc2e4', 'Noun'), ('\\ud788', 'Adverb'), ('\\ud544\\uc694\\ud574', 'Adjective'), ('\\ubcf4\\uc785\\ub2c8\\ub2e4', 'Verb')]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nouns_only\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46139,\n        \"samples\": [\n          \"['\\ud5c8\\uc704\\ub9e4\\ubb3c', '\\uc800\\ud76c', '\\ub3d9\\ub124', '\\uc2dc', '\\uc784\\ucc28\\uc778', '\\uc81c', '\\uc2e0\\ub9bc\\ub3d9', '\\ud3c9\\uc218', '\\ubc29', '\\ubd81', '\\uc720\\ub7fd', '\\uc218\\uac00']\",\n          \"['\\ubcf4\\uae30', '\\ub313\\uae00', '\\uc790\\uae30', '\\uc544\\ud30c\\ud2b8', '\\uc790\\ub791']\",\n          \"['\\ud61c\\ub9ac', '\\uad11\\uace0']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nouns_without_stopwords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38146,\n        \"samples\": [\n          \"['\\uc8fc\\uc18c', '\\uac80\\uc0c9', '\\uc120\\ud0dd', '\\ud574\\ub3c4', '\\uc544\\ubb34', '\\ubc18\\uc751', '\\uc2e4\\ub9e4\\ubb3c']\",\n          \"['\\uc788\\ub139']\",\n          \"['\\uc6d4\\uc138', '\\ubcf4\\uc99d\\uae08', '\\uc2dd', '\\ucc98\\uc74c']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"9jx_N8meO8KO"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNAgD4BPMp8mLxZPv/YMxE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}